{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"nmr_FAIR-DOs","text":"<p>This project creates FAIR Digital Objects (FAIR-DOs) for multiple repositories, registers them with the Typed PID-Maker and indexes them in an Elasticsearch instance.</p> <p>Currently, these repositories are supported:</p> <ul> <li>NMRXiv</li> <li>Chemotion</li> </ul> <p>See the created FAIR-DOs of the project.</p> <p>If you want to explore these FAIR-DOs in a user-friendly manner, please visit the search interface. For more information, see the documentation.</p>"},{"location":"#usage","title":"Usage","text":"<p>To get started, please check out the quickstart guide.</p>"},{"location":"#how-to-cite","title":"How to Cite","text":"<p>If you want to cite this project in your scientific work, please use the citation file in the repository.</p>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>This is a Python project generated from the fair-python-cookiecutter template.</p> <p>We kindly thank all authors and contributors.</p> <p>This tool was created at Karlsruhe Institute of Technology (KIT) at the Scientific Computing Center (SCC) in the department Data Exploitation Methods (DEM).</p> <p>This work is supported by the consortium NFDI-MatWerk, funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under the National Research Data Infrastructure \u2013 NFDI 38/1 \u2013 project number 460247524. TODO: relevant organizational acknowledgements (employers, funders)</p>"},{"location":"changelog/","title":"Changelog","text":"<p>Here we provide notes that summarize the most important changes in each released version.</p> <p>Please consult the changelog to inform yourself about breaking changes and security issues.</p>"},{"location":"changelog/#0.1.0","title":"v0.1.0 (2024-11-04)","text":"<ul> <li>First release</li> </ul>"},{"location":"code_of_conduct/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"code_of_conduct/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"code_of_conduct/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes,   and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the overall   community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or advances of   any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email address,   without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"code_of_conduct/#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"code_of_conduct/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"code_of_conduct/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the project maintainers by e-mail. All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"code_of_conduct/#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"code_of_conduct/#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"code_of_conduct/#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"code_of_conduct/#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.</p>"},{"location":"code_of_conduct/#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"code_of_conduct/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html.</p> <p>Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder.</p> <p>For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.</p>"},{"location":"contributing/","title":"How To Contribute","text":"<p>All kinds of contributions are very welcome! You can contribute in various ways, e.g. by</p> <ul> <li>providing feedback</li> <li>asking questions</li> <li>suggesting ideas</li> <li>implementing features</li> <li>fixing problems</li> <li>improving documentation</li> </ul> <p>To make contributing to open source projects a good experience to everyone involved, please make sure that you follow our code of conduct when communicating with others.</p>"},{"location":"contributing/#ideas-questions-and-problems","title":"Ideas, Questions and Problems","text":"<p>If you have questions or difficulties using this software, please use the issue tracker.</p> <p>If your topic is not already covered by an existing issue, please create a new issue using one of the provided issue templates.</p> <p>If your issue is caused by incomplete, unclear or outdated documentation, we are also happy to get suggestions on how to improve it. Outdated or incorrect documentation is a bug, while missing documentation is a feature request.</p> <p>NOTE: If you want to report a critical security problem, do not open an issue! Instead, please create a private security advisory, or contact the current package maintainers directly by e-mail.</p>"},{"location":"contributing/#development","title":"Development","text":"<p>This project uses Poetry for dependency management.</p> <p>You can run the following lines to check out the project and prepare it for development:</p> <pre><code>git clone https://github.com/maximiliani/nmr_FAIR-DOs\ncd nmr_FAIR-DOs\npoetry install --with docs\npoetry run poe init-dev\n</code></pre> <p>Common tasks are accessible via poe:</p> <ul> <li> <p>Use <code>poetry run poe lint</code> to run linters manually, add <code>--all-files</code> to check everything.</p> </li> <li> <p>Use <code>poetry run poe test</code> to run tests, add <code>--cov</code> to also show test coverage.</p> </li> <li> <p>Use <code>poetry run poe docs</code> to generate local documentation</p> </li> </ul> <p>In order to contribute code, please open a pull request.</p> <p>Before opening the PR, please make sure that your changes</p> <ul> <li>are sufficiently covered by meaningful tests,</li> <li>are reflected in suitable documentation (API docs, guides, etc.), and</li> <li>successfully pass all pre-commit hooks.</li> </ul>"},{"location":"credits/","title":"Authors and Contributors","text":"<p>Main authors are persons whose contributions significantly shaped the state of the software at some point in time.</p> <p>Additional contributors are persons who are not main authors, but contributed non-trivially to this project, e.g. by providing smaller fixes and enhancements to the code and/or documentation.</p> <p>Of course, this is just a rough overview and categorization. For a more complete overview of all contributors and contributions, please inspect the git history of this repository.</p>"},{"location":"credits/#main-authors","title":"Main Authors","text":"<ul> <li>Maximilian Inckmann (     E-Mail,     ORCID   ): original author</li> </ul>"},{"location":"credits/#additional-contributors","title":"Additional Contributors","text":"<p>... maybe you?</p>"},{"location":"dev_guide/","title":"Developer Guide","text":"<p>This guide is targeting mainly developers, maintainers and other technical contributors and provides more information on how to work with this repository.</p> <p>Important Information</p>"},{"location":"dev_guide/#todo-final-steps","title":"TODO: Final Steps","text":"<p>Dear project author, thank you for using <code>fair-python-cookiecutter</code>!</p> <p>Before diving into your actual project work, please complete the following steps to finalize the configuration of your project repository:</p>"},{"location":"dev_guide/#inspect-the-generated-project-files","title":"Inspect the generated project files","text":"<p>We suggest that first you familiarize yourself with the generated structure and make it \"your own\". The following sections of this guide provide a high-level overview, but you might want to inspect the various files to get a better understanding. A few files contain TODO items or sections -- please complete and remove them.</p>"},{"location":"dev_guide/#test-the-tools-locally","title":"Test the tools locally","text":"<p>After having some idea about the repository structure, we suggest that you try to run some operations, such as linting, running tests and building the documentation on your computer.</p>"},{"location":"dev_guide/#push-the-repository","title":"Push the repository","text":"<p>If you have not created an empty repository in your git hosting service already, you should create it now. Follow the instructions of your hosting service to push an existing repository (i.e. this one), which will consist of</p> <ol> <li>adding the remote repository locally (<code>git remote add ...</code>)</li> <li>pushing the contents to the remote (<code>git push</code>)</li> </ol>"},{"location":"dev_guide/#check-the-ci","title":"Check the CI","text":"<p>Your first push should have automatically triggered the CI pipeline. Please check that it runs successfully.</p>"},{"location":"dev_guide/#set-up-pages-and-releases","title":"Set up Pages and Releases","text":"<p>For deployment of documentation pages and releases of your code, some additional configuration is required. Please consult the corresponding sections of this guide.</p>"},{"location":"dev_guide/#overview","title":"Overview","text":""},{"location":"dev_guide/#repository-structure","title":"Repository Structure","text":"<p>Here is a non-exhaustive list of the most important files and directories in the repository.</p> GeneralMetadataDevelopmentCI / QA <ul> <li><code>AUTHORS.md</code>: acknowledges and lists all contributors</li> <li><code>CHANGELOG.md</code>: summarizes the changes for each version of the software for users</li> <li><code>CODE_OF_CONDUCT.md</code>: defines the social standards that must be followed by contributors</li> <li><code>CONTRIBUTING.md</code>: explains  how others can contribute to the project</li> <li><code>README.md</code>: provides an overview and points to other resources</li> </ul> <ul> <li><code>CITATION.cff</code>: metadata stating how to cite the project</li> <li><code>codemeta.json</code>: metadata for harvesting by other tools and services</li> <li><code>LICENSE</code>: the (main) license of the project</li> <li><code>LICENSES</code>: copies of all licenses that apply to files in the project</li> <li><code>.reuse/dep5</code>: granular license and copyright information for all files and directories</li> </ul> <ul> <li><code>pyproject.toml</code>: project metadata, dependencies, development tool configurations</li> <li><code>poetry.lock</code>: needed for reproducible installation of the project</li> <li><code>src</code>: actual code provided by the project</li> <li><code>tests</code>: all tests for the code in the project</li> <li><code>mkdocs.yml</code>: configuration of the project website</li> <li><code>docs</code>: most contents used for the project website</li> </ul> <ul> <li><code>.pre-commit-config.yaml</code>: quality assurance tools used in the project</li> <li><code>.github/workflows</code>: CI scripts for GitHub (QA, documentation and package deployment)</li> <li><code>.github/ISSUE_TEMPLATE</code>: templates for the GitHub issue tracker</li> <li><code>.gitlab-ci.yml</code>: mostly equivalent CI scripts, but for GitLab</li> <li><code>.gitlab/issue_templates</code>: The same issues templates, but for GitLab</li> </ul> <p>Tip</p> <p>You might find various other files popping up which are generated by different tools. Most of these should not be committed into the repository, so they are excluded in the <code>.gitignore</code> file. Everything listed there is safe to delete.</p>"},{"location":"dev_guide/#used-tools","title":"Used Tools","text":"<p>Here is a non-exhaustive list of the most important tools used in the project.</p> GeneralCode QualityFormatting and StyleFAIR metadata <ul> <li><code>poetry</code> for dependency management and packaging</li> <li><code>poethepoet</code> tool for running common tasks</li> <li><code>pre-commit</code> for orchestrating linters, formatters and other utilities</li> <li><code>mkdocs</code> for generating the project documentation website</li> <li><code>mike</code> for managing the <code>mkdocs</code>-generated documentation website</li> </ul> <ul> <li><code>flake8</code> for general linting (using various linter plugins)</li> <li><code>mypy</code> for editor-independent type-checking</li> <li><code>pytest</code> for unit testing</li> <li><code>pytest-cov</code> for computing code coverage by tests</li> <li><code>hypothesis</code> for property-based testing</li> <li><code>bandit</code> for checking security issues in the code</li> <li><code>safety</code> for checking security issues in the current dependencies</li> </ul> <ul> <li><code>black</code> for source-code formatting</li> <li><code>autoflake</code> for automatically removing unused imports</li> <li><code>pydocstyle</code> for checking docstring conventions</li> </ul> <ul> <li><code>cffconvert</code> to check the <code>CITATION.cff</code> (citation metadata)</li> <li><code>codemetapy</code> to generate a <code>codemeta.json</code> (general software metadata)</li> <li><code>somesy</code> to keep all important metadata continuously synchronized</li> <li><code>reuse</code> to check REUSE-compliance (granular copyright and license metadata)</li> <li><code>licensecheck</code> to scan for possible license incompatibilities in the dependencies</li> </ul> <p>Tip</p> <p>Most tools installed and used by this project are listed in the <code>pyproject.toml</code> and <code>.pre-commit-config.yaml</code> files.</p>"},{"location":"dev_guide/#basics","title":"Basics","text":"<p>The project</p> <ul> <li>heavily uses <code>pyproject.toml</code>, which is a recommended standard</li> <li>adopts the <code>src</code> layout, to avoid common problems</li> <li>keeps the actual code (<code>src</code>) and test code (<code>tests</code>) separated</li> </ul> <p>The <code>pyproject.toml</code> is the main configuration file for the project. It contains both general information about the software as well as configuration for various tools.</p> <p>In older software, most of this information is often scattered over many little tool-specific configuration files and a <code>setup.py</code>, <code>setup.cfg</code> and/or <code>requirements.txt</code> file.</p> <p>Tip</p> <p><code>pyproject.toml</code> is the first place your should check when looking for the configuration of some development tool.</p>"},{"location":"dev_guide/#configuration","title":"Configuration","text":"<p>The main tool needed to manage and configure the project is Poetry.</p> <p>Please follow its setup documentation to install it correctly. Poetry should not be installed with <code>pip</code> like other Python tools.</p> <p>Poetry performs many important tasks:</p> <ul> <li>it manages the virtual environment(s) used for the project</li> <li>it manages all the dependencies needed for the code to work</li> <li>it takes care of packaging the code into a <code>pip</code>-installable package</li> </ul> <p>You can find a cheatsheet with the most important commands here and consult its official documentation for detailed information.</p> <p>Note that <code>poetry</code> is only needed for development of the repository. The end-users who just want to install and use this project do not need to set up or know anything about poetry.</p> <p>Tip</p> <p>If you use <code>poetry shell</code> to activate the virtual environment of the project, and the project is already installed with <code>poetry install</code>, in the following you do not have to prepend <code>poetry run</code> in the commands you will see below.</p>"},{"location":"dev_guide/#task-runner","title":"Task Runner","text":"<p>It is a good practice to have a common way for launching different project-related tasks. It removes the need of remembering flags for various tools, and avoids duplication of the same commands in the CI pipelines. If something in a workflow needs to change, it can be changed in just one place, thus reducing the risk of making a mistake.</p> <p>Often projects use a shell script or <code>Makefile</code> for this purpose. This project uses poethepoet, as it integrates nicely with <code>poetry</code>. The tasks are defined in <code>pyproject.toml</code> and can be launched using:</p> <pre><code>poetry run poe TASK_NAME\n</code></pre>"},{"location":"dev_guide/#ci-workflows","title":"CI Workflows","text":"<p>The project contains CI workflows for both GitHub and GitLab.</p> <p>The main CI pipeline runs on each new pushed commit and will</p> <ol> <li>Run all configured code analysis tools,</li> <li>Run code tests with multiple versions of Python,</li> <li>build and deploy the online project documentation website, and</li> <li>if a new version tag was pushed, launch the release workflow</li> </ol>"},{"location":"dev_guide/#quality-control","title":"Quality Control","text":""},{"location":"dev_guide/#static-analysis","title":"Static Analysis","text":"<p>Except for code testing, most tools for quality control are added to the project as <code>pre-commit</code> hooks. The <code>pre-commit</code> tool takes care of installing, updating and running the tools according to the configuration in the <code>.pre-commit-config.yaml</code> file.</p> <p>For every new copy of the repository (e.g. after <code>git clone</code>), <code>pre-commit</code> first must be activated. This is usually done using <code>pre-commit install</code>, which also requires that <code>pre-commit</code> is already available. For more convenience, we simplified the procedure.</p> <p>In this project, you can run:</p> <pre><code>poetry run poe init-dev\n</code></pre> <p>This will make sure that <code>pre-commit</code> is enabled in your repository copy.</p> <p>Once enabled, every time you try to <code>git commit</code> some changed files various tools will run on those (and only those) files.</p> <p>This means that (with some exceptions) <code>pre-commit</code> by default will run only on the changed files that were added to the next commit (i.e., files in the git staging area). These files are usually colored in green when running <code>git status</code>.</p> <ul> <li>Some tools only report the problems they detected</li> <li>Some tools actively modify files (e.g., fix formatting)</li> </ul> <p>In any case, the <code>git commit</code> will fail if a file was modified by a tool, or some problems were reported. In order to complete the commit, you need to</p> <ul> <li>resolve all problems (by fixing them or marking them as false alarm), and</li> <li><code>git add</code> all changed files again (to update the files in the staging area).</li> </ul> <p>After doing that, you can retry to <code>git commit</code> your changes.</p> <p>To avoid having to deal with many issues at once, it is a good habit to run <code>pre-commit</code> by hand from time to time. In this project, this can be done with:</p> <pre><code>poetry run poe lint --all-files\n</code></pre>"},{"location":"dev_guide/#testing","title":"Testing","text":"<p>pytest is used as the main framework for testing.</p> <p>The project uses the <code>pytest-cov</code> plugin to integrate <code>pytest</code> with <code>coverage</code>, which collects and reports test coverage information.</p> <p>In addition to writing regular unit tests with <code>pytest</code>, consider using hypothesis, which integrates nicely with <code>pytest</code> and implements property-based testing - which involves automatic generation of randomized inputs for test cases. This can help to find bugs often found for various edge cases that are easy to overlook in ad-hoc manual tests. Such randomized tests can be a good addition to hand-crafted tests and inputs.</p> <p>To run all tests, either invoke <code>pytest</code> directly, or use the provided task:</p> <pre><code>poetry run poe test\n</code></pre> <p>Tip</p> <p>Add the flag <code>--cov</code> to enable the test coverage tracking and get a table with results after the tests are completed.</p>"},{"location":"dev_guide/#documentation","title":"Documentation","text":"<p>The project uses <code>mkdocs</code> with the popular and excellent <code>mkdocs-material</code> theme to generate the project documentation website, which provides both user and developer documentation.</p> <p><code>mkdocs</code> is configured in the <code>mkdocs.yml</code> file, which we prepared in a way that there is</p> <ul> <li>no need to duplicate sections from files in other places (such as <code>README.md</code>)</li> <li>fully automatic API documentation pages based on Python docstrings in the code</li> <li>a detailed test coverage report is included in the website</li> </ul> <p>The first point is important, because avoiding duplication means avoiding errors whenever text or examples are updated. The second point is convenient, as modules and functions do not need to be added by hand, which is easy to forget. The third point removes the need to use an external service such as CodeCov to store and present code coverage information.</p> <p>As software changes over time and users cannot always keep up with the latest developments, each new version of the software should provide version-specific documentation. To make this both possible as well as convenient, this project uses <code>mike</code> to generate and manage the <code>mkdocs</code> documentation for different versions of the software.</p> <p>Tip</p> <p>You can easily add new pages (e.g. extended tutorials or topic-specific guides) to your documentation website by creating markdown files in the <code>docs/</code> directory and adding them to the <code>nav</code> section in <code>mkdocs.yml</code>.</p>"},{"location":"dev_guide/#offline-documentation","title":"Offline Documentation","text":"<p>You can manually generate a local and fully offline copy of the documentation, which can be useful for e.g. previewing the results during active work on the documentation:</p> <pre><code>poetry install --with docs\npoetry run poe docs\n</code></pre> <p>Once the documentation site is built, run <code>mkdocs serve</code> and open <code>https://localhost:8000</code> in your browser to see the local copy of the website.</p> <p>Tip</p> <p>You probably should always check bigger website updates locally before it is publicly deployed. The automatic pipelines can only catch technical problems, but you still e.g. might want to do some proof-reading.</p>"},{"location":"dev_guide/#online-documentation","title":"Online Documentation","text":"<p>To avoid dependence on additional services such as readthedocs, the project website is set up for simple deployment using GitHub Pages or GitLab Pages.</p> <p>The provided CI pipeline automatically generates the documentation for the latest development version (i.e., current state of the <code>main</code> branch) as well as every released version (i.e., marked by a version tag <code>vX.Y.Z</code>).</p> <p>Publishing the documentation to a website using GitHub or GitLab Pages needs a bit of configuration. Please follow the steps for your respective hosting service.</p> GitLabGitHub <ol> <li>Create a new project access token for GitLab Pages deployment<ul> <li>in your GitLab project, go to Settings &gt; Access Tokens</li> <li>Add a new token with the following settings:<ul> <li>Token name: <code>PAGES_DEPLOYMENT_TOKEN</code></li> <li>Expiration date: (far in the future)</li> <li>Select a role: Maintainer</li> <li>Select scopes: read_repository, write_repository</li> </ul> </li> </ul> </li> <li>Provide the token as a masked(!) variable to the CI pipeline<ul> <li>in your GitLab project, go to Settings &gt; CI/CD</li> <li>in the section Variables add a new variable with<ul> <li>Key: <code>PAGES_TOKEN</code></li> <li>Value: (the token string, as generated in the previous step)</li> <li>enable Mask variable, so your token will not appear in logs</li> </ul> </li> </ul> </li> <li>Ensure that the GitLab pages URL is correct<ul> <li>in your GitLab project, go to Deploy &gt; Pages</li> <li>make sure that Use unique domain is NOT enabled</li> <li>check that under Access pages the URL matches the <code>site_url</code> in your <code>mkdocs.yml</code></li> </ul> </li> </ol> <ul> <li>make sure that you pushed the repository and the CI pipeline completed at least once</li> <li>check that a <code>gh-pages</code> branch exists (created by the CI)</li> <li>go to your GitHub repository Settings and from there to settings for Pages</li> <li>under Build and deployment pick <code>gh-pages</code> as the branch for serving documentation</li> </ul> <p>Important Information</p> <p>When adding any kind of token to your repository configuration, which usually allows code and pipelines to access and modify your project, make sure that the token is protected.</p> <ul> <li>In GitHub, tokens should be always added as secrets</li> <li>In GitLab, tokens should be added as CI variables that are masked</li> </ul> <p>This will make sure that the token will not appear in logs of the CI pipeline runs and minimize the risk of abuse for malicious purposes. NEVER save a token in a text file in your repository!</p> <p>Tip</p> <p>Should anything go wrong and you need to manually access the data of the deployed website, you can find it in the <code>gh-pages</code> or <code>gl-pages</code> branch of the repository. Normally you should not need to use that branch directly, though.</p>"},{"location":"dev_guide/#releases","title":"Releases","text":"<p>From time to time the project is ready for a new release for users.</p>"},{"location":"dev_guide/#creating-a-new-release","title":"Creating a New Release","text":"<p>Before releasing a new version, push the commit the new release should be based on to the upstream repository, and make sure that:</p> <ul> <li>the CI pipeline completes successfully</li> <li>the version number in <code>pyproject.toml</code> is updated, in particular:</li> <li>it must be larger than the previous released version</li> <li>it should adequately reflect the severity of changes</li> <li>the provided user and developer documentation is up-to-date, including:</li> <li>a new section in the <code>CHANGELOG.md</code> file summarizing changes in the new version</li> <li>possibly revised information about contributors and/or maintainers</li> </ul> <p>If this is the case, proceed with the release by:</p> <ul> <li>creating a new tag that matches the version in the <code>pyproject.toml</code>: <code>git tag vX.Y.Z</code></li> <li>pushing the new tag to the upstream repository: <code>git push origin vX.Y.Z</code></li> </ul> <p>The pushed version tag will trigger a pipeline that will:</p> <ul> <li>build and deploy the documentation website for the specific version</li> <li>publish the package to enabled targets (see below)</li> </ul>"},{"location":"dev_guide/#release-targets","title":"Release Targets","text":"<p>The CI pipelines are built in such a way that features can be enabled, disabled and configured easily.</p> GitLabGitHub <p>Targets for releases can be enabled or disabled in the <code>variables</code> section in <code>.gitlab-ci.yml</code>.</p> <p>Targets for releases can be enabled or disabled in <code>.github/workflows/ci.yml</code> and configured by adapting the corresponding actions in <code>.github/workflows/releases.yml</code>.</p>"},{"location":"dev_guide/#github-gitlab-release","title":"GitHub / GitLab Release","text":"<p>By default, the release workflow will create a basic GitHub or GitLab Release that provides a snapshot of the repository as a download. This requires no additional configuration.</p> <p>See here for information on how the Github release can be customized.</p> <p>Note</p> <p>The Github Release can be used to trigger automated software publication of your released versions to Zenodo, based on the metadata provided in the <code>CITATION.cff</code> file.</p>"},{"location":"dev_guide/#pypi-and-compatible-indices","title":"PyPI and Compatible Indices","text":"<p>The CI pipelines support automatic releases to PyPI, Test PyPI or other custom repositories, but in any case this requires a bit of initial configuration.</p> GitLabGitHub <p>For automated releases to PyPI and Test PyPI the project uses the classic token-based workflow.</p> <p>Before the project can be released to PyPI or Test PyPI the first time, a new PyPI API token must be created in the PyPI account of the main project maintainer, and added to your CI as a masked variable, and a variable updated in the <code>.gitlab-ci.yml</code>.</p> <p>The corresponding tokens can be added analogously to the <code>PAGES_TOKEN</code> for online documentation, which was explained here.</p> <p>PyPI:</p> <ul> <li>add the token as a masked CI variable called <code>RELEASE_TOKEN_pypi</code></li> <li>in <code>.gitlab-ci.yml</code>, set <code>release_to_pypi: \"true\"</code></li> </ul> <p>Test PyPI:</p> <ul> <li>add the token as a masked CI variable called <code>RELEASE_TOKEN_testpypi</code></li> <li>in <code>.gitlab-ci.yml</code>, set <code>release_to_testpypi: \"true\"</code></li> </ul> <p>Custom Package Index:</p> <ul> <li>add the token as a masked CI variable called <code>RELEASE_TOKEN_custom</code></li> <li>in <code>.gitlab-ci.yml</code>, set <code>release_to_custom: \"true\"</code></li> <li>update <code>PKGIDX_URL</code> in the <code>release_custom_pypi</code> job to the correct     legacy API endpoint</li> </ul> <p>For automated releases to PyPI and Test PyPI the project uses the new Trusted Publishers workflow that is both more secure and convenient to use than other authorization methods.</p> <p>Before the project can be released to PyPI or Test PyPI the first time, first a pending publisher must be added in the PyPI account of the main project maintainer, using <code>release.yml</code> as the requested workflow name.</p> <p>Note</p> <p>It is important to use the correct workflow name, otherwise the workflow will fail!</p> <p>Once this is done, set the corresponding option (<code>to_pypi</code> / <code>to_test_pypi</code>) to <code>true</code> in the <code>publish</code> job in <code>ci.yml</code> to enable the corresponding publication target.</p> <p>If the old and less secure token-based authentication method is needed or the package should be published to a different PyPI-compatible package index, please adapt <code>release.yml</code> accordingly.</p> <p>If for some reason you do not want to use the CI for the PyPI releases, you can skip these instructions and manually use <code>poetry publish</code> to do the release.</p>"},{"location":"license/","title":"License","text":"<p>Unless stated otherwise, all code provided by this project (excluding external dependencies) is distributed under the following license:</p> <pre><code>Apache License\nVersion 2.0, January 2004\nhttp://www.apache.org/licenses/\n\nTERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n1. Definitions.\n\n\"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document.\n\n\"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License.\n\n\"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.\n\n\"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License.\n\n\"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.\n\n\"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.\n\n\"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below).\n\n\"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof.\n\n\"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\"\n\n\"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.\n\n2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form.\n\n3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed.\n\n4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions:\n\n     (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and\n\n     (b) You must cause any modified files to carry prominent notices stating that You changed the files; and\n\n     (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and\n\n     (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License.\n\n     You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License.\n\n5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions.\n\n6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file.\n\n7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License.\n\n8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages.\n\n9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability.\n\nEND OF TERMS AND CONDITIONS\n\nAPPENDIX: How to apply the Apache License to your work.\n\nTo apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!)  The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives.\n\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n</code></pre> <p>This project is REUSE compliant. The following detailed license and copyright information in DEP5 format can also be found in the <code>.reuse/dep5</code> file in the project source directory:</p> <pre><code>Format: https://www.debian.org/doc/packaging-manuals/copyright-format/1.0/\nUpstream-Name: nmr_FAIR-DOs\nUpstream-Contact: Maximilian Inckmann &lt;maximilian.inckmann@kit.edu&gt;\nSource: https://github.com/maximiliani/nmr_FAIR-DOs\n\nFiles: .gitignore pyproject.toml poetry.lock .pre-commit-config.yaml codemeta.json CITATION.cff README.md RELEASE_NOTES.md CHANGELOG.md CODE_OF_CONDUCT.md AUTHORS.md CONTRIBUTING.md .gitlab-ci.yml .gitlab/* .github/* mkdocs.yml docs/*\nCopyright: Copyright \u00a9 2025 Karlsruhe Institute for Technology - Scientific Computing Center (SCC) - Data Exploitation Methods (DEM) - Maximilian Inckmann &lt;maximilian.inckmann@kit.edu&gt;\nLicense: CC0-1.0\n\nFiles: src/* tests/*\nCopyright: Copyright \u00a9 2025 Karlsruhe Institute for Technology - Scientific Computing Center (SCC) - Data Exploitation Methods (DEM) - Maximilian Inckmann &lt;maximilian.inckmann@kit.edu&gt;\nLicense: Apache-2.0\n</code></pre>"},{"location":"quickstart/","title":"Quickstart","text":""},{"location":"quickstart/#installation","title":"Installation","text":"<p>Clone this project and use Poetry to install the dependencies.</p> <pre><code>git clone https://github.com/kit-data-manager/nmr_FAIR-DOs.git\ncd nmr_FAIR-DOs\npoetry install\n</code></pre> <p>This project works with Python &gt; 3.8.</p>"},{"location":"quickstart/#getting-started","title":"Getting Started","text":"<p>Get started by running the command line interface (CLI) with the <code>nmr_FAIR-DOs</code> command. You can use the <code>--help</code> flag to see the available options. <pre><code>poetry run nmr_FAIR-DOs-cli --help\n</code></pre></p> <p>To create FAIR-DOs for all NMR data in the repositories and log the output, run the following command: <pre><code>poetry run nmr_FAIR-DOs-cli createallavailable 2&gt;&amp;1 | tee full.log\n</code></pre></p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>nmr_FAIR_DOs<ul> <li>cli</li> <li>connectors<ul> <li>elasticsearch</li> <li>terminology</li> <li>tpm_connector</li> </ul> </li> <li>domain<ul> <li>dataType</li> <li>pid_record</li> <li>pid_record_entry</li> </ul> </li> <li>env</li> <li>lib</li> <li>repositories<ul> <li>AbstractRepository</li> <li>chemotion</li> <li>nmrxiv</li> </ul> </li> <li>utils</li> </ul> </li> </ul>"},{"location":"reference/nmr_FAIR_DOs/","title":"nmr_FAIR_DOs","text":""},{"location":"reference/nmr_FAIR_DOs/#nmr_FAIR_DOs.__version__","title":"__version__  <code>module-attribute</code>","text":"<pre><code>__version__: Final[str] = version(__package__ or __name__)\n</code></pre> <p>This package contains the source code of the project.</p> <p>The package is structured as follows:</p> <ul> <li><code>connectors/</code>: Contains the connectors to the different data sources.</li> <li><code>domain/</code>: Contains the domain classes of the project.</li> <li><code>repositories/</code>: Contains the repositories for which FAIR-DOs are generated.</li> <li><code>cli.py</code>: Contains the command line interface of the project.</li> <li><code>env.py</code>: Manages the environment variables of the project.</li> <li><code>lib.py</code>: Contains the main business logic of the project.</li> <li><code>utils.py</code>: Contains various utility functions.</li> </ul>"},{"location":"reference/nmr_FAIR_DOs/cli/","title":"cli","text":"<p>CLI of nmr_FAIR-DOs.</p>"},{"location":"reference/nmr_FAIR_DOs/cli/#nmr_FAIR_DOs.cli.createAllAvailable","title":"createAllAvailable","text":"<pre><code>createAllAvailable(\n    repositories: list[str] = typer.Option(\n        None,\n        help=\"List of repositories to create PID records for. If unspecified, all available repositories are queried.\",\n    ),\n    start: datetime = typer.Option(\n        None,\n        help=\"Start of the time range to create PID records for. If unspecified, datetime.min() is used.\",\n    ),\n    end: datetime = typer.Option(\n        None,\n        help=\"End of the time range to create PID records for. If unspecified, datetime.max() is used.\",\n    ),\n    dryrun: bool = typer.Option(\n        False,\n        help=\"If True, only print the resources that would be created. If unspecified or false, create the PID records.\",\n    ),\n)\n</code></pre> <p>Create PID records for all available resources.</p> <p>Parameters:</p> Name Type Description Default <code>repositories</code> <code>list[str]</code> <p>List of repositories to create PID records for. If None, all available repositories are queried.</p> <code>Option(None, help='List of repositories to create PID records for. If unspecified, all available repositories are queried.')</code> <code>start</code> <code>datetime</code> <p>Start of the time range to create PID records for. If None, datetime.min() is used.</p> <code>Option(None, help='Start of the time range to create PID records for. If unspecified, datetime.min() is used.')</code> <code>end</code> <code>datetime</code> <p>End of the time range to create PID records for. If None, datetime.max() is used.</p> <code>Option(None, help='End of the time range to create PID records for. If unspecified, datetime.max() is used.')</code> <code>dryrun</code> <code>bool</code> <p>If True, only print the resources that would be created. If False, create the PID records. Default: False.</p> <code>Option(False, help='If True, only print the resources that would be created. If unspecified or false, create the PID records.')</code> Source code in <code>src/nmr_FAIR_DOs/cli.py</code> <pre><code>@app.command()\ndef createAllAvailable(\n    repositories: list[str] = typer.Option(\n        None,\n        help=\"List of repositories to create PID records for. If unspecified, all available repositories are queried.\",\n    ),\n    start: datetime = typer.Option(\n        None,\n        help=\"Start of the time range to create PID records for. If unspecified, datetime.min() is used.\",\n    ),\n    end: datetime = typer.Option(\n        None,\n        help=\"End of the time range to create PID records for. If unspecified, datetime.max() is used.\",\n    ),\n    dryrun: bool = typer.Option(\n        False,\n        help=\"If True, only print the resources that would be created. If unspecified or false, create the PID records.\",\n    ),\n):\n    \"\"\"\n    Create PID records for all available resources.\n\n    Args:\n        repositories (list[str]): List of repositories to create PID records for. If None, all available repositories are queried.\n        start (datetime): Start of the time range to create PID records for. If None, datetime.min() is used.\n        end (datetime): End of the time range to create PID records for. If None, datetime.max() is used.\n        dryrun (bool): If True, only print the resources that would be created. If False, create the PID records. Default: False.\n    \"\"\"\n    if repositories is None:\n        repositories = [None]\n    logger.info(\n        f\"Creating PID records for all available resources in {repositories} in timerange {start}-{end}. Dryrun: {dryrun}\"\n    )\n\n    repos: list[AbstractRepository] = getRepositories(repositories)\n    resources = asyncio.run(create_pidRecords_from_scratch(repos, start, end, dryrun))\n\n    typer.echo(f\"Created PID records for {len(resources)} resources in {repos}.\")\n    typer.echo(\"If errors occurred, please see the logs for details.\")\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/cli/#nmr_FAIR_DOs.cli.buildElastic","title":"buildElastic","text":"<pre><code>buildElastic(\n    from_file: str = typer.Option(\n        None,\n        help=\"Path to a file containing PID records to be indexed. If unspecified, all FAIR-DOs in the active Typed PID-Maker instance will be re-indexed.\",\n    )\n)\n</code></pre> <p>Build the ElasticSearch index for all available resources.</p> <p>Parameters:</p> Name Type Description Default <code>from_file</code> <code>str</code> <p>Path to a file containing PID records to be indexed. If None, all FAIR-DOs in the active Typed PID-Maker instance will be re-indexed. Default: None.</p> <code>Option(None, help='Path to a file containing PID records to be indexed. If unspecified, all FAIR-DOs in the active Typed PID-Maker instance will be re-indexed.')</code> Source code in <code>src/nmr_FAIR_DOs/cli.py</code> <pre><code>@app.command()\ndef buildElastic(\n    from_file: str = typer.Option(\n        None,\n        help=\"Path to a file containing PID records to be indexed. If unspecified, all FAIR-DOs in the active Typed PID-Maker instance will be re-indexed.\",\n    ),\n):\n    \"\"\"\n    Build the ElasticSearch index for all available resources.\n\n    Args:\n        from_file (str): Path to a file containing PID records\n            to be indexed. If None, all FAIR-DOs in the active Typed PID-Maker instance will be re-indexed. Default: None.\n    \"\"\"\n    logger.info(\"Building the ElasticSearch index for all available resources.\")\n    asyncio.run(add_all_existing_pidRecords_to_elasticsearch(from_file))\n\n    typer.echo(\"ElasticSearch index built successfully.\")\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/env/","title":"env","text":"<p>This module reads the environment variables from the .env file and sets them as global variables.</p> <p>The following environment variables are required:</p> <ul> <li><code>TPM_URL</code>: The URL of the Typed PID-Maker instance. See Typed PID Maker on GitHub</li> <li><code>TERMINOLOGY_URL</code>: The base URL of the terminology service. e.g. https://api.terminology.tib.eu</li> <li><code>CHEMOTION_BASE_URL</code>: The base URL of the Chemotion repository instance. e.g. https://chemotion-repository.net</li> <li><code>NMRXIV_BASE_URL</code>: The base URL of the NMRXIV repository instance. e.g. https://nmrxiv.org</li> <li><code>ELASTICSEARCH_URL</code>: The base URL of the Elasticsearch API endpoint. e.g. https://elasticsearch.example.com:9200</li> <li><code>ELASTICSEARCH_INDEX</code>: The name of the Elasticsearch index to use.</li> <li><code>ELASTICSEARCH_APIKEY</code>: The API key to use for the Elasticsearch API.</li> <li><code>CACHE_DIR</code>: The directory to use for caching API results. This is necessary because of missing bulk API support in Chemotion and NMRXiv repositories. e.g. tmp/cache</li> </ul>"},{"location":"reference/nmr_FAIR_DOs/lib/","title":"lib","text":"<p>This module contains the main functionality to create PID records from resources and to add them to the Typed PID-Maker and Elasticsearch. It initializes the repositories and the connectors and provides functions to add entries to PID records and to create PID records from resources or from scratch.</p>"},{"location":"reference/nmr_FAIR_DOs/lib/#nmr_FAIR_DOs.lib.getRepository","title":"getRepository","text":"<pre><code>getRepository(repo: str) -&gt; AbstractRepository\n</code></pre> <p>Get the repository object for the given repository name. If the repository is not found, a ValueError is raised.</p> <p>Parameters:</p> Name Type Description Default <code>repo</code> <code>str</code> <p>The name of the repository</p> required <p>Returns:</p> Name Type Description <code>AbstractRepository</code> <code>AbstractRepository</code> <p>The repository object</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the repository is not found</p> Source code in <code>src/nmr_FAIR_DOs/lib.py</code> <pre><code>def getRepository(repo: str) -&gt; AbstractRepository:\n    \"\"\"\n    Get the repository object for the given repository name. If the repository is not found, a ValueError is raised.\n\n    Args:\n        repo (str): The name of the repository\n\n    Returns:\n        AbstractRepository: The repository object\n\n    Raises:\n        ValueError: If the repository is not found\n    \"\"\"\n    for repository in _REPOSITORIES:\n        if repository.name == repo.upper():\n            logger.info(f\"Found repository {repository.name}\")\n            return repository.value\n    raise ValueError(\"Repository not found\", repo)\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/lib/#nmr_FAIR_DOs.lib.getRepositories","title":"getRepositories","text":"<pre><code>getRepositories(\n    repos: str | list[str] | None,\n) -&gt; list[AbstractRepository]\n</code></pre> <p>Get the repository objects for the given repository names.</p> <p>Parameters:</p> Name Type Description Default <code>repos</code> <code>str | list[str] | None</code> <p>The name of the repositories or None to get all repositories</p> required <p>Returns:</p> Type Description <code>list[AbstractRepository]</code> <p>list[AbstractRepository]: The repository objects</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input is invalid</p> Source code in <code>src/nmr_FAIR_DOs/lib.py</code> <pre><code>def getRepositories(repos: str | list[str] | None) -&gt; list[AbstractRepository]:\n    \"\"\"\n    Get the repository objects for the given repository names.\n\n    Args:\n        repos (str| list[str] | None): The name of the repositories or None to get all repositories\n\n    Returns:\n        list[AbstractRepository]: The repository objects\n\n    Raises:\n        ValueError: If the input is invalid\n    \"\"\"\n    if repos is None:\n        return [repo.value for repo in _REPOSITORIES]\n    elif isinstance(repos, str):\n        return [getRepository(repos)]\n    elif isinstance(repos, list):\n        if len(repos) == 1 and repos[0] is None:\n            logger.info(\"Getting all repositories\")\n            return [repo.value for repo in _REPOSITORIES]\n        return [getRepository(repo) for repo in repos]\n    raise ValueError(\"Invalid input\", repos)\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/lib/#nmr_FAIR_DOs.lib.addRelationship","title":"addRelationship","text":"<pre><code>addRelationship(\n    presumed_pid: str,\n    entries: list[PIDRecordEntry],\n    onSuccess: Callable[[str], None] | None = None,\n    allowRetry: bool = True,\n) -&gt; str\n</code></pre> <p>This method creates a relationship between two FAIR-DOs by adding entries to the PID record with the given PID. To accomplish this, the method first checks if the PID record already exists in the list of PID records to be created or in the list of PID records. If the PID record is not found, the method searches for the PID record in Elasticsearch and gets it from the Typed PID-Maker. If the PID record is still not found, the method raises an exception. The method then adds the entries to the PID record and calls the onSuccess function if it is given. Usually, this onSuccess function is used to add a relationship from the target PID record to the PID of the PID record that the entries are added to. This feature allows the creation of bidirectional relationships between two FAIR-DOs.</p> <p>Parameters:</p> Name Type Description Default <code>presumed_pid</code> <code>str</code> <p>The PID of the target PID record.</p> required <code>entries</code> <code>list[PIDRecordEntry]</code> <p>The PIDRecordEntries to add to the PID record. See PIDRecordEntry for more information.</p> required <code>onSuccess</code> <code>function</code> <p>The function to call after the entries have been added to the PID record (optional). This function gets the PID of the PID record as an argument.</p> <code>None</code> <code>allowRetry</code> <code>bool</code> <p>If true, the function will retry to add the entries to the PID record if it fails the first time (optional). Default is True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The PID of the PID record the entries were added to or \"None\" if the PID record was not found.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If any error occurs during the addition of the entries to the PID record</p> Source code in <code>src/nmr_FAIR_DOs/lib.py</code> <pre><code>def addRelationship(\n    presumed_pid: str,\n    entries: list[PIDRecordEntry],\n    onSuccess: Callable[[str], None] | None = None,\n    allowRetry: bool = True,\n) -&gt; str:\n    \"\"\"\n    This method creates a relationship between two FAIR-DOs by adding entries to the PID record with the given PID.\n    To accomplish this, the method first checks if the PID record already exists in the list of PID records to be created or in the list of PID records.\n    If the PID record is not found, the method searches for the PID record in Elasticsearch and gets it from the Typed PID-Maker.\n    If the PID record is still not found, the method raises an exception.\n    The method then adds the entries to the PID record and calls the onSuccess function if it is given.\n    Usually, this onSuccess function is used to add a relationship from the target PID record to the PID of the PID record that the entries are added to.\n    This feature allows the creation of bidirectional relationships between two FAIR-DOs.\n\n    Args:\n        presumed_pid (str): The PID of the target PID record.\n        entries (list[PIDRecordEntry]): The PIDRecordEntries to add to the PID record. See PIDRecordEntry for more information.\n        onSuccess (function): The function to call after the entries have been added to the PID record (optional). This function gets the PID of the PID record as an argument.\n        allowRetry (bool): If true, the function will retry to add the entries to the PID record if it fails the first time (optional). Default is True.\n\n    Returns:\n        str: The PID of the PID record the entries were added to or \"None\" if the PID record was not found.\n\n    Raises:\n        Exception: If any error occurs during the addition of the entries to the PID record\n    \"\"\"\n    logger.debug(f\"Adding entries to PID record with PID {presumed_pid}.\", entries)\n\n    cleartext_presumed_pid = decodeFromBase64(\n        presumed_pid\n    )  # decode the presumed PID from base64\n\n    # Check if the PID record already exists in the list of PID records to be created\n    for record in records_to_create:\n        if (\n            record.getPID() == presumed_pid\n        ):  # PID of the record matches the presumed PID\n            logger.debug(\n                f\"Adding entries to record in creation with PID {presumed_pid}. Identified by PID.\",\n                entries,\n            )\n            record.addListOfEntries(entries)  # add entries to the record\n            if onSuccess is not None and callable(\n                onSuccess\n            ):  # call onSuccess function if it is given and callable\n                onSuccess(record.getPID())\n            return (\n                record.getPID()\n            )  # return the PID of the record the entries were added to. SUCCESS\n        elif record.entryExists(\n            \"21.T11148/b8457812905b83046284\", cleartext_presumed_pid\n        ):  # The value of digitalObjectLocation matches the presumed PID\n            logger.debug(\n                f\"Adding entries to record in creation with PID {presumed_pid}. Identified by digitalObjectLocation.\",\n                entries,\n            )\n            record.addListOfEntries(entries)  # add entries to the record\n            if onSuccess is not None and callable(\n                onSuccess\n            ):  # call onSuccess function if it is given and callable\n                onSuccess(record.getPID())\n            return record.getPID()\n\n    # Check if the PID record already exists in the list of PID records\n    for record in pid_records:\n        if (\n            record.getPID() == presumed_pid\n        ):  # PID of the record matches the presumed PID\n            logger.debug(\n                f\"Adding entries to existing record with PID {presumed_pid}. Identified by PID.\",\n                entries,\n            )\n            record.addListOfEntries(entries)  # add entries to the record\n            tpm.updatePIDRecord(record)  # update PID record in the Typed PID-Maker\n            if onSuccess is not None and callable(\n                onSuccess\n            ):  # call onSuccess function if it is given and callable\n                onSuccess(record.getPID())\n            return record.getPID()\n        elif record.entryExists(\n            \"21.T11148/b8457812905b83046284\", cleartext_presumed_pid\n        ):  # The value of digitalObjectLocation matches the presumed PID\n            logger.debug(\n                f\"Adding entries to existing record with PID {presumed_pid}. Identified by digitalObjectLocation.\",\n                entries,\n            )\n            record.addListOfEntries(entries)  # add entries to the record\n            tpm.updatePIDRecord(record)  # update PID record in the Typed PID-Maker\n            if onSuccess is not None and callable(onSuccess):\n                onSuccess(record.getPID())\n            return record.getPID()\n\n    # Check if the PID record exists in Elasticsearch and get it from the Typed PID-Maker\n    try:\n        logger.info(\n            \"Couldn't find a record to add entries to. Calling add_relationship function. Starting to search in elasticsearch.\"\n        )\n        pid = elasticsearch.searchForPID(\n            cleartext_presumed_pid\n        )  # search for the PID in Elasticsearch\n\n        if (\n            pid is not None\n        ):  # PID found in Elasticsearch. This is the most probable match determined by Elasticsearch for the presumed PID\n            logger.info(\n                f\"Found PID record in Elasticsearch with PID {pid}. Adding entries to it.\"\n            )\n            record = tpm.getPIDRecord(\n                pid\n            )  # get the PID record from the Typed PID-Maker with the found PID from Elasticsearch\n\n            if record is not None and isinstance(\n                record, PIDRecord\n            ):  # Check if a PID record was found in the Typed PID-Maker\n                record.addListOfEntries(entries)  # add entries to the record\n                pid_records.append(\n                    record\n                )  # add the record to the list of PID records for future use\n                tpm.updatePIDRecord(\n                    record\n                )  # update the PID record in the Typed PID-Maker\n                if onSuccess is not None and callable(\n                    onSuccess\n                ):  # call onSuccess function if it is given and callable\n                    onSuccess(\n                        record.getPID()\n                    )  # call onSuccess function with the PID of the record\n                return record.getPID()\n    except Exception as e:  # Something went wrong during the search in Elasticsearch or getting the PID record from the Typed PID-Maker\n        if allowRetry:  # Retry is enabled -&gt; add the entries to the list of future entries for future use\n            future_entry = {\"presumed_pid\": presumed_pid, \"entries\": entries}\n            logger.info(\n                f\"Could not find a PID record locally or in Elasticsearch with PID {presumed_pid} aka {cleartext_presumed_pid}. Reminding entry for future use. {str(e)}\",\n                future_entry,\n                pid_records,\n                e,\n            )\n            if (\n                presumed_pid is not None or entries is not None\n            ):  # Check if the presumed PID and the entries are not None\n                future_entries.append(future_entry)\n        else:  # Retry is disabled -&gt; raise an exception\n            logger.error(\n                f\"Retry disabled. Error adding entries to PID record {presumed_pid}. {str(e)}\",\n                entries,\n            )\n            raise Exception(\n                \"Error adding entries to PID record. Retry disabled.\",\n                presumed_pid,\n                entries,\n                e,\n            )\n\n    return \"None\"  # No PID record found. Return \"None\"\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/lib/#nmr_FAIR_DOs.lib.create_pidRecords_from_resources","title":"create_pidRecords_from_resources  <code>async</code>","text":"<pre><code>create_pidRecords_from_resources(\n    repo: AbstractRepository, resources: list[dict]\n) -&gt; None\n</code></pre> <p>This function PID records for the given resources of the given repository. It extracts the PID records from the resources and adds them to the list of PID records to be created. If the repository FDO is not found, it is created and added to the list of PID records to be created. If an error occurs during the creation of the PID records, the error is added to the list of errors for further investigation by the user.</p> <p>Parameters:</p> Name Type Description Default <code>repo</code> <code>AbstractRepository</code> <p>The repository to create PID records for</p> required <code>resources</code> <code>list[dict]</code> <p>A list of resources to create PID records from (e.g., JSON objects). The format of the resources is repository specific.</p> required <p>Returns:</p> Type Description <code>None</code> <p>list[PIDRecord]: A list of PID records created from the provided resources</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If an error occurs during the creation of the PID records</p> Source code in <code>src/nmr_FAIR_DOs/lib.py</code> <pre><code>async def create_pidRecords_from_resources(\n    repo: AbstractRepository, resources: list[dict]\n) -&gt; None:\n    \"\"\"\n    This function PID records for the given resources of the given repository.\n    It extracts the PID records from the resources and adds them to the list of PID records to be created.\n    If the repository FDO is not found, it is created and added to the list of PID records to be created.\n    If an error occurs during the creation of the PID records, the error is added to the list of errors for further investigation by the user.\n\n    Args:\n        repo (AbstractRepository): The repository to create PID records for\n        resources (list[dict]): A list of resources to create PID records from (e.g., JSON objects). The format of the resources is repository specific.\n\n    Returns:\n        list[PIDRecord]: A list of PID records created from the provided resources\n\n    Raises:\n        Exception: If an error occurs during the creation of the PID records\n    \"\"\"\n    logger.info(f\"Creating PID records for the {len(resources)} resources\")\n\n    # get repository FDO\n    repo_FDO, isNew = await _getRepoFAIRDO(repo)\n\n    # Extract PID records from the resources\n    for resource in resources:  # iterate over the resources\n        logger.debug(f\"Extracting PID record from {str(resource)[:100]}\")\n        try:\n            pid_record = await repo.extractPIDRecordFromResource(\n                resource, addRelationship\n            )  # extract PID record from the resource\n            if pid_record is not None and isinstance(\n                pid_record, PIDRecord\n            ):  # Check if a PID record was extracted\n                pid_record.addEntry(  # add the repository FDO as primary source to the PID record\n                    \"21.T11148/a753134738da82809fc1\",\n                    repo_FDO.getPID(),\n                    \"hadPrimarySource\",\n                )\n                # repo_FDO.addEntry( TODO: add this entry to the repository FDO; disabled due to size constraints of Handle records (problems at ~400 KB; actual size of repository FDO: ~2.9 MB)\n                #     \"21.T11148/4fe7cde52629b61e3b82\",\n                #     pid_record.getPID(),\n                #     \"isMetadataFor\",\n                # )\n                records_to_create.append(\n                    pid_record\n                )  # add the PID record to the list of PID records to be created\n            else:  # No PID record extracted from the resource -&gt; add an error to the list of errors\n                logger.error(f\"No PID record extracted from {resource}\")\n                errors.append(\n                    {\n                        \"url\": resource,\n                        \"error\": \"No PID record extracted\",\n                        \"timestamp\": datetime.now().isoformat(),\n                    }\n                )\n        except Exception as e:  # An error occurred during the extraction of the PID record -&gt; add an error to the list of errors\n            logger.error(f\"Error extracting PID record from {resource}: {str(e)}\", e)\n            errors.append(\n                {\n                    # \"url\": resource,\n                    \"error\": str(e),\n                    \"timestamp\": datetime.now().isoformat(),\n                }\n            )\n\n    logger.info(\"Dealing with future entries\", future_entries)\n    # Add entries from future entries to PID records (second attempt)\n    while len(future_entries) &gt; 0:  # while there are future entries\n        entry = future_entries.pop()  # get the first entry\n        try:  # try to add the entries to the PID record\n            pid = entry[\"presumed_pid\"]\n            entries = entry[\"entries\"]\n\n            logger.info(\n                f\"Adding entries to PID record with PID {pid} from future entries (second attempt).\",\n                entries,\n            )\n\n            addRelationship(\n                pid, entries, None, False\n            )  # add the entries to the PID record (without retry to ensure that no infinite loop is created)\n        except Exception as e:  # An error occurred during the addition of the entries to the PID record -&gt; add an error to the list of errors\n            logger.error(\n                f\"Error adding entries to PID record with PID {entry['presumed_pid']} from future entries. This was the second and last attempt.\",\n                entry,\n                e,\n            )\n            errors.append(\n                {\n                    \"url\": entry[\"presumed_pid\"],\n                    \"error\": str(e),\n                    \"timestamp\": datetime.now().isoformat(),\n                }\n            )\n\n    if isNew:  # Check if the repository FDO is newly created\n        logger.info(f\"Creating repository FDO with preliminary PID {repo_FDO.getPID()}\")\n        records_to_create.append(\n            repo_FDO\n        )  # add the repository FDO to the list of PID records to be created\n    else:  # The repository FDO is not newly created\n        logger.info(f\"Updating repository FDO with actual PID {repo_FDO.getPID()}\")\n        tpm.updatePIDRecord(\n            repo_FDO\n        )  # update the repository FDO in the Typed PID-Maker\n        await elasticsearch.addPIDRecord(\n            repo_FDO\n        )  # add the repository FDO to Elasticsearch\n\n    # write errors to file\n    with open(\"errors_\" + repo.repositoryID.replace(\"/\", \"_\") + \".json\", \"w\") as f:\n        json.dump(errors, f)\n        logger.info(\"Errors written to file errors.json\")\n\n    # write PID records to file\n    with open(\n        \"records_to_create\" + repo.repositoryID.replace(\"/\", \"_\") + \".json\", \"w\"\n    ) as f:\n        json.dump([record.toJSON() for record in records_to_create], f)\n        logger.info(\"PID records written to file records_to_create.json\")\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/lib/#nmr_FAIR_DOs.lib.create_pidRecords_from_scratch","title":"create_pidRecords_from_scratch  <code>async</code>","text":"<pre><code>create_pidRecords_from_scratch(\n    repos: list[AbstractRepository],\n    start: datetime = None,\n    end: datetime = None,\n    dryrun: bool = False,\n) -&gt; list[PIDRecord]\n</code></pre> <p>Create PID records from scratch for the given time frame or all available URLs if no time frame is given.</p> <p>Parameters:</p> Name Type Description Default <code>repos</code> <code>list[AbstractRepository]</code> <p>The repositories to create PID records for. If None, all available repositories are used.</p> required <code>start</code> <code>datetime</code> <p>The start of the time frame. If None, all available URLs are used.</p> <code>None</code> <code>end</code> <code>datetime</code> <p>The end of the time frame. If None, all available URLs are used.</p> <code>None</code> <code>dryrun</code> <code>bool</code> <p>If true, the PID records will not be created in TPM or Elasticsearch</p> <code>False</code> <p>Returns:</p> Type Description <code>list[PIDRecord]</code> <p>list[PIDRecord]: A list of PID records created from scratch</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If an error occurs during the creation of the PID records</p> Source code in <code>src/nmr_FAIR_DOs/lib.py</code> <pre><code>async def create_pidRecords_from_scratch(\n    repos: list[AbstractRepository],\n    start: datetime = None,\n    end: datetime = None,\n    dryrun: bool = False,\n) -&gt; list[PIDRecord]:\n    \"\"\"\n    Create PID records from scratch for the given time frame or all available URLs if no time frame is given.\n\n    Args:\n        repos (list[AbstractRepository]): The repositories to create PID records for. If None, all available repositories are used.\n        start (datetime): The start of the time frame. If None, all available URLs are used.\n        end (datetime): The end of the time frame. If None, all available URLs are used.\n        dryrun (bool): If true, the PID records will not be created in TPM or Elasticsearch\n\n    Returns:\n        list[PIDRecord]: A list of PID records created from scratch\n\n    Raises:\n        Exception: If an error occurs during the creation of the PID records\n    \"\"\"\n    start_time = datetime.now()\n    for repo in repos:  # iterate over the repositories\n        resources = []  # list of resources to create PID records from\n\n        # Get the URLs for the given time frame or all available URLs if no time frame is given\n        if (  # Check if the start and end of the time frame are given and are of type datetime\n            start is not None\n            and end is not None\n            and isinstance(start, datetime)\n            and isinstance(end, datetime)\n        ):\n            resources = await repo.getResourcesForTimeFrame(\n                start, end\n            )  # get the resources for the given time frame\n        else:\n            with open(\"last_run_\" + repo.repositoryID.replace(\"/\", \"_\"), \"w\") as f:\n                f.write(datetime.now().isoformat())\n            resources = (\n                await repo.getAllAvailableResources()\n            )  # get all available resources\n\n        logger.info(f\"Creating PID records from scratch for {len(resources)} resources\")\n\n        await create_pidRecords_from_resources(\n            repo, resources\n        )  # create PID records from the resources\n\n    real_pid_records = await _createRecordsToCreate(\n        dryrun\n    )  # create PID records in TPM and Elasticsearch\n\n    # write PID records to file\n    with open(\"pid_records_all.json\", \"w\") as f:\n        json.dump([record.toJSON() for record in pid_records], f)\n        logger.info(\"PID records written to file pid_records.json\")\n\n    logger.info(\n        f\"Finished creating {len(real_pid_records)} PID records in {datetime.now() - start_time}\"\n    )\n    return real_pid_records\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/lib/#nmr_FAIR_DOs.lib.add_all_existing_pidRecords_to_elasticsearch","title":"add_all_existing_pidRecords_to_elasticsearch  <code>async</code>","text":"<pre><code>add_all_existing_pidRecords_to_elasticsearch(\n    fromFile: str = None,\n) -&gt; None\n</code></pre> <p>Add all existing PID records to Elasticsearch. If fromFile is not None, the PID records will be read from a file instead of the Typed PID-Maker.</p> <p>Parameters:</p> Name Type Description Default <code>fromFile</code> <code>bool</code> <p>If true, the PID records will be read from a file instead of the Typed PID-Maker. Default is None.</p> <code>None</code> <p>Raises:</p> Type Description <code>Exception</code> <p>If an error occurs during the addition of the PID records to Elasticsearch</p> Source code in <code>src/nmr_FAIR_DOs/lib.py</code> <pre><code>async def add_all_existing_pidRecords_to_elasticsearch(fromFile: str = None) -&gt; None:\n    \"\"\"\n    Add all existing PID records to Elasticsearch. If fromFile is not None, the PID records will be read from a file instead of the Typed PID-Maker.\n\n    Args:\n        fromFile (bool): If true, the PID records will be read from a file instead of the Typed PID-Maker. Default is None.\n\n    Raises:\n        Exception: If an error occurs during the addition of the PID records to Elasticsearch\n    \"\"\"\n    try:\n        records: list[PIDRecord]\n        if fromFile is not None:  # Check if the PID records should be read from a file\n            with open(fromFile, \"r\") as f:  # read the PID records from the file\n                records = [\n                    PIDRecord.fromJSON(record) for record in json.load(f)\n                ]  # convert the JSON objects to PID records\n                logger.info(f\"found {len(records)} PID records in file {fromFile}\")\n        else:  # Read the PID records from the Typed PID-Maker\n            records = (\n                await tpm.getAllPIDRecords()\n            )  # get all PID records from the Typed PID-Maker\n            logger.info(f\"found {len(records)} PID records in TPM\")\n\n        logger.info(\"Adding all existing PID records to Elasticsearch\")\n        await elasticsearch.addPIDRecords(\n            records\n        )  # add the PID records to Elasticsearch\n\n        with open(\"pid_records_all.json\", \"w\") as f:  # write the PID records to a file\n            json.dump([record.toJSON() for record in records], f)\n            logger.info(\"PID records written to file pid_records_all.json\")\n    except (\n        Exception\n    ) as e:  # An error occurred during the addition of the PID records to Elasticsearch\n        logger.error(\"Error adding PID records to Elasticsearch\")\n        raise Exception(\"Error adding PID records to Elasticsearch\", e)\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/lib/#nmr_FAIR_DOs.lib.extractBiggestFAIRDO","title":"extractBiggestFAIRDO","text":"<pre><code>extractBiggestFAIRDO(\n    records: list[PIDRecord],\n) -&gt; PIDRecord | None\n</code></pre> <p>Extract the biggest FAIR-DO from a list of PID records. The biggest FAIR-DO is the PID record with the most entries (even if they are from the same data type).</p> <p>Parameters:</p> Name Type Description Default <code>records</code> <code>list[PIDRecord]</code> <p>The list of PID records to extract the biggest FAIR-DO from</p> required <p>Returns:</p> Name Type Description <code>PIDRecord</code> <code>PIDRecord | None</code> <p>The biggest FAIR-DO record from the list of PID records</p> Source code in <code>src/nmr_FAIR_DOs/lib.py</code> <pre><code>def extractBiggestFAIRDO(records: list[PIDRecord]) -&gt; PIDRecord | None:\n    \"\"\"\n    Extract the biggest FAIR-DO from a list of PID records.\n    The biggest FAIR-DO is the PID record with the most entries (even if they are from the same data type).\n\n    Args:\n        records (list[PIDRecord]): The list of PID records to extract the biggest FAIR-DO from\n\n    Returns:\n        PIDRecord: The biggest FAIR-DO record from the list of PID records\n    \"\"\"\n    if (\n        not records\n        or records is None\n        or not isinstance(records, list)\n        or len(records) == 0\n    ):\n        logger.error(\"Invalid input: records is None or not a list or empty\")\n        return None\n    elif len(records) == 1:  # Only one PID record in the list\n        logger.info(\"Only one PID record in list. Returning it.\")\n        return records[0]\n\n    biggest_FDO = records[0]\n    biggest_FDO_attributeValue = 0\n    for record in records:  # iterate over the PID records\n        for entry in record.getEntries().values():\n            if isinstance(entry, list) and len(entry) &gt; biggest_FDO_attributeValue:\n                logger.info(f\"New biggest FAIR-DO: {record.getPID()}\")\n                biggest_FDO = record\n                biggest_FDO_attributeValue = len(entry)\n\n    logger.info(f\"Found biggest FAIR-DO: {biggest_FDO.getPID()}\")\n    return biggest_FDO\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/lib/#nmr_FAIR_DOs.lib.extractRecordWithMostDataTypes","title":"extractRecordWithMostDataTypes","text":"<pre><code>extractRecordWithMostDataTypes(\n    records: list[PIDRecord],\n) -&gt; PIDRecord | None\n</code></pre> <p>Extract the PID record with the most different data types from a list of PID records. The PID record with the most different data types is the PID record with the most different keys in its entries.</p> <p>Parameters:</p> Name Type Description Default <code>records</code> <code>list[PIDRecord]</code> <p>The list of PID records to extract the PID record with the most different data types from</p> required <p>Returns:</p> Name Type Description <code>PIDRecord</code> <code>PIDRecord | None</code> <p>The PID record with the most different data types from the list of PID records</p> Source code in <code>src/nmr_FAIR_DOs/lib.py</code> <pre><code>def extractRecordWithMostDataTypes(records: list[PIDRecord]) -&gt; PIDRecord | None:\n    \"\"\"\n    Extract the PID record with the most different data types from a list of PID records.\n    The PID record with the most different data types is the PID record with the most different keys in its entries.\n\n    Args:\n        records (list[PIDRecord]): The list of PID records to extract the PID record with the most different data types from\n\n    Returns:\n        PIDRecord: The PID record with the most different data types from the list of PID records\n    \"\"\"\n    if (\n        not records\n        or records is None\n        or not isinstance(records, list)\n        or len(records) == 0\n    ):\n        logger.error(\"Invalid input: records is None or not a list or empty\")\n        return None\n    elif len(records) == 1:  # Only one PID record in the list\n        logger.info(\"Only one PID record in list. Returning it.\")\n        return records[0]\n\n    most_informative_FDO = records[0]\n    for record in records:  # iterate over the PID records\n        if len(record.getEntries()) &gt; len(most_informative_FDO.getEntries()):\n            logger.info(f\"New most informative FAIR-DO: {record.getPID()}\")\n            most_informative_FDO = record\n\n    logger.info(f\"Found most informative FAIR-DO: {most_informative_FDO.getPID()}\")\n    return most_informative_FDO\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/utils/","title":"utils","text":"<p>This module provides utility functions for the NMR FAIR DOs project.</p>"},{"location":"reference/nmr_FAIR_DOs/utils/#nmr_FAIR_DOs.utils.fetch_data","title":"fetch_data  <code>async</code>","text":"<pre><code>fetch_data(url: str, forceFresh: bool = False) -&gt; dict\n</code></pre> <p>Fetches data from the specified URL. The data is cached in the CACHE_DIR. If the data is already cached, it is used instead of fetching fresh data.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to fetch data from</p> required <code>forceFresh</code> <code>bool</code> <p>Whether to force fetching fresh data. This tells the function to ignore cached data.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The fetched data</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the URL is invalid or the data cannot be fetched</p> Source code in <code>src/nmr_FAIR_DOs/utils.py</code> <pre><code>async def fetch_data(url: str, forceFresh: bool = False) -&gt; dict:\n    \"\"\"\n    Fetches data from the specified URL.\n    The data is cached in the CACHE_DIR.\n    If the data is already cached, it is used instead of fetching fresh data.\n\n    Args:\n        url (str): The URL to fetch data from\n        forceFresh (bool): Whether to force fetching fresh data. This tells the function to ignore cached data.\n\n    Returns:\n        dict: The fetched data\n\n    Raises:\n        ValueError: If the URL is invalid or the data cannot be fetched\n    \"\"\"\n    if not url or url is None or not isinstance(url, str):\n        raise ValueError(\"Invalid URL\")\n\n    filename = CACHE_DIR + \"/\" + url.replace(\"/\", \"_\") + \".json\"\n\n    # check if data is cached\n    if os.path.isfile(filename) and not forceFresh:\n        with open(filename, \"r\") as f:  # load from cache\n            result = json.load(f)  # get JSON\n            if result is not None and isinstance(\n                result, dict\n            ):  # check if JSON is valid\n                logger.info(f\"Using cached data for {url}\")\n                return result  # return cached data\n\n    try:\n        logger.debug(f\"Fetching {url}\")\n        async with aiohttp.ClientSession() as session:  # create a new session\n            async with session.get(url) as response:  # fetch data\n                if response.status == 200:  # check if the response is OK\n                    with open(filename, \"w\") as c:  # save to cache\n                        json.dump(await response.json(), c)\n                    return await response.json()  # return fetched data\n                else:  # if the response is not OK raise an error\n                    logger.error(f\"Failed to fetch {url}: {response.status}\", response)\n                    raise ValueError(\n                        f\"Failed to fetch {url}: {response.status}\",\n                        response,\n                        datetime.now().isoformat(),\n                    )\n    except Exception as e:  # if an error occurs raise an error\n        print(f\"Error fetching {url}: {str(e)}\")\n        raise ValueError(str(e), url, datetime.now().isoformat())\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/utils/#nmr_FAIR_DOs.utils.fetch_multiple","title":"fetch_multiple  <code>async</code>","text":"<pre><code>fetch_multiple(\n    urls: list[str], forceFresh: bool = False\n) -&gt; list[dict]\n</code></pre> <p>Fetches data from multiple URLs. This function is a wrapper around fetch_data that fetches data from multiple URLs concurrently.</p> <p>Parameters:</p> Name Type Description Default <code>urls</code> <code>List[str]</code> <p>A list of URLs to fetch data from</p> required <code>forceFresh</code> <code>bool</code> <p>Whether to force fetching fresh data. This tells the function to ignore cached data.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>List[dict]: A list of fetched data</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the URLs are invalid or the data cannot be fetched</p> Source code in <code>src/nmr_FAIR_DOs/utils.py</code> <pre><code>async def fetch_multiple(urls: list[str], forceFresh: bool = False) -&gt; list[dict]:\n    \"\"\"\n    Fetches data from multiple URLs.\n    This function is a wrapper around fetch_data that fetches data from multiple URLs concurrently.\n\n    Args:\n        urls (List[str]): A list of URLs to fetch data from\n        forceFresh (bool): Whether to force fetching fresh data. This tells the function to ignore cached data.\n\n    Returns:\n        List[dict]: A list of fetched data\n\n    Raises:\n        ValueError: If the URLs are invalid or the data cannot be fetched\n    \"\"\"\n    if not urls or urls is None or not isinstance(urls, list):\n        raise ValueError(\"Invalid URLs. Please provide a list of URLs.\")\n\n    num_concurrent_requests = 100  # number of concurrent requests\n    connector = aiohttp.TCPConnector(\n        limit=num_concurrent_requests\n    )  # create a new connector\n    async with aiohttp.ClientSession(connector=connector):\n        results = []\n        for i in range(\n            0, len(urls), num_concurrent_requests\n        ):  # iterate over the URLs in batches\n            batch = urls[i : i + num_concurrent_requests]  # get the current batch\n            tasks = [\n                asyncio.create_task(fetch_data(url, forceFresh)) for url in batch\n            ]  # create tasks for each URL in the batch\n            results.extend(\n                await asyncio.gather(*tasks)\n            )  # close the tasks and add the results to the list\n        return results\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/utils/#nmr_FAIR_DOs.utils.encodeInBase64","title":"encodeInBase64","text":"<pre><code>encodeInBase64(data: str) -&gt; str\n</code></pre> <p>Encodes the given data in Base64.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>str</code> <p>The data to encode</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The Base64 encoded data</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the data is None or empty</p> Source code in <code>src/nmr_FAIR_DOs/utils.py</code> <pre><code>def encodeInBase64(data: str) -&gt; str:\n    \"\"\"\n    Encodes the given data in Base64.\n\n    Args:\n        data (str): The data to encode\n\n    Returns:\n        str: The Base64 encoded data\n\n    Raises:\n        ValueError: If the data is None or empty\n    \"\"\"\n    if data is None or len(data) == 0:\n        raise ValueError(\"Data must not be None or empty\")\n\n    result = base64.b64encode(bytes(data, \"utf-8\")).decode(\"utf-8\")\n    return result\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/utils/#nmr_FAIR_DOs.utils.decodeFromBase64","title":"decodeFromBase64","text":"<pre><code>decodeFromBase64(data: str) -&gt; str\n</code></pre> <p>Decodes the given Base64 encoded data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>str</code> <p>The Base64 encoded data to decode</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The decoded data</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the data is None or empty</p> Source code in <code>src/nmr_FAIR_DOs/utils.py</code> <pre><code>def decodeFromBase64(data: str) -&gt; str:\n    \"\"\"\n    Decodes the given Base64 encoded data.\n\n    Args:\n        data (str): The Base64 encoded data to decode\n\n    Returns:\n        str: The decoded data\n\n    Raises:\n        ValueError: If the data is None or empty\n    \"\"\"\n    if data is None or len(data) == 0:\n        raise ValueError(\"Data must not be None or empty\")\n\n    result = base64.b64decode(data).decode(\"utf-8\")\n    return result\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/utils/#nmr_FAIR_DOs.utils.parseDateTime","title":"parseDateTime","text":"<pre><code>parseDateTime(text: str) -&gt; datetime\n</code></pre> <p>Parses a datetime from an arbitrary string.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The string to parse</p> required <p>Returns:</p> Name Type Description <code>datetime</code> <code>datetime</code> <p>The parsed datetime</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the text is None or empty or the datetime cannot be parsed</p> Source code in <code>src/nmr_FAIR_DOs/utils.py</code> <pre><code>def parseDateTime(text: str) -&gt; datetime:\n    \"\"\"\n    Parses a datetime from an arbitrary string.\n\n    Args:\n        text (str): The string to parse\n\n    Returns:\n        datetime: The parsed datetime\n\n    Raises:\n        ValueError: If the text is None or empty or the datetime cannot be parsed\n    \"\"\"\n    if text is None or len(text) == 0:  # check if the text is empty\n        raise ValueError(\"Text must not be None or empty\")\n\n    try:\n        return datetime.fromisoformat(text)\n    except ValueError:\n        pass\n\n    try:\n        return datetime.strptime(text, \"%Y-%m-%d %H:%M:%S\")\n    except ValueError:\n        pass\n\n    try:\n        return datetime.strptime(text, \"%Y-%m-%d\")\n    except ValueError:\n        pass\n\n    try:\n        return datetime.strptime(text, \"%Y-%m-%dT%H:%M:%S\")\n    except ValueError:\n        pass\n\n    try:\n        return datetime.strptime(text, \"%Y-%m-%dT%H:%M:%S.%f\")\n    except ValueError:\n        pass\n\n    raise ValueError(\"Could not parse datetime from text \" + text)\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/utils/#nmr_FAIR_DOs.utils.parseSPDXLicenseURL","title":"parseSPDXLicenseURL  <code>async</code>","text":"<pre><code>parseSPDXLicenseURL(input_str: str) -&gt; str\n</code></pre> <p>This function takes a string input and searches for a matching SPDX license URL.</p> <p>Parameters:</p> Name Type Description Default <code>input_str</code> <code>str</code> <p>The input string to search for. This can be a license name, SPDX ID, URL, etc.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The SPDX license URL</p> Source code in <code>src/nmr_FAIR_DOs/utils.py</code> <pre><code>async def parseSPDXLicenseURL(input_str: str) -&gt; str:\n    \"\"\"\n    This function takes a string input and searches for a matching SPDX license URL.\n\n    Args:\n        input_str (str): The input string to search for. This can be a license name, SPDX ID, URL, etc.\n\n    Returns:\n        str: The SPDX license URL\n    \"\"\"\n    spdx_base_url = \"https://spdx.org/licenses\"\n    file_format = \"json\"\n\n    if input_str in known_licenses:  # check if the input string is already known\n        logger.debug(\n            f\"Using cached available_license URL for {input_str}: {known_licenses[input_str]}\"\n        )\n        return known_licenses[input_str]\n\n    # Fetch the list of licenses once\n    available_licenses = await fetch_data(\n        f\"{spdx_base_url}/licenses.json\"\n    )  # fetch the list of licenses\n    available_licenses = available_licenses[\"licenses\"]\n\n    for available_license in available_licenses:  # iterate over the licenses\n        url = f\"{spdx_base_url}/{available_license['licenseId']}.{file_format}\"  # create the URL\n\n        if (\n            \"reference\" in available_license\n            and input_str.lower() == available_license[\"reference\"].lower()\n        ):  # check if the input string is the reference (e.g. https://spdx.org/licenses/MIT.html)\n            known_licenses[input_str] = url\n            return url\n        elif (\n            \"details\" in available_license\n            and input_str.lower() in available_license[\"details\"].lower()\n        ):  # check if the input string is in the details (e.g. https://spdx.org/licenses/MIT.json)\n            known_licenses[input_str] = url\n            return url\n        elif (\n            \"licenseId\" in available_license\n            and input_str.lower() == available_license[\"licenseId\"].lower()\n        ):  # check if the input string is the available_license ID (e.g. MIT)\n            known_licenses[input_str] = url\n            return url\n        elif (\n            \"seeAlso\" in available_license\n            and checkTextIsSimilar(input_str, available_license[\"seeAlso\"])\n        ):  # check if the input string is in the seeAlso list (e.g. [https://opensource.org/license/mit/])\n            known_licenses[input_str] = url\n            return url\n        elif \"name\" in available_license and checkTextIsSimilar(\n            input_str, available_license[\"name\"]\n        ):  # check if the input string is in the name (e.g. MIT License)\n            known_licenses[input_str] = url\n            return url\n        elif \"referenceNumber\" in available_license and input_str == str(\n            available_license[\"referenceNumber\"]\n        ):  # check if the input string is the reference number (e.g. 1)\n            known_licenses[input_str] = url\n            return url\n\n    logger.warning(f\"Could not parse available_license URL {input_str}\")\n    return input_str  # return the input string if no match was found\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/utils/#nmr_FAIR_DOs.utils.checkTextIsSimilar","title":"checkTextIsSimilar","text":"<pre><code>checkTextIsSimilar(\n    original: str, target: list[str] | str\n) -&gt; bool\n</code></pre> <p>Checks if the original text is similar to the target text.</p> <p>Parameters:</p> Name Type Description Default <code>original</code> <code>str</code> <p>The original text</p> required <code>target</code> <code>list[str] | str</code> <p>The target text or a list of target texts</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Whether the original text is similar to the target text</p> Source code in <code>src/nmr_FAIR_DOs/utils.py</code> <pre><code>def checkTextIsSimilar(original: str, target: list[str] | str) -&gt; bool:\n    \"\"\"\n    Checks if the original text is similar to the target text.\n\n    Args:\n        original (str): The original text\n        target (list[str]|str): The target text or a list of target texts\n\n    Returns:\n        bool: Whether the original text is similar to the target text\n    \"\"\"\n    if isinstance(target, str):\n        target = [target]\n\n    for t in target:\n        # Remove case sensitivity\n        original = original.lower()\n        t = t.lower()\n\n        # remove whitespaces and prefixes from URLs\n        original = original.replace(\" \", \"\")\n        t = t.replace(\" \", \"\")\n        original = original.replace(\"https://\", \"\")\n        t = t.replace(\"https://\", \"\")\n        original = original.replace(\"http://\", \"\")\n        t = t.replace(\"http://\", \"\")\n        original = original.replace(\"www.\", \"\")\n        t = t.replace(\"www.\", \"\")\n        original = original.replace(\"legalcode\", \"\")\n        t = t.replace(\"legalcode\", \"\")\n\n        # remove file extensions\n        original = original.replace(\".json\", \"\")\n        t = t.replace(\".json\", \"\")\n        original = original.replace(\".html\", \"\")\n        t = t.replace(\".html\", \"\")\n        original = original.replace(\".txt\", \"\")\n        t = t.replace(\".txt\", \"\")\n        original = original.replace(\".md\", \"\")\n        t = t.replace(\".md\", \"\")\n        original = original.replace(\".xml\", \"\")\n        t = t.replace(\".xml\", \"\")\n        original = original.replace(\".rdf\", \"\")\n        t = t.replace(\".rdf\", \"\")\n\n        # replace licenses with license to match SPDX URLs (e.g. https://opensource.org/licenses/MIT)\n        original = original.replace(\"licenses\", \"license\")\n        t = t.replace(\"licenses\", \"license\")\n\n        # if there is a slash at the end of the URL, remove it\n        if original.endswith(\"/\"):\n            original = original[:-1]\n        if t.endswith(\"/\"):\n            t = t[:-1]\n\n        if original == t:  # check if the strings are equal\n            logger.debug(f\"Found similar text: {original} == {t}\")\n            return True\n\n    return False\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/connectors/","title":"connectors","text":"<p>This module contains the connectors of the nmr_FAIR_DOs package.</p> <ul> <li><code>nmr_FAIR_DOs.connectors.TPMConnector</code>: This class is a connector to the Typed PID Maker API.</li> <li><code>nmr_FAIR_DOs.connectors.ElasticsearchConnector</code>: This class is a connector to the Elasticsearch API.</li> <li><code>nmr_FAIR_DOs.connectors.Terminology</code>: This class is a connector to the Terminology API.</li> </ul>"},{"location":"reference/nmr_FAIR_DOs/connectors/elasticsearch/","title":"elasticsearch","text":"<p>This module provides a connector to an Elasticsearch instance to store and retrieve FAIR-DOs.</p>"},{"location":"reference/nmr_FAIR_DOs/connectors/elasticsearch/#nmr_FAIR_DOs.connectors.elasticsearch.ElasticsearchConnector","title":"ElasticsearchConnector","text":"<p>This class provides a connector to an Elasticsearch instance to store and retrieve FAIR-DOs.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>The URL of the Elasticsearch instance</p> <code>apikey</code> <code>str</code> <p>The API key to access the Elasticsearch instance</p> <code>indexName</code> <code>str</code> <p>The name of the index to use</p> Source code in <code>src/nmr_FAIR_DOs/connectors/elasticsearch.py</code> <pre><code>class ElasticsearchConnector:\n    \"\"\"\n    This class provides a connector to an Elasticsearch instance to store and retrieve FAIR-DOs.\n\n    Attributes:\n        url (str): The URL of the Elasticsearch instance\n        apikey (str): The API key to access the Elasticsearch instance\n        indexName (str): The name of the index to use\n    \"\"\"\n\n    def __init__(self, url: str, apikey: str, indexName: str):\n        \"\"\"\n        Creates an Elasticsearch connector\n\n        Args:\n            url (str): The URL of the Elasticsearch instance\n            apikey (str): The API key to access the Elasticsearch instance\n            indexName (str): The name of the index to use\n        \"\"\"\n\n        if not url or url == \"\":  # if the URL is None, raise an error\n            raise ValueError(\"URL must not be None or empty\")\n        if (\n            not indexName or indexName == \"\"\n        ):  # if the index name is None, raise an error\n            raise ValueError(\"Index name must not be None or empty\")\n\n        self._url = url\n        self._apikey = apikey\n        self._indexName = indexName\n\n        self._client = Elasticsearch(\n            hosts=self._url, api_key=self._apikey\n        )  # create the Elasticsearch client\n\n        logger.info(f\"Connected to Elasticsearch: {self._client.info()}\")\n\n        # Check if the client is connected\n        if not self._client.ping():\n            raise Exception(\"Could not connect to Elasticsearch\")\n\n        # Create the index if it does not exist\n        if self._client.indices.exists(index=indexName):\n            logger.info(\"Index \" + indexName + \" already exists\")\n        else:  # if the index does not exist, create it\n            self._client.indices.create(index=indexName)\n            logger.info(\"Created index \" + indexName)\n\n    async def addPIDRecord(self, pidRecord: PIDRecord):\n        \"\"\"\n        Adds a PID record to the Elasticsearch index.\n\n        Args:\n            pidRecord (PIDRecord): The PID record to add to the Elasticsearch index.\n        \"\"\"\n        result = await _generate_elastic_JSON_from_PIDRecord(\n            pidRecord\n        )  # generate the JSON object from the PID record\n\n        response = self._client.index(\n            index=self._indexName, id=result[\"pid\"], document=result\n        )  # store the JSON object in the Elasticsearch index\n\n        if response.meta.status not in [\n            200,\n            201,\n        ]:  # if the response status is not 200 or 201, log an error\n            logger.error(\n                \"Error storing FAIR-DO in elasticsearch index: \" + result[\"pid\"],\n                result,\n                response,\n            )\n\n        logger.info(\n            \"Stored FAIR-DO in elasticsearch index: \" + result[\"pid\"], result, response\n        )\n\n    async def addPIDRecords(self, pidRecords: list[PIDRecord]):\n        \"\"\"\n        Adds a list of PID records to the Elasticsearch index.\n        This method uses the bulk API of Elasticsearch to store the PID records more efficiently.\n\n        Args:\n            pidRecords (list[PIDRecord]): The list of PID records to add to the Elasticsearch index.\n\n        Raises:\n            Exception: If the response status is not 200 or 201.\n        \"\"\"\n        # Generate the JSON objects from the PID records\n        actions = [\n            {\n                \"_op_type\": \"create\",\n                \"_index\": self._indexName,\n                \"_id\": pidRecord.getPID(),\n                \"_source\": await _generate_elastic_JSON_from_PIDRecord(pidRecord),\n                # generate the JSON object from the PID record\n            }\n            for pidRecord in pidRecords  # iterate over the PID records\n        ]\n\n        response = bulk(\n            self._client, actions\n        )  # store the JSON objects in the Elasticsearch index\n        logger.debug(\n            \"Elasticsearch response for bulk insert of PID records: \", response\n        )\n\n    def searchForPID(self, presumedPID: str) -&gt; str:\n        \"\"\"\n        Searches for a PID in the Elasticsearch index.\n        If a record with the PID or the digitalObjectLocation equal to the presumed PID is found, the PID is returned.\n\n        Args:\n            presumedPID (str): The PID to search for.\n\n        Returns:\n            str: The PID of the found record.\n\n        Raises:\n            Exception: If the response status is not 200.\n            Exception: If no record with the PID or the digitalObjectLocation equal to the presumed PID is found.\n            Exception: If the PID of the found record does not match the presumed PID.\n        \"\"\"\n        response = self._client.search(  # search for the PID in the Elasticsearch index\n            index=self._indexName,\n            body={\n                \"query\": {\n                    \"multi_match\": {\n                        \"type\": \"best_fields\",\n                        \"query\": presumedPID,  # search for the presumed PID\n                        \"fields\": [\"digitalObjectLocation\", \"pid\"],\n                        # search in the digitalObjectLocation and the pid fields\n                    }\n                }\n            },\n        )\n\n        logger.debug(\n            \"Elasticsearch response for search query: \" + presumedPID, response\n        )\n\n        if (\n            response.meta.status != 200\n        ):  # if the response status is not 200, log an error and raise an exception\n            logger.error(\n                \"Error retrieving FAIR-DO from elasticsearch index: \" + presumedPID,\n                response,\n            )\n            raise Exception(\n                \"Error retrieving FAIR-DO from elasticsearch index: \" + presumedPID,\n                response,\n            )\n\n        result = (  # get the result from the response\n            response[\"hits\"][\"hits\"][0][\n                \"_source\"\n            ]  # get the source of the first hit in the response if it exists\n            if response[\"hits\"][\"total\"][\"value\"] &gt; 0\n            else None  # if no hit exists, set the result to None\n        )\n\n        if result is None:  # if no result is found, log an error and raise an exception\n            logger.warning(\n                \"No FAIR-DO found in elasticsearch index: \" + presumedPID, response\n            )\n            raise Exception(\n                \"No FAIR-DO found in elasticsearch index: \" + presumedPID, response\n            )\n        elif (\n            result[\"pid\"] != presumedPID\n            and result[\"digitalObjectLocation\"] != presumedPID\n        ):  # if the PID of the found record does not match the presumed PID, log an error and raise an exception\n            logger.warning(\n                \"PID of retrieved FAIR-DO does not match requested PID: \" + presumedPID,\n                result,\n            )\n            raise Exception(\n                \"PID of retrieved FAIR-DO does not match requested PID: \" + presumedPID,\n                result,\n            )\n\n        pid = result[\"pid\"]  # get the PID from the result\n        logger.info(\n            \"Retrieved possible FAIRDO from elasticsearch index: \" + pid, result\n        )\n\n        return pid  # return the PID\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/connectors/elasticsearch/#nmr_FAIR_DOs.connectors.elasticsearch.ElasticsearchConnector.__init__","title":"__init__","text":"<pre><code>__init__(url: str, apikey: str, indexName: str)\n</code></pre> <p>Creates an Elasticsearch connector</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL of the Elasticsearch instance</p> required <code>apikey</code> <code>str</code> <p>The API key to access the Elasticsearch instance</p> required <code>indexName</code> <code>str</code> <p>The name of the index to use</p> required Source code in <code>src/nmr_FAIR_DOs/connectors/elasticsearch.py</code> <pre><code>def __init__(self, url: str, apikey: str, indexName: str):\n    \"\"\"\n    Creates an Elasticsearch connector\n\n    Args:\n        url (str): The URL of the Elasticsearch instance\n        apikey (str): The API key to access the Elasticsearch instance\n        indexName (str): The name of the index to use\n    \"\"\"\n\n    if not url or url == \"\":  # if the URL is None, raise an error\n        raise ValueError(\"URL must not be None or empty\")\n    if (\n        not indexName or indexName == \"\"\n    ):  # if the index name is None, raise an error\n        raise ValueError(\"Index name must not be None or empty\")\n\n    self._url = url\n    self._apikey = apikey\n    self._indexName = indexName\n\n    self._client = Elasticsearch(\n        hosts=self._url, api_key=self._apikey\n    )  # create the Elasticsearch client\n\n    logger.info(f\"Connected to Elasticsearch: {self._client.info()}\")\n\n    # Check if the client is connected\n    if not self._client.ping():\n        raise Exception(\"Could not connect to Elasticsearch\")\n\n    # Create the index if it does not exist\n    if self._client.indices.exists(index=indexName):\n        logger.info(\"Index \" + indexName + \" already exists\")\n    else:  # if the index does not exist, create it\n        self._client.indices.create(index=indexName)\n        logger.info(\"Created index \" + indexName)\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/connectors/elasticsearch/#nmr_FAIR_DOs.connectors.elasticsearch.ElasticsearchConnector.addPIDRecord","title":"addPIDRecord  <code>async</code>","text":"<pre><code>addPIDRecord(pidRecord: PIDRecord)\n</code></pre> <p>Adds a PID record to the Elasticsearch index.</p> <p>Parameters:</p> Name Type Description Default <code>pidRecord</code> <code>PIDRecord</code> <p>The PID record to add to the Elasticsearch index.</p> required Source code in <code>src/nmr_FAIR_DOs/connectors/elasticsearch.py</code> <pre><code>async def addPIDRecord(self, pidRecord: PIDRecord):\n    \"\"\"\n    Adds a PID record to the Elasticsearch index.\n\n    Args:\n        pidRecord (PIDRecord): The PID record to add to the Elasticsearch index.\n    \"\"\"\n    result = await _generate_elastic_JSON_from_PIDRecord(\n        pidRecord\n    )  # generate the JSON object from the PID record\n\n    response = self._client.index(\n        index=self._indexName, id=result[\"pid\"], document=result\n    )  # store the JSON object in the Elasticsearch index\n\n    if response.meta.status not in [\n        200,\n        201,\n    ]:  # if the response status is not 200 or 201, log an error\n        logger.error(\n            \"Error storing FAIR-DO in elasticsearch index: \" + result[\"pid\"],\n            result,\n            response,\n        )\n\n    logger.info(\n        \"Stored FAIR-DO in elasticsearch index: \" + result[\"pid\"], result, response\n    )\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/connectors/elasticsearch/#nmr_FAIR_DOs.connectors.elasticsearch.ElasticsearchConnector.addPIDRecords","title":"addPIDRecords  <code>async</code>","text":"<pre><code>addPIDRecords(pidRecords: list[PIDRecord])\n</code></pre> <p>Adds a list of PID records to the Elasticsearch index. This method uses the bulk API of Elasticsearch to store the PID records more efficiently.</p> <p>Parameters:</p> Name Type Description Default <code>pidRecords</code> <code>list[PIDRecord]</code> <p>The list of PID records to add to the Elasticsearch index.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If the response status is not 200 or 201.</p> Source code in <code>src/nmr_FAIR_DOs/connectors/elasticsearch.py</code> <pre><code>async def addPIDRecords(self, pidRecords: list[PIDRecord]):\n    \"\"\"\n    Adds a list of PID records to the Elasticsearch index.\n    This method uses the bulk API of Elasticsearch to store the PID records more efficiently.\n\n    Args:\n        pidRecords (list[PIDRecord]): The list of PID records to add to the Elasticsearch index.\n\n    Raises:\n        Exception: If the response status is not 200 or 201.\n    \"\"\"\n    # Generate the JSON objects from the PID records\n    actions = [\n        {\n            \"_op_type\": \"create\",\n            \"_index\": self._indexName,\n            \"_id\": pidRecord.getPID(),\n            \"_source\": await _generate_elastic_JSON_from_PIDRecord(pidRecord),\n            # generate the JSON object from the PID record\n        }\n        for pidRecord in pidRecords  # iterate over the PID records\n    ]\n\n    response = bulk(\n        self._client, actions\n    )  # store the JSON objects in the Elasticsearch index\n    logger.debug(\n        \"Elasticsearch response for bulk insert of PID records: \", response\n    )\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/connectors/elasticsearch/#nmr_FAIR_DOs.connectors.elasticsearch.ElasticsearchConnector.searchForPID","title":"searchForPID","text":"<pre><code>searchForPID(presumedPID: str) -&gt; str\n</code></pre> <p>Searches for a PID in the Elasticsearch index. If a record with the PID or the digitalObjectLocation equal to the presumed PID is found, the PID is returned.</p> <p>Parameters:</p> Name Type Description Default <code>presumedPID</code> <code>str</code> <p>The PID to search for.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The PID of the found record.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the response status is not 200.</p> <code>Exception</code> <p>If no record with the PID or the digitalObjectLocation equal to the presumed PID is found.</p> <code>Exception</code> <p>If the PID of the found record does not match the presumed PID.</p> Source code in <code>src/nmr_FAIR_DOs/connectors/elasticsearch.py</code> <pre><code>def searchForPID(self, presumedPID: str) -&gt; str:\n    \"\"\"\n    Searches for a PID in the Elasticsearch index.\n    If a record with the PID or the digitalObjectLocation equal to the presumed PID is found, the PID is returned.\n\n    Args:\n        presumedPID (str): The PID to search for.\n\n    Returns:\n        str: The PID of the found record.\n\n    Raises:\n        Exception: If the response status is not 200.\n        Exception: If no record with the PID or the digitalObjectLocation equal to the presumed PID is found.\n        Exception: If the PID of the found record does not match the presumed PID.\n    \"\"\"\n    response = self._client.search(  # search for the PID in the Elasticsearch index\n        index=self._indexName,\n        body={\n            \"query\": {\n                \"multi_match\": {\n                    \"type\": \"best_fields\",\n                    \"query\": presumedPID,  # search for the presumed PID\n                    \"fields\": [\"digitalObjectLocation\", \"pid\"],\n                    # search in the digitalObjectLocation and the pid fields\n                }\n            }\n        },\n    )\n\n    logger.debug(\n        \"Elasticsearch response for search query: \" + presumedPID, response\n    )\n\n    if (\n        response.meta.status != 200\n    ):  # if the response status is not 200, log an error and raise an exception\n        logger.error(\n            \"Error retrieving FAIR-DO from elasticsearch index: \" + presumedPID,\n            response,\n        )\n        raise Exception(\n            \"Error retrieving FAIR-DO from elasticsearch index: \" + presumedPID,\n            response,\n        )\n\n    result = (  # get the result from the response\n        response[\"hits\"][\"hits\"][0][\n            \"_source\"\n        ]  # get the source of the first hit in the response if it exists\n        if response[\"hits\"][\"total\"][\"value\"] &gt; 0\n        else None  # if no hit exists, set the result to None\n    )\n\n    if result is None:  # if no result is found, log an error and raise an exception\n        logger.warning(\n            \"No FAIR-DO found in elasticsearch index: \" + presumedPID, response\n        )\n        raise Exception(\n            \"No FAIR-DO found in elasticsearch index: \" + presumedPID, response\n        )\n    elif (\n        result[\"pid\"] != presumedPID\n        and result[\"digitalObjectLocation\"] != presumedPID\n    ):  # if the PID of the found record does not match the presumed PID, log an error and raise an exception\n        logger.warning(\n            \"PID of retrieved FAIR-DO does not match requested PID: \" + presumedPID,\n            result,\n        )\n        raise Exception(\n            \"PID of retrieved FAIR-DO does not match requested PID: \" + presumedPID,\n            result,\n        )\n\n    pid = result[\"pid\"]  # get the PID from the result\n    logger.info(\n        \"Retrieved possible FAIRDO from elasticsearch index: \" + pid, result\n    )\n\n    return pid  # return the PID\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/connectors/terminology/","title":"terminology","text":""},{"location":"reference/nmr_FAIR_DOs/connectors/terminology/#nmr_FAIR_DOs.connectors.terminology.Terminology","title":"Terminology","text":"<p>This class interacts with an external terminology service to search for terms and validate them.</p> <p>Attributes:</p> Name Type Description <code>terminology_url</code> <p>str The base URL of the terminology service</p> <code>cache</code> <code>dict[str, str]</code> <p>dict[str, str] A cache to store already found terms</p> <code>validation_functions</code> <code>dict[str, Callable[[dict], bool]]</code> <p>dict[str, Callable[[dict], bool] A dictionary of validation functions for different ontologies</p> Source code in <code>src/nmr_FAIR_DOs/connectors/terminology.py</code> <pre><code>class Terminology:\n    \"\"\"\n    This class interacts with an external terminology service to search for terms and validate them.\n\n    Attributes:\n        terminology_url:str The base URL of the terminology service\n        cache:dict[str, str] A cache to store already found terms\n        validation_functions:dict[str, Callable[[dict], bool] A dictionary of validation functions for different ontologies\n    \"\"\"\n\n    # This list contains the terms that are already in the cache. The format is \"query\", \"IRI\". The provided entries were found by hand and are not guaranteed to be correct. Refer to https://www.sigmaaldrich.com/DE/de/technical-documents/technical-article/analytical-chemistry/nuclear-magnetic-resonance/nmr-deuterated-solvent-properties-reference\n    cache: dict[str, str] = {\n        \"DMSO\": \"http://purl.obolibrary.org/obo/CHEBI_193041\",\n        \"DMSO_D6\": \"http://purl.obolibrary.org/obo/CHEBI_193041\",\n        \"CDCL3\": \"http://purl.obolibrary.org/obo/CHEBI_85365\",\n        \"CHLOROFORM-D\": \"http://purl.obolibrary.org/obo/CHEBI_85365\",\n        \"Acetone\": \"http://purl.obolibrary.org/obo/CHEBI_78217\",\n        \"Aceton\": \"http://purl.obolibrary.org/obo/CHEBI_78217\",\n        \"MEOD\": \"http://purl.obolibrary.org/obo/CHEBI_156265\",\n        \"D2O\": \"http://purl.obolibrary.org/obo/CHEBI_41981\",\n        \"C6D6\": \"http://purl.obolibrary.org/obo/CHEBI_193039\",\n        \"CD3CN\": \"http://purl.obolibrary.org/obo/CHEBI_193038\",\n        \"THF\": \"http://purl.obolibrary.org/obo/CHEBI_193047\",\n        \"CD2Cl2\": \"http://purl.obolibrary.org/obo/CHEBI_193042\",\n        # \"MeOH\": \"http://purl.obolibrary.org/obo/CHEBI_17790\"\n        # \"Dioxane\": \"http://purl.obolibrary.org/obo/CHEBI_46923\"\n    }\n\n    # This dictionary contains the validation functions for different ontologies. The functions return True if the node is valid and False otherwise.\n    validation_functions: dict[str, Callable[[dict], bool]] = {\n        \"chebi\": lambda x: Terminology._validateCHEBI(x)\n    }\n\n    def __init__(self, terminology_url: str):\n        \"\"\"\n        Creates a Terminology object\n\n        Args:\n            terminology_url:str The URL of the terminology service\n\n        Raises:\n            ValueError: If the terminology URL is None or empty\n        \"\"\"\n        if terminology_url is None or terminology_url == \"\":\n            raise ValueError(\"Terminology URL must not be None or empty\")\n        self._terminology_url = terminology_url\n\n    async def searchForTerm(\n        self,\n        query: str,\n        ontology: str,\n        parent: str | None,\n        validateNode: Callable[[dict], bool] = None,\n    ) -&gt; str | None:\n        \"\"\"\n        Searches for a term in the terminology service. If multiple terms are found, a heuristic is used to find the best term. The best term is the one that is most likely to be the parent of the other terms found.\n\n        Args:\n            query:str The term to search for\n            ontology:str The name of the ontology to search in\n            parent:str The IRI of the parent term to search for\n            validateNode:Callable[[dict], bool] A function to validate the node found. Input is the entity from the terminology service (optional)\n\n        Returns:\n            str|None The IRI of the best term found or None if no term was found\n        \"\"\"\n        # Set the validation function to the one provided or the default one for the ontology. If the ontology is not in the list, use a lambda function that always returns True\n        validateNode = (\n            validateNode  # user provided function, if available\n            if validateNode is not None\n            else self.validation_functions[\n                ontology\n            ]  # function from the validation_functions dictionary\n            if ontology in self.validation_functions\n            else lambda x: True  # Default function that always returns True if no function is provided\n        )\n\n        logger.debug(\n            f\"Searching for term {query} in ontology {ontology} with parent {parent}\"\n        )\n\n        # Check if the term is already in the cache\n        if query in self.cache:\n            logger.debug(f\"Found term {query} in cache\")\n            return self.cache[query]  # Return the term from the cache\n\n        # use a URL template to replace the placeholders with the actual values\n        template = Template(\n            \"$terminology_url/api/search?q=$query&amp;ontology=$ontology&amp;option=COMPOSITE&amp;fieldList=iri%2Clabel%2Cshort_form%2Cobo_id%2Contology_name&amp;exact=true&amp;obsoletes=false&amp;local=true&amp;allChildrenOf=$parent&amp;rows=10&amp;start=0&amp;format=json&amp;lang=en\"\n        )\n        url = template.substitute(\n            terminology_url=self._terminology_url,\n            query=query,\n            ontology=ontology,\n            parent=parent.replace(\":\", \"%3A\").replace(\n                \"/\", \"%2F\"\n            )  # Replace : and / in the parent IRI\n            if parent is not None\n            else \"\",\n        )\n        logger.debug(f\"URL: {url}\")\n        response = requests.get(url)  # Send the request to the terminology service\n\n        json = None  # JSON response from the terminology service\n        if response.status_code == 200:  # Check if the request was successful\n            json = response.json()\n        else:  # If the request was not successful, log an error and raise an exception\n            logger.error(f\"Error: {response.status_code} - {response.text}\")\n            raise Exception(f\"Error: {response.status_code} - {response.text}\")\n\n        entities = []  # List of entities found\n        if (\n            \"response\" not in json\n            or \"docs\" not in json[\"response\"]\n            or len(json[\"response\"][\"docs\"]) == 0\n        ):  # Check if any entities were found in the search results. If not, log an error and return None\n            logger.error(\n                f\"No results found for query {query} in ontology {ontology} with parent {parent}\"\n            )\n            return None\n        else:  # If entities were found, check if they are valid and add them to the list of entities found\n            for doc in json[\"response\"][\"docs\"]:  # Iterate over the entities found\n                iri = doc[\"iri\"]  # Get the IRI of the entity\n                entity = await self._getEntity(\n                    ontology, iri\n                )  # Get more information about the entity from the terminology service\n\n                if entity is not None and validateNode(\n                    entity\n                ):  # Check if the entity is valid\n                    entities.append(iri)  # Add the IRI to the list of entities found\n                else:  # If the entity is not valid, log a warning\n                    logger.info(f\"Entity {iri} is not valid and will be ignored\")\n\n        if len(entities) == 1:  # If only one entity was found, return it\n            logger.info(f\"Found single result: {entities[0]}\")\n            self.cache[query] = entities[0]  # Add the entity to the cache\n            return entities[0]  # Return the entity\n\n        # If multiple entities were found, find the parent of the entities\n        result = await self._findParent(\n            ontology, entities\n        )  # Find the parent of the entities in the search\n        if result is None:  # If no parent was found, log an error and return None\n            logger.error(\n                f\"No parent found for entities {entities} in ontology {ontology}\"\n            )\n            return None\n        else:  # If a parent was found, log the result and return it\n            logger.info(f\"Found result to search: {result}\")\n            self.cache[query] = result  # Add the result to the cache\n            return result  # Return the result\n\n    async def _getEntity(self, ontology: str, iri: str) -&gt; dict | None:\n        \"\"\"\n        Gets an entity from the terminology service\n\n        Args:\n            ontology:str The ontology to get the entity from\n            iri:str The IRI of the entity to get\n\n        Returns:\n            dict|None The response from the terminology service. If the entity was not found, return None\n        \"\"\"\n\n        logger.debug(f\"Getting entity {iri} from ontology {ontology}\")\n\n        iri = iri.replace(\":\", \"%253A\").replace(\n            \"/\", \"%252F\"\n        )  # Replace the : and / in the IRI\n        url = f\"{self._terminology_url}/api/v2/ontologies/{ontology}/entities/{iri}\"\n\n        response = requests.get(url)  # Send the request to the terminology service\n\n        if response.status_code == 200:  # Check if the request was successful\n            return response.json()\n        else:  # If the request was not successful, log an error and raise an exception\n            logger.error(f\"Error: {response.status_code} - {response.text}\")\n            raise Exception(f\"Error: {response.status_code} - {response.text}\")\n\n    async def _getChildren(self, ontology: str, entity_iri: str) -&gt; list[str]:\n        \"\"\"\n        Gets the children of an entity from the terminology service\n\n        Args:\n            ontology:str The ontology to get the children from\n            entity_iri:str The IRI of the entity to get the children of\n\n        Returns:\n            list[str] The response from the terminology service. A list of IRIs of the children of the entity\n        \"\"\"\n        logger.debug(\n            f\"Getting children of entity {entity_iri} from ontology {ontology}\"\n        )\n\n        entity_iri = entity_iri.replace(\":\", \"%253A\").replace(\n            \"/\", \"%252F\"\n        )  # Replace the : and / in the IRI\n        url = f\"{self._terminology_url}/api/ontologies/{ontology}/terms/{entity_iri}/hierarchicalChildren?lang=en\"\n\n        logger.debug(f\"Getting children from URL {url}\")\n        response = requests.get(url)  # Send the request to the terminology service\n\n        children: list[str] = []\n        if response.status_code == 200:  # Check if the request was successful\n            json = response.json()\n\n            if (\n                \"_embedded\" not in json or \"terms\" not in json[\"_embedded\"]\n            ):  # Check if any children were found\n                logger.error(\n                    f\"No children found for entity {entity_iri} from ontology {ontology}\"\n                )\n                return children\n            else:  # If children were found, add them to the list of children\n                for term in json[\"_embedded\"][\n                    \"terms\"\n                ]:  # Iterate over the children found\n                    children.append(term[\"iri\"])  # Add the IRI to the list of children\n\n        logger.debug(\n            f\"Found {len(children)} children for entity {entity_iri} from ontology {ontology}\"\n        )\n        return children  # Return the list of children\n\n    async def _findParent(self, ontology: str, entities: list[str]) -&gt; str | None:\n        \"\"\"\n        Finds the parent of a list of entities in the terminology service\n\n        Args:\n            ontology:str The ontology to search in\n            entities:list[str] The entities to search for\n\n        Returns:\n            str|None The parent entity of the entities\n        \"\"\"\n        logger.debug(f\"Finding parent of entities {entities} in ontology {ontology}\")\n\n        if (\n            len(entities) == 0\n        ):  # Check if there are any entities to search for in the ontology and return None if there are none\n            logger.error(f\"No entities to search for in ontology {ontology}\")\n            return None\n\n        # Get the children of each entity\n        children = {}\n        for entity in entities:  # Iterate over the entities\n            children[entity] = await self._getChildren(\n                ontology, entity\n            )  # Get the children of the entity\n\n        # Check if one of the entities is the parent of one of the others\n        for entity in entities:  # Iterate over the entities\n            for child in children[entity]:  # Iterate over the children of the entity\n                if child in entities:  # Check if the child is one of the entities\n                    logger.debug(f\"Found parent {entity} of child {child}\")\n                    return entity  # Return the parent\n        logger.info(f\"No parent found for entities {entities} in ontology {ontology}\")\n\n        # Check for entity with the most children\n        max_children = 0\n        parent = None\n        for entity in entities:  # Iterate over the entities\n            if (\n                len(children[entity]) &gt; max_children\n            ):  # Check if the entity has more children than the current maximum\n                max_children = len(\n                    children[entity]\n                )  # Update the maximum number of children\n                parent = entity  # Update the parent\n        if parent is not None:  # Check if a parent was found\n            logger.debug(f\"Found {parent} with {max_children} children\")\n            return parent  # Return the parent\n        else:  # If no parent was found, log an error and return None\n            logger.error(\n                f\"No parent found for entities {entities} in ontology {ontology}\"\n            )\n            return None\n\n    @staticmethod\n    def _validateCHEBI(node: dict) -&gt; bool:\n        \"\"\"\n        Validates that a term in the CHEBI ontology is an atom or has some chemical properties.\n\n        Args:\n            node:dict The node to validate (entity from the terminology service)\n\n        Returns:\n            bool True if the node is a valid chemical entity, False otherwise\n        \"\"\"\n        if \"http://purl.obolibrary.org/obo/chebi/inchikey\" in node:\n            return True\n        elif \"http://purl.obolibrary.org/obo/chebi/smiles\" in node:\n            return True\n        elif \"http://purl.obolibrary.org/obo/chebi/inchi\" in node:\n            return True\n        elif \"http://purl.obolibrary.org/obo/chebi/mass\" in node:\n            return True\n        elif \"http://purl.obolibrary.org/obo/chebi/formula\" in node:\n            return True\n        return False\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/connectors/terminology/#nmr_FAIR_DOs.connectors.terminology.Terminology.__init__","title":"__init__","text":"<pre><code>__init__(terminology_url: str)\n</code></pre> <p>Creates a Terminology object</p> <p>Parameters:</p> Name Type Description Default <code>terminology_url</code> <code>str</code> <p>str The URL of the terminology service</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the terminology URL is None or empty</p> Source code in <code>src/nmr_FAIR_DOs/connectors/terminology.py</code> <pre><code>def __init__(self, terminology_url: str):\n    \"\"\"\n    Creates a Terminology object\n\n    Args:\n        terminology_url:str The URL of the terminology service\n\n    Raises:\n        ValueError: If the terminology URL is None or empty\n    \"\"\"\n    if terminology_url is None or terminology_url == \"\":\n        raise ValueError(\"Terminology URL must not be None or empty\")\n    self._terminology_url = terminology_url\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/connectors/terminology/#nmr_FAIR_DOs.connectors.terminology.Terminology.searchForTerm","title":"searchForTerm  <code>async</code>","text":"<pre><code>searchForTerm(\n    query: str,\n    ontology: str,\n    parent: str | None,\n    validateNode: Callable[[dict], bool] = None,\n) -&gt; str | None\n</code></pre> <p>Searches for a term in the terminology service. If multiple terms are found, a heuristic is used to find the best term. The best term is the one that is most likely to be the parent of the other terms found.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>str The term to search for</p> required <code>ontology</code> <code>str</code> <p>str The name of the ontology to search in</p> required <code>parent</code> <code>str | None</code> <p>str The IRI of the parent term to search for</p> required <code>validateNode</code> <code>Callable[[dict], bool]</code> <p>Callable[[dict], bool] A function to validate the node found. Input is the entity from the terminology service (optional)</p> <code>None</code> <p>Returns:</p> Type Description <code>str | None</code> <p>str|None The IRI of the best term found or None if no term was found</p> Source code in <code>src/nmr_FAIR_DOs/connectors/terminology.py</code> <pre><code>async def searchForTerm(\n    self,\n    query: str,\n    ontology: str,\n    parent: str | None,\n    validateNode: Callable[[dict], bool] = None,\n) -&gt; str | None:\n    \"\"\"\n    Searches for a term in the terminology service. If multiple terms are found, a heuristic is used to find the best term. The best term is the one that is most likely to be the parent of the other terms found.\n\n    Args:\n        query:str The term to search for\n        ontology:str The name of the ontology to search in\n        parent:str The IRI of the parent term to search for\n        validateNode:Callable[[dict], bool] A function to validate the node found. Input is the entity from the terminology service (optional)\n\n    Returns:\n        str|None The IRI of the best term found or None if no term was found\n    \"\"\"\n    # Set the validation function to the one provided or the default one for the ontology. If the ontology is not in the list, use a lambda function that always returns True\n    validateNode = (\n        validateNode  # user provided function, if available\n        if validateNode is not None\n        else self.validation_functions[\n            ontology\n        ]  # function from the validation_functions dictionary\n        if ontology in self.validation_functions\n        else lambda x: True  # Default function that always returns True if no function is provided\n    )\n\n    logger.debug(\n        f\"Searching for term {query} in ontology {ontology} with parent {parent}\"\n    )\n\n    # Check if the term is already in the cache\n    if query in self.cache:\n        logger.debug(f\"Found term {query} in cache\")\n        return self.cache[query]  # Return the term from the cache\n\n    # use a URL template to replace the placeholders with the actual values\n    template = Template(\n        \"$terminology_url/api/search?q=$query&amp;ontology=$ontology&amp;option=COMPOSITE&amp;fieldList=iri%2Clabel%2Cshort_form%2Cobo_id%2Contology_name&amp;exact=true&amp;obsoletes=false&amp;local=true&amp;allChildrenOf=$parent&amp;rows=10&amp;start=0&amp;format=json&amp;lang=en\"\n    )\n    url = template.substitute(\n        terminology_url=self._terminology_url,\n        query=query,\n        ontology=ontology,\n        parent=parent.replace(\":\", \"%3A\").replace(\n            \"/\", \"%2F\"\n        )  # Replace : and / in the parent IRI\n        if parent is not None\n        else \"\",\n    )\n    logger.debug(f\"URL: {url}\")\n    response = requests.get(url)  # Send the request to the terminology service\n\n    json = None  # JSON response from the terminology service\n    if response.status_code == 200:  # Check if the request was successful\n        json = response.json()\n    else:  # If the request was not successful, log an error and raise an exception\n        logger.error(f\"Error: {response.status_code} - {response.text}\")\n        raise Exception(f\"Error: {response.status_code} - {response.text}\")\n\n    entities = []  # List of entities found\n    if (\n        \"response\" not in json\n        or \"docs\" not in json[\"response\"]\n        or len(json[\"response\"][\"docs\"]) == 0\n    ):  # Check if any entities were found in the search results. If not, log an error and return None\n        logger.error(\n            f\"No results found for query {query} in ontology {ontology} with parent {parent}\"\n        )\n        return None\n    else:  # If entities were found, check if they are valid and add them to the list of entities found\n        for doc in json[\"response\"][\"docs\"]:  # Iterate over the entities found\n            iri = doc[\"iri\"]  # Get the IRI of the entity\n            entity = await self._getEntity(\n                ontology, iri\n            )  # Get more information about the entity from the terminology service\n\n            if entity is not None and validateNode(\n                entity\n            ):  # Check if the entity is valid\n                entities.append(iri)  # Add the IRI to the list of entities found\n            else:  # If the entity is not valid, log a warning\n                logger.info(f\"Entity {iri} is not valid and will be ignored\")\n\n    if len(entities) == 1:  # If only one entity was found, return it\n        logger.info(f\"Found single result: {entities[0]}\")\n        self.cache[query] = entities[0]  # Add the entity to the cache\n        return entities[0]  # Return the entity\n\n    # If multiple entities were found, find the parent of the entities\n    result = await self._findParent(\n        ontology, entities\n    )  # Find the parent of the entities in the search\n    if result is None:  # If no parent was found, log an error and return None\n        logger.error(\n            f\"No parent found for entities {entities} in ontology {ontology}\"\n        )\n        return None\n    else:  # If a parent was found, log the result and return it\n        logger.info(f\"Found result to search: {result}\")\n        self.cache[query] = result  # Add the result to the cache\n        return result  # Return the result\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/connectors/tpm_connector/","title":"tpm_connector","text":""},{"location":"reference/nmr_FAIR_DOs/connectors/tpm_connector/#nmr_FAIR_DOs.connectors.tpm_connector.TPMConnector","title":"TPMConnector","text":"<p>This class handles all communication with the Typed PID Maker (TPM) (see https://kit-data-manager.github.io/webpage/typed-pid-maker for more information). The Typed PID Maker is a service that allows the creation and management of FAIR-DOs (Findable, Accessible, Interoperable, Reusable Digital Objects). It communicates with the Handle.net service to create PIDs and stores PID records in a globally persistent manner.</p> <p>Attributes:</p> Name Type Description <code>_tpm_url</code> <p>str The URL of the Typed PID Maker instance</p> Source code in <code>src/nmr_FAIR_DOs/connectors/tpm_connector.py</code> <pre><code>class TPMConnector:\n    \"\"\"\n    This class handles all communication with the Typed PID Maker (TPM) (see https://kit-data-manager.github.io/webpage/typed-pid-maker for more information).\n    The Typed PID Maker is a service that allows the creation and management of FAIR-DOs (Findable, Accessible, Interoperable, Reusable Digital Objects).\n    It communicates with the Handle.net service to create PIDs and stores PID records in a globally persistent manner.\n\n    Attributes:\n        _tpm_url:str The URL of the Typed PID Maker instance\n    \"\"\"\n\n    def __init__(self, tpm_url: str):\n        \"\"\"\n        Creates a new TPMConnector\n\n        Args:\n            tpm_url:str The URL of the Typed PID Maker instance\n\n        Raises:\n            ValueError: If the TPM URL is None or empty\n        \"\"\"\n        if tpm_url is None or len(tpm_url) == 0:\n            raise ValueError(\"TPM URL must not be None or empty\")\n        self._tpm_url = tpm_url\n\n    def createSingleFAIRDO(self, pidRecord: PIDRecord) -&gt; PIDRecord:\n        \"\"\"\n        Creates a single FAIR-DO in the TPM\n\n        Args:\n            pidRecord:PIDRecord The FAIR-DO to create\n\n        Returns:\n            PIDRecord The response from the TPM. This response contains the PID and the PID record.\n        \"\"\"\n        logger.info(f\"Creating FAIR-DO {pidRecord.getPID()}\")\n\n        if pidRecord is None or not isinstance(\n            pidRecord, PIDRecord\n        ):  # if the PID record is None or not an instance of PIDRecord, raise an error\n            raise ValueError(\n                \"FAIR-DO must not be None and must be an instance of PIDRecord\"\n            )\n\n        headers = {\"Content-Type\": \"application/json\"}\n\n        # content = self._applyTypeAPIFixes(pidRecord.toJSON()) # Possible fix for Type API issues\n        content = pidRecord.toJSON()  # get the JSON representation of the PID record\n\n        endpoint = \"/api/v1/pit/pid\"\n\n        if (\n            content is None or len(content) == 0\n        ):  # if the content is None or empty, raise an error\n            raise ValueError(\"No content to create due to invalid input\")\n\n        resource_response = requests.post(\n            self._tpm_url + endpoint, headers=headers, json=content\n        )  # send a POST request to the TPM to create the PID record\n        logger.debug(f\"Response for URL {self._tpm_url + endpoint}\", resource_response)\n\n        if (\n            resource_response.status_code != 201\n        ):  # if the status code is not 201, raise an error\n            raise Exception(\"Error creating PID record: \", resource_response)\n\n        return PIDRecord.fromJSON(\n            resource_response.json()\n        )  # parse a PID record from the response JSON and return it\n\n    def createMultipleFAIRDOs(self, pidRecord: list[PIDRecord]) -&gt; list[PIDRecord]:\n        \"\"\"\n        Creates multiple FAIR-DOs in the TPM.\n        This function uses the bulk-create endpoint of the TPM to create multiple FAIR-DOs at once.\n        One advantage of using this endpoint is that it can create multiple connected FAIR-DOs in one request and automatically replaces \"placeholder\"/\"fantasy\"/\"preliminary\" PIDs in the records with the real deal.\n\n        Args:\n            pidRecord:list[PIDRecord] The FAIR-DOs to create\n\n        Returns:\n            list[PIDRecord] The response from the TPM which is a list of all created FAIR-DOs\n        \"\"\"\n        logger.info(f\"Creating {len(pidRecord)} FAIR-DOs\")\n\n        headers = {\"Content-Type\": \"application/json\"}\n\n        content = []\n\n        for fairdo in pidRecord:  # iterate over all PID records\n            if fairdo is None or not isinstance(\n                fairdo, PIDRecord\n            ):  # Check the validity or raise an exception\n                raise ValueError(\n                    \"FAIR-DO must not be None and must be an instance of PIDRecord\"\n                )\n\n            # content.append(self._applyTypeAPIFixes(fairdo.toJSON())) # Possible fix for Type API issues\n            content.append(fairdo.toJSON())  # Mark this record ready for creation\n\n        endpoint = \"/api/v1/pit/pids\"\n\n        if (\n            content is None or len(content) == 0\n        ):  # if the content is None or empty, raise an error\n            raise ValueError(\"No content to create due to invalid input\")\n\n        logger.debug(\n            f\"Creating FAIR-DOs at {self._tpm_url + endpoint} : {json.dumps(content)[:250]}\"\n        )\n        resource_response = requests.post(\n            self._tpm_url + endpoint, headers=headers, json=content, timeout=None\n        )  # send a POST request to the TPM to create the PID records\n\n        logger.debug(f\"Response for URL {self._tpm_url + endpoint}\", resource_response)\n\n        if (\n            resource_response.status_code != 201\n        ):  # if the status code is not 201, raise an error\n            raise Exception(\n                \"Error creating PID records. API response from TPM: \",\n                repr(resource_response),\n            )\n\n        result = []\n        for (\n            i\n        ) in resource_response.json():  # iterate over all PID records in the response\n            result.append(\n                PIDRecord.fromJSON(i)\n            )  # parse a PID record from the response JSON and add it to the result list\n\n        logger.info(\"Successfully created FAIR-DOs\")\n        return result  # return the list of all created PID records (with their actual PIDs)\n\n    def getPIDRecord(self, pid: str) -&gt; PIDRecord:\n        \"\"\"\n        Retrieves a PID record from the TPM\n\n        Args:\n            pid (str): The PID to retrieve\n\n        Returns:\n            PIDRecord: The PID record retrieved from the TPM\n\n        Raises:\n            ValueError: If the PID is None or empty\n            Exception: If the PID record cannot be retrieved\n        \"\"\"\n        if pid is None or len(pid) == 0:  # if the PID is None or empty, raise an error\n            raise ValueError(\"PID must not be None or empty\")\n\n        endpoint = \"/api/v1/pit/pid/\" + pid\n\n        resource_response = requests.get(\n            self._tpm_url + endpoint, headers={\"Accept\": \"application/json\"}\n        )  # send a GET request to the TPM to retrieve the PID record\n\n        if (\n            resource_response.status_code != 200\n        ):  # if the status code is not 200, raise an error\n            raise Exception(\"Error retrieving PID record: \", resource_response)\n\n        return PIDRecord.fromJSON(\n            resource_response.json()\n        )  # parse a PID record from the response JSON and return it\n\n    def updatePIDRecord(self, pidRecord: PIDRecord) -&gt; PIDRecord:\n        \"\"\"\n        Updates a PID record in the TPM\n\n        Args:\n            pidRecord:PIDRecord The PID record to update\n\n        Returns:\n            PIDRecord The response from the TPM\n\n        Raises:\n            ValueError: If the PID record is None or not an instance of PIDRecord\n            Exception: If the PID record cannot be updated\n        \"\"\"\n        if pidRecord is None or not isinstance(\n            pidRecord, PIDRecord\n        ):  # if the PID record is None or not an instance of PIDRecord, raise an error\n            raise ValueError(\n                \"PID record must not be None and must be an instance of PIDRecord\"\n            )\n\n        headers = {\"Content-Type\": \"application/json\"}\n\n        content = pidRecord.toJSON()  # get the JSON representation of the PID record\n\n        endpoint = \"/api/v1/pit/pid/\" + pidRecord.getPID()  # create the endpoint URL\n\n        if (\n            content is None or len(content) == 0\n        ):  # if the content is None or empty, raise an error\n            raise ValueError(\"No content to update due to invalid input\")\n\n        resource_response = requests.put(\n            self._tpm_url + endpoint, headers=headers, json=content\n        )  # send a PUT request to the TPM to update the PID record\n\n        if (\n            resource_response.status_code != 200\n        ):  # if the status code is not 200, raise an error\n            raise Exception(\n                \"Error updating PID record: \",\n                resource_response,\n            )\n\n        return PIDRecord.fromJSON(\n            resource_response.json()\n        )  # parse a PID record from the response JSON and return it\n\n    async def getAllPIDRecords(self) -&gt; list[PIDRecord]:\n        \"\"\"\n        Retrieves all PID records from the TPM.\n        This function uses the known-pid endpoint of the TPM to retrieve all PID records.\n        Keep in mind that the TPM does not necessarily know all PIDs in the system or even in the prefix or same instance.\n\n        Returns:\n            list[PIDRecord] The list of all PID records\n        \"\"\"\n        endpoint = \"/api/v1/pit/known-pid\"\n\n        resource_response = requests.get(\n            self._tpm_url + endpoint, headers={\"Accept\": \"application/json\"}\n        )  # send a GET request to the TPM to retrieve all PID records\n\n        if (\n            resource_response.status_code != 200\n        ):  # if the status code is not 200, raise an error\n            raise Exception(\"Error retrieving PID records: \", resource_response)\n\n        url_template = Template(\n            \"$tpmURL/api/v1/pit/pid/$pid\"\n        )  # create a template for the URL\n\n        single_pidRecord_urls = []\n        for (\n            i\n        ) in resource_response.json():  # iterate over all PID records in the response\n            # Create the URL\n            url = url_template.safe_substitute(\n                tpmURL=self._tpm_url,\n                pid=i[\"pid\"],\n            )  # create the URL for the PID record\n            single_pidRecord_urls.append(url)  # add the URL to the list\n\n        # Fetch all PID records in a parallelized manner. Do not use the cache.\n        json_records = await fetch_multiple(single_pidRecord_urls, True)\n\n        result = []\n        for i in json_records:  # iterate over all PID records in the response\n            result.append(\n                PIDRecord.fromJSON(i)\n            )  # parse a PID record from the response JSON and add it to the result list\n\n        return result  # return the list of all fetched PID records\n\n    @staticmethod\n    def _applyTypeAPIFixes(content: dict) -&gt; dict:\n        \"\"\"\n        Applies fixes to the content to match the TPM API.\n        This is due to an issue in the schema generation of the Type API.\n\n        Args:\n            content:dict The content to fix\n\n        Returns:\n            dict The fixed content\n\n        Raises:\n            ValueError: If the content is None or not a dict\n        \"\"\"\n        # Define a set of types that need to be fixed and the new name of the internal key\n        types_to_fix = {\n            \"21.T11969/8710d753ad10f371189b\": \"landingPageLocation\",\n            \"21.T11148/f3f0cbaa39fa9966b279\": \"identifier\",\n            \"21.T11969/7a19f6d5c8e63dd6bfcb\": \"NMR_Method\",\n            \"21.T11148/7fdada5846281ef5d461\": \"locationPreview/Sample\",\n        }\n\n        if content is None or not isinstance(\n            content, dict\n        ):  # if the content is None or not a dict, raise an error\n            raise ValueError(\"Content must not be None and must be a dict\")\n\n        result = {\"pid\": content[\"pid\"], \"entries\": {}}\n\n        for key, value in content[\n            \"entries\"\n        ].items():  # iterate over all entries in the content\n            fix_name = types_to_fix.get(key)  # get the fix name for the current key\n\n            if fix_name is not None:  # if a fix name is available\n                logger.debug(f\"Fixing content for type {key} to {fix_name}\")\n                values = []\n                for item in value:  # iterate over all values to this key\n                    newEntry = {\n                        \"key\": item[\"key\"],\n                        \"value\": '{\"' + fix_name + '\": \"' + item[\"value\"] + '\"}',\n                    }  # create a new entry with the fixed name and value in an internal JSON string\n                    values.append(newEntry)  # add the new entry to the list\n                result[\"entries\"][key] = values  # define the new entries for the key\n                logger.debug(f\"Fixed content for type {key} to {values}\")\n            else:  # if no fix name is available\n                result[\"entries\"][key] = value  # use the original value\n                logger.debug(f\"No fix for type {key}\")\n\n        return result  # return the fixed content\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/connectors/tpm_connector/#nmr_FAIR_DOs.connectors.tpm_connector.TPMConnector.__init__","title":"__init__","text":"<pre><code>__init__(tpm_url: str)\n</code></pre> <p>Creates a new TPMConnector</p> <p>Parameters:</p> Name Type Description Default <code>tpm_url</code> <code>str</code> <p>str The URL of the Typed PID Maker instance</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the TPM URL is None or empty</p> Source code in <code>src/nmr_FAIR_DOs/connectors/tpm_connector.py</code> <pre><code>def __init__(self, tpm_url: str):\n    \"\"\"\n    Creates a new TPMConnector\n\n    Args:\n        tpm_url:str The URL of the Typed PID Maker instance\n\n    Raises:\n        ValueError: If the TPM URL is None or empty\n    \"\"\"\n    if tpm_url is None or len(tpm_url) == 0:\n        raise ValueError(\"TPM URL must not be None or empty\")\n    self._tpm_url = tpm_url\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/connectors/tpm_connector/#nmr_FAIR_DOs.connectors.tpm_connector.TPMConnector.createSingleFAIRDO","title":"createSingleFAIRDO","text":"<pre><code>createSingleFAIRDO(pidRecord: PIDRecord) -&gt; PIDRecord\n</code></pre> <p>Creates a single FAIR-DO in the TPM</p> <p>Parameters:</p> Name Type Description Default <code>pidRecord</code> <code>PIDRecord</code> <p>PIDRecord The FAIR-DO to create</p> required <p>Returns:</p> Type Description <code>PIDRecord</code> <p>PIDRecord The response from the TPM. This response contains the PID and the PID record.</p> Source code in <code>src/nmr_FAIR_DOs/connectors/tpm_connector.py</code> <pre><code>def createSingleFAIRDO(self, pidRecord: PIDRecord) -&gt; PIDRecord:\n    \"\"\"\n    Creates a single FAIR-DO in the TPM\n\n    Args:\n        pidRecord:PIDRecord The FAIR-DO to create\n\n    Returns:\n        PIDRecord The response from the TPM. This response contains the PID and the PID record.\n    \"\"\"\n    logger.info(f\"Creating FAIR-DO {pidRecord.getPID()}\")\n\n    if pidRecord is None or not isinstance(\n        pidRecord, PIDRecord\n    ):  # if the PID record is None or not an instance of PIDRecord, raise an error\n        raise ValueError(\n            \"FAIR-DO must not be None and must be an instance of PIDRecord\"\n        )\n\n    headers = {\"Content-Type\": \"application/json\"}\n\n    # content = self._applyTypeAPIFixes(pidRecord.toJSON()) # Possible fix for Type API issues\n    content = pidRecord.toJSON()  # get the JSON representation of the PID record\n\n    endpoint = \"/api/v1/pit/pid\"\n\n    if (\n        content is None or len(content) == 0\n    ):  # if the content is None or empty, raise an error\n        raise ValueError(\"No content to create due to invalid input\")\n\n    resource_response = requests.post(\n        self._tpm_url + endpoint, headers=headers, json=content\n    )  # send a POST request to the TPM to create the PID record\n    logger.debug(f\"Response for URL {self._tpm_url + endpoint}\", resource_response)\n\n    if (\n        resource_response.status_code != 201\n    ):  # if the status code is not 201, raise an error\n        raise Exception(\"Error creating PID record: \", resource_response)\n\n    return PIDRecord.fromJSON(\n        resource_response.json()\n    )  # parse a PID record from the response JSON and return it\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/connectors/tpm_connector/#nmr_FAIR_DOs.connectors.tpm_connector.TPMConnector.createMultipleFAIRDOs","title":"createMultipleFAIRDOs","text":"<pre><code>createMultipleFAIRDOs(\n    pidRecord: list[PIDRecord],\n) -&gt; list[PIDRecord]\n</code></pre> <p>Creates multiple FAIR-DOs in the TPM. This function uses the bulk-create endpoint of the TPM to create multiple FAIR-DOs at once. One advantage of using this endpoint is that it can create multiple connected FAIR-DOs in one request and automatically replaces \"placeholder\"/\"fantasy\"/\"preliminary\" PIDs in the records with the real deal.</p> <p>Parameters:</p> Name Type Description Default <code>pidRecord</code> <code>list[PIDRecord]</code> <p>list[PIDRecord] The FAIR-DOs to create</p> required <p>Returns:</p> Type Description <code>list[PIDRecord]</code> <p>list[PIDRecord] The response from the TPM which is a list of all created FAIR-DOs</p> Source code in <code>src/nmr_FAIR_DOs/connectors/tpm_connector.py</code> <pre><code>def createMultipleFAIRDOs(self, pidRecord: list[PIDRecord]) -&gt; list[PIDRecord]:\n    \"\"\"\n    Creates multiple FAIR-DOs in the TPM.\n    This function uses the bulk-create endpoint of the TPM to create multiple FAIR-DOs at once.\n    One advantage of using this endpoint is that it can create multiple connected FAIR-DOs in one request and automatically replaces \"placeholder\"/\"fantasy\"/\"preliminary\" PIDs in the records with the real deal.\n\n    Args:\n        pidRecord:list[PIDRecord] The FAIR-DOs to create\n\n    Returns:\n        list[PIDRecord] The response from the TPM which is a list of all created FAIR-DOs\n    \"\"\"\n    logger.info(f\"Creating {len(pidRecord)} FAIR-DOs\")\n\n    headers = {\"Content-Type\": \"application/json\"}\n\n    content = []\n\n    for fairdo in pidRecord:  # iterate over all PID records\n        if fairdo is None or not isinstance(\n            fairdo, PIDRecord\n        ):  # Check the validity or raise an exception\n            raise ValueError(\n                \"FAIR-DO must not be None and must be an instance of PIDRecord\"\n            )\n\n        # content.append(self._applyTypeAPIFixes(fairdo.toJSON())) # Possible fix for Type API issues\n        content.append(fairdo.toJSON())  # Mark this record ready for creation\n\n    endpoint = \"/api/v1/pit/pids\"\n\n    if (\n        content is None or len(content) == 0\n    ):  # if the content is None or empty, raise an error\n        raise ValueError(\"No content to create due to invalid input\")\n\n    logger.debug(\n        f\"Creating FAIR-DOs at {self._tpm_url + endpoint} : {json.dumps(content)[:250]}\"\n    )\n    resource_response = requests.post(\n        self._tpm_url + endpoint, headers=headers, json=content, timeout=None\n    )  # send a POST request to the TPM to create the PID records\n\n    logger.debug(f\"Response for URL {self._tpm_url + endpoint}\", resource_response)\n\n    if (\n        resource_response.status_code != 201\n    ):  # if the status code is not 201, raise an error\n        raise Exception(\n            \"Error creating PID records. API response from TPM: \",\n            repr(resource_response),\n        )\n\n    result = []\n    for (\n        i\n    ) in resource_response.json():  # iterate over all PID records in the response\n        result.append(\n            PIDRecord.fromJSON(i)\n        )  # parse a PID record from the response JSON and add it to the result list\n\n    logger.info(\"Successfully created FAIR-DOs\")\n    return result  # return the list of all created PID records (with their actual PIDs)\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/connectors/tpm_connector/#nmr_FAIR_DOs.connectors.tpm_connector.TPMConnector.getPIDRecord","title":"getPIDRecord","text":"<pre><code>getPIDRecord(pid: str) -&gt; PIDRecord\n</code></pre> <p>Retrieves a PID record from the TPM</p> <p>Parameters:</p> Name Type Description Default <code>pid</code> <code>str</code> <p>The PID to retrieve</p> required <p>Returns:</p> Name Type Description <code>PIDRecord</code> <code>PIDRecord</code> <p>The PID record retrieved from the TPM</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the PID is None or empty</p> <code>Exception</code> <p>If the PID record cannot be retrieved</p> Source code in <code>src/nmr_FAIR_DOs/connectors/tpm_connector.py</code> <pre><code>def getPIDRecord(self, pid: str) -&gt; PIDRecord:\n    \"\"\"\n    Retrieves a PID record from the TPM\n\n    Args:\n        pid (str): The PID to retrieve\n\n    Returns:\n        PIDRecord: The PID record retrieved from the TPM\n\n    Raises:\n        ValueError: If the PID is None or empty\n        Exception: If the PID record cannot be retrieved\n    \"\"\"\n    if pid is None or len(pid) == 0:  # if the PID is None or empty, raise an error\n        raise ValueError(\"PID must not be None or empty\")\n\n    endpoint = \"/api/v1/pit/pid/\" + pid\n\n    resource_response = requests.get(\n        self._tpm_url + endpoint, headers={\"Accept\": \"application/json\"}\n    )  # send a GET request to the TPM to retrieve the PID record\n\n    if (\n        resource_response.status_code != 200\n    ):  # if the status code is not 200, raise an error\n        raise Exception(\"Error retrieving PID record: \", resource_response)\n\n    return PIDRecord.fromJSON(\n        resource_response.json()\n    )  # parse a PID record from the response JSON and return it\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/connectors/tpm_connector/#nmr_FAIR_DOs.connectors.tpm_connector.TPMConnector.updatePIDRecord","title":"updatePIDRecord","text":"<pre><code>updatePIDRecord(pidRecord: PIDRecord) -&gt; PIDRecord\n</code></pre> <p>Updates a PID record in the TPM</p> <p>Parameters:</p> Name Type Description Default <code>pidRecord</code> <code>PIDRecord</code> <p>PIDRecord The PID record to update</p> required <p>Returns:</p> Type Description <code>PIDRecord</code> <p>PIDRecord The response from the TPM</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the PID record is None or not an instance of PIDRecord</p> <code>Exception</code> <p>If the PID record cannot be updated</p> Source code in <code>src/nmr_FAIR_DOs/connectors/tpm_connector.py</code> <pre><code>def updatePIDRecord(self, pidRecord: PIDRecord) -&gt; PIDRecord:\n    \"\"\"\n    Updates a PID record in the TPM\n\n    Args:\n        pidRecord:PIDRecord The PID record to update\n\n    Returns:\n        PIDRecord The response from the TPM\n\n    Raises:\n        ValueError: If the PID record is None or not an instance of PIDRecord\n        Exception: If the PID record cannot be updated\n    \"\"\"\n    if pidRecord is None or not isinstance(\n        pidRecord, PIDRecord\n    ):  # if the PID record is None or not an instance of PIDRecord, raise an error\n        raise ValueError(\n            \"PID record must not be None and must be an instance of PIDRecord\"\n        )\n\n    headers = {\"Content-Type\": \"application/json\"}\n\n    content = pidRecord.toJSON()  # get the JSON representation of the PID record\n\n    endpoint = \"/api/v1/pit/pid/\" + pidRecord.getPID()  # create the endpoint URL\n\n    if (\n        content is None or len(content) == 0\n    ):  # if the content is None or empty, raise an error\n        raise ValueError(\"No content to update due to invalid input\")\n\n    resource_response = requests.put(\n        self._tpm_url + endpoint, headers=headers, json=content\n    )  # send a PUT request to the TPM to update the PID record\n\n    if (\n        resource_response.status_code != 200\n    ):  # if the status code is not 200, raise an error\n        raise Exception(\n            \"Error updating PID record: \",\n            resource_response,\n        )\n\n    return PIDRecord.fromJSON(\n        resource_response.json()\n    )  # parse a PID record from the response JSON and return it\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/connectors/tpm_connector/#nmr_FAIR_DOs.connectors.tpm_connector.TPMConnector.getAllPIDRecords","title":"getAllPIDRecords  <code>async</code>","text":"<pre><code>getAllPIDRecords() -&gt; list[PIDRecord]\n</code></pre> <p>Retrieves all PID records from the TPM. This function uses the known-pid endpoint of the TPM to retrieve all PID records. Keep in mind that the TPM does not necessarily know all PIDs in the system or even in the prefix or same instance.</p> <p>Returns:</p> Type Description <code>list[PIDRecord]</code> <p>list[PIDRecord] The list of all PID records</p> Source code in <code>src/nmr_FAIR_DOs/connectors/tpm_connector.py</code> <pre><code>async def getAllPIDRecords(self) -&gt; list[PIDRecord]:\n    \"\"\"\n    Retrieves all PID records from the TPM.\n    This function uses the known-pid endpoint of the TPM to retrieve all PID records.\n    Keep in mind that the TPM does not necessarily know all PIDs in the system or even in the prefix or same instance.\n\n    Returns:\n        list[PIDRecord] The list of all PID records\n    \"\"\"\n    endpoint = \"/api/v1/pit/known-pid\"\n\n    resource_response = requests.get(\n        self._tpm_url + endpoint, headers={\"Accept\": \"application/json\"}\n    )  # send a GET request to the TPM to retrieve all PID records\n\n    if (\n        resource_response.status_code != 200\n    ):  # if the status code is not 200, raise an error\n        raise Exception(\"Error retrieving PID records: \", resource_response)\n\n    url_template = Template(\n        \"$tpmURL/api/v1/pit/pid/$pid\"\n    )  # create a template for the URL\n\n    single_pidRecord_urls = []\n    for (\n        i\n    ) in resource_response.json():  # iterate over all PID records in the response\n        # Create the URL\n        url = url_template.safe_substitute(\n            tpmURL=self._tpm_url,\n            pid=i[\"pid\"],\n        )  # create the URL for the PID record\n        single_pidRecord_urls.append(url)  # add the URL to the list\n\n    # Fetch all PID records in a parallelized manner. Do not use the cache.\n    json_records = await fetch_multiple(single_pidRecord_urls, True)\n\n    result = []\n    for i in json_records:  # iterate over all PID records in the response\n        result.append(\n            PIDRecord.fromJSON(i)\n        )  # parse a PID record from the response JSON and add it to the result list\n\n    return result  # return the list of all fetched PID records\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/domain/","title":"domain","text":"<p>This module contains the domain classes of the nmr_FAIR_DOs package.</p> <ul> <li><code>nmr_FAIR_DOs.domain.PIDRecord</code>: This class represents a PID record.</li> <li><code>nmr_FAIR_DOs.domain.PIDRecordEntry</code>: This class represents a single entry in a PID record. It is heavily used by the PIDRecord class.</li> </ul> <p>Additionally, this module contains a helper function to extract the data type name from a PID. See <code>nmr_FAIR_DOs.domain.dataType.extractDataTypeNameFromPID</code>.</p>"},{"location":"reference/nmr_FAIR_DOs/domain/dataType/","title":"dataType","text":""},{"location":"reference/nmr_FAIR_DOs/domain/dataType/#nmr_FAIR_DOs.domain.dataType.extractDataTypeNameFromPID","title":"extractDataTypeNameFromPID  <code>async</code>","text":"<pre><code>extractDataTypeNameFromPID(pid) -&gt; str\n</code></pre> <p>Extracts the data type name from a PID. This PID is used in the key coloumn of a given PID record and references to a data type (inside a data type registry). Inside of the data type registry (DTR), the data type is stored and contains much more information (i.e., description, provenance, regex, etc.). For more information on the information available in the data type registry, have a look at data type registry</p> <p>Parameters:</p> Name Type Description Default <code>pid</code> <code>str</code> <p>The PID to extract the data type name from.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A human-readable name of the data type.</p> Source code in <code>src/nmr_FAIR_DOs/domain/dataType.py</code> <pre><code>async def extractDataTypeNameFromPID(pid) -&gt; str:\n    \"\"\"\n    Extracts the data type name from a PID.\n    This PID is used in the key coloumn of a given PID record and references to a data type (inside a data type registry).\n    Inside of the data type registry (DTR), the data type is stored and contains much more information (i.e., description, provenance, regex, etc.).\n    For more information on the information available in the data type registry, have a look at [data type registry](https://typeregistry.lab.pidconsortium.net/)\n\n    Args:\n        pid (str): The PID to extract the data type name from.\n\n    Returns:\n        str: A human-readable name of the data type.\n    \"\"\"\n    # Check if the data type name is already known\n    if pid in typeMappings:\n        # Return the known data type name\n        return typeMappings[pid]\n    else:  # If the data type name is not known\n        # Resolve the PID via the Handle.net resolver. When resolving a data type PID, the user is automatically redirected to the data type registry.\n        url = requests.get(\"https://hdl.handle.net/\" + pid).url\n        url = url.replace(\n            \"#\", \"\"\n        )  # The URL might contain a hash which signalizes the DTR to render a webpage. This webpage is not useful for the extraction of the data type name.\n\n        # Request the data type from the data type registry\n        logger.debug(\"Requesting data type name from Data Type Registry: \" + url)\n        response = requests.get(\n            url\n        )  # Request the data type from the data type registry\n        response_json = response.json()\n\n        # Extract the data type name from the response. If the name is not available, return the PID as the name to avoid errors.\n        name = response_json[\"name\"] if \"name\" in response_json else pid\n        # Store the data type name in the typeMappings dictionary\n        typeMappings[pid] = name\n        # Return the data type name\n        return name\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/domain/pid_record/","title":"pid_record","text":""},{"location":"reference/nmr_FAIR_DOs/domain/pid_record/#nmr_FAIR_DOs.domain.pid_record.PIDRecord","title":"PIDRecord","text":"<p>\" This class represents a PID record with a PID and entries. For more information on the PID record format, see the documentation of the Typed PID Maker (https://kit-data-manager.github.io/webpage/typed-pid-maker/openapi.html)</p> <p>Attributes:</p> Name Type Description <code>_pid</code> <code>str</code> <p>The PID of the PID record</p> <code>_entries</code> <code>dict[str, list[PIDRecordEntry]]</code> <p>The entries of the PID record. The entries are stored in a dictionary with the key as the key of the entry and the value as a list of values for the entry. Each value is a dictionary with the key \"value\" and the value of the entry as the value. The value can also be accessed with the key \"@value\"</p> Source code in <code>src/nmr_FAIR_DOs/domain/pid_record.py</code> <pre><code>class PIDRecord:\n    \"\"\" \"\n    This class represents a PID record with a PID and entries.\n    For more information on the PID record format, see the documentation of the Typed PID Maker (https://kit-data-manager.github.io/webpage/typed-pid-maker/openapi.html)\n\n    Attributes:\n        _pid (str): The PID of the PID record\n        _entries (dict[str, list[PIDRecordEntry]]): The entries of the PID record. The entries are stored in a dictionary with the key as the key of the entry and the value as a list of values for the entry. Each value is a dictionary with the key \"value\" and the value of the entry as the value. The value can also be accessed with the key \"@value\"\n    \"\"\"\n\n    _pid: str\n    _entries: dict[str, list[PIDRecordEntry]]\n\n    def __init__(self, pid: str, entries: list[PIDRecordEntry] = None):\n        \"\"\"\n        Creates a PID record\n\n        Args:\n            pid (str): The PID of the PID record\n            entries (list[PIDRecordEntry]): The entries of the PID record (optional) Entries is a dictionary with the key as the key of the entry and the value as a list of values for the entry. Each value is a dictionary with the key \"value\" and the value of the entry as the value. The value can also be accessed with the key \"@value\"\n\n        Raises:\n            ValueError: If the PID is None\n        \"\"\"\n        if pid is None:\n            raise ValueError(\"PID must not be None\")\n\n        self._pid = pid\n\n        self._entries = {}\n        if entries is not None and isinstance(\n            entries, list\n        ):  # Check if entries is not None and a list\n            for entry in entries:\n                if isinstance(entry, PIDRecordEntry):\n                    self.addPIDRecordEntry(entry)\n                elif isinstance(entry, dict) and \"key\" in entry and \"value\" in entry:\n                    self.addEntry(\n                        entry[\"key\"],\n                        entry[\"value\"],\n                        entry[\"name\"] if \"name\" in entry else None,\n                    )\n\n    def addPIDRecordEntry(self, entry: PIDRecordEntry):\n        \"\"\"\n        Adds a PID record entry to the PID record\n\n        Args:\n            entry (PIDRecordEntry): The PID record entry to add\n\n        Raises:\n            ValueError: If the key of the entry is None or the value of the entry is None\n        \"\"\"\n\n        if entry.key is None:  # Check if the key is None\n            raise ValueError(\"Key must not be None\")\n        if entry.value is None:  # Check if the value is None\n            raise ValueError(\"Value must not be None\")\n\n        if (\n            entry.key not in self._entries\n        ):  # Check if the key is not already in the PID record\n            logger.debug(f\"Adding entry {entry} to PID record\")\n            self._entries[entry.key] = [entry]  # Add the entry to the PID record\n        elif isinstance(\n            self._entries[entry.key], list\n        ):  # Check if the entry is already a list\n            if not any(\n                e.value == entry.value\n                for e in self._entries[\n                    entry.key\n                ]  # Check if the entry value is already in the list\n            ):\n                logger.debug(\n                    f\"Adding entry {entry} to PID record. Entry with key {entry.key} already exists. Adding to list\"\n                )\n                self._entries[entry.key].append(\n                    entry\n                )  # Add the entry to the list iff the value is not already in the list\n            logger.debug(\n                f\"Entry with key {entry.key} and value {entry.value} already exists. Skipping\"\n            )\n        else:  # If the entry is not a list\n            logger.debug(\n                f\"Adding entry {entry} to PID record. Entry with key {entry.key} already exists. Converting to list\"\n            )\n            self._entries[entry.key] = [\n                self._entries[entry.key],\n                entry,\n            ]  # Convert the entry to a list\n\n    def addEntry(self, key: str, value: str | dict, name: str = None):\n        \"\"\"\n        Adds an entry to the PID record\n        If the entry already exists, it is not added again (no duplicates)\n\n        Args:\n            key (str): The key of the entry\n            value (str|dict): The value of the entry\n            name (str): The name of the entry (optional)\n\n        Raises:\n            ValueError: If the key is None or the values are None\n        \"\"\"\n\n        entry = PIDRecordEntry(key, value, name)  # Create a PIDRecordEntry object\n        self.addPIDRecordEntry(entry)  # Add the PIDRecordEntry object to the PID record\n\n    def addListOfEntries(self, entries: list[PIDRecordEntry]):\n        \"\"\"\n        Adds multiple PID record entries to the PID record\n\n        Args:\n            entries (list[PIDRecordEntry]): The PID record entries to add\n\n        Raises:\n            ValueError: If the entries are None\n        \"\"\"\n\n        if entries is None:\n            raise ValueError(\"Entries must not be None\")\n\n        for entry in entries:  # Add each entry to the PID record\n            self.addPIDRecordEntry(entry)\n\n    def addEntries(self, key: str, values: list[str], name: str = None):\n        \"\"\"\n        Adds multiple entries to the PID record\n\n        Args:\n            key (str): The key of the entries\n            values (list[str]): The values of the entries. All values are added to the PID record with the same key.\n            name (str): The name of the entries (optional)\n\n        Raises:\n            ValueError: If the key is None or the values are None\n        \"\"\"\n        if key is None:  # Check if the key is None\n            raise ValueError(\"Key must not be None\")\n\n        if values is None:  # Check if the values are None\n            raise ValueError(\"Values must not be None\")\n\n        for value in values:  # Add each value to the PID record\n            self.addEntry(key, value, name)\n\n    def updateEntry(self, key: str, value: str | dict, name: str = None):\n        \"\"\"\n        Updates an entry in the PID record\n        If the entry does not exist, it is added\n\n        Args:\n            key (str): The key of the entry\n            value (str|dict): The value of the entry. If the value is a dictionary, it is converted to a string internally.\n            name (str): The name of the entry (optional)\n\n        Raises:\n            ValueError: If the key is None\n        \"\"\"\n        entry = PIDRecordEntry(key, value, name)  # Create a PIDRecordEntry object\n        self.deleteEntry(key)  # Delete the entry with the given key\n        self.addPIDRecordEntry(entry)  # Add the PIDRecordEntry object to the PID record\n\n    def getEntries(self) -&gt; dict:\n        \"\"\"\n        Returns the entries of the PID record\n\n        Returns:\n            dict: The entries of the PID record\n        \"\"\"\n        return self._entries\n\n    def getPID(self) -&gt; str:\n        \"\"\"\n        Returns the PID of the PID record\n\n        Returns:\n            str: The PID of the PID record\n        \"\"\"\n        return self._pid\n\n    def getEntry(self, key: str) -&gt; list[PIDRecordEntry] | PIDRecordEntry | None:\n        \"\"\"\n        Returns all entries with the given key\n\n        Args:\n            key (str): The key of the entries\n\n        Returns:\n            list[PIDRecordEntry]: The entries with the given key\n            PIDRecordEntry: The entry with the given key if only one entry is found\n            None: If no entry is found\n\n        Raises:\n            ValueError: If the key is None\n        \"\"\"\n        if key is None:  # Check if the key is None\n            raise ValueError(\"Key must not be None\")\n\n        if key in self._entries:  # Check if the key is in the PID record\n            return self._entries[key]\n        else:  # If the key is not in the PID record\n            return None\n\n    def deleteEntry(self, key: str, value: str | dict = None):\n        \"\"\"\n        Deletes an entry from the PID record\n\n        Args:\n            key (str): The key of the entry\n            value (str|dict): The value of the entry (optional) If the value is None, all entries with the given key are deleted. If the value is not None, only the entry with the given key and value is deleted.\n\n        Raises:\n            ValueError: If the key is None\n        \"\"\"\n        if key is None:  # Check if the key is None\n            raise ValueError(\"Key must not be None\")\n\n        if key in self._entries:\n            if value is None:  # Delete all entries with the given key\n                del self._entries[key]\n            else:\n                self._entries[key] = [\n                    entry for entry in self._entries[key] if entry[\"value\"] != value\n                ]\n\n    def deleteAllEntries(self):\n        \"\"\"\n        Deletes all entries from the PID record\n        \"\"\"\n        self._entries = {}\n\n    def entryExists(self, key: str, value: str | dict = None) -&gt; bool:\n        \"\"\"\n        Checks if an entry exists\n\n        Args:\n            key (str): The key of the entry\n            value (str|dict): The value of the entry (optional) If the value is None, the method checks if an entry with the given key exists. If the value is not None, the method checks if an entry with the given key and value exists.\n\n        Returns:\n            bool: True if the entry exists, False otherwise\n\n        Raises:\n            ValueError: If the key is None\n        \"\"\"\n        if key is None:  # Check if the key is None\n            raise ValueError(\"Key must not be None\")\n\n        if key in self._entries:  # Check if the key is in the PID record\n            if value is None:  # Check if the value argument is not specified (None)\n                return True\n            else:  # If the value argument is specified, check if the value is in the list of entries\n                return any(entry[\"value\"] == value for entry in self._entries[key])\n        else:  # If the key is not in the PID record\n            return False\n\n    def toJSON(self) -&gt; dict:\n        \"\"\"\n        Exports the PID record as JSON object\n\n        Returns:\n            dict: The PID record as JSON object\n        \"\"\"\n        entries = {}\n\n        for key, value in self._entries.items():  # Iterate over all entries\n            entries[key] = [\n                entry.toJSON() for entry in value\n            ]  # Convert the entries to JSON\n\n        return {\"pid\": self._pid, \"entries\": entries}\n\n    def exportSimpleFormatJSON(self) -&gt; dict:\n        \"\"\"\n        Exports the PID record as a simple JSON object\n\n        Returns:\n            dict: The PID record as a simple JSON object\n        \"\"\"\n        kv_pairs = []\n\n        for key, value in self._entries.items():  # Iterate over all entries\n            for entry in value:  # Iterate over all values of the entry\n                kv_pairs.append(\n                    {\"key\": key, \"value\": entry[\"value\"]}\n                )  # Add the key and value to the list\n\n        return {\"pid\": self._pid, \"record\": kv_pairs}\n\n    @staticmethod\n    def fromJSON(input_json: dict) -&gt; \"PIDRecord\":\n        \"\"\"\n        Creates a PID record from a JSON object\n\n        Args:\n            input_json (dict): The JSON object to create the PID record from\n\n        Returns:\n            PIDRecord: The PID record created from the JSON object\n\n        Raises:\n            ValueError: If the JSON object is None or invalid\n        \"\"\"\n        logger.debug(\"Trying to extract PID record from JSON\", input_json)\n\n        if input_json is None:  # Check if the JSON object is None\n            raise ValueError(\"JSON must not be None\")\n\n        if \"pid\" not in input_json:  # Check if the JSON object contains a PID\n            raise ValueError(\"PID must be in JSON object\")\n\n        if \"entries\" not in input_json:  # Check if the JSON object contains entries\n            return PIDRecord(input_json[\"pid\"])\n        else:\n            entries = []\n\n            for key, value in input_json[\n                \"entries\"\n            ].items():  # Iterate over all entries in the JSON object\n                for entry in value:  # Iterate over all values of the entry. Each value consists of a dict with the keys \"key\", \"value\" and \"name\". Name is the only optional key.\n                    if \"value\" not in entry or \"key\" not in entry:\n                        # Skip this entry if it does not contain a key or value\n                        logger.warning(\n                            f\"Skipping entry {entry} because it does not contain a key or value\"\n                        )\n                        continue\n                    elif \"name\" in entry:\n                        # If the entry contains a name, add it to the PIDRecordEntry\n                        entries.append(\n                            PIDRecordEntry(key, entry[\"value\"], entry[\"name\"])\n                        )\n                    else:\n                        # If the entry does not contain a name, add it without a name\n                        entries.append(PIDRecordEntry(key, entry[\"value\"]))\n\n            logger.debug(\n                f\"Extracted PID record from JSON: {PIDRecord(input_json['pid'], entries)}\"\n            )\n            return PIDRecord(input_json[\"pid\"], entries)\n\n    def merge(self, other: \"PIDRecord\") -&gt; \"PIDRecord\":\n        \"\"\"\n        Merges the PID record with another PID record\n\n        Args:\n            other (PIDRecord): The PID record to merge with\n\n        Returns:\n            PIDRecord: The merged PID record\n\n        Raises:\n            ValueError: If the other PID record is None\n        \"\"\"\n        if other is None:  # Check if the other PID record is None\n            raise ValueError(\"Other PID record must not be None\")\n\n        if (\n            self._pid != other.getPID()\n        ):  # Check if the PID of both PID records is the same\n            raise ValueError(\"PID of both PID records must be the same\")\n\n        for (\n            key,\n            value,\n        ) in (\n            other.getEntries().items()\n        ):  # Iterate over all entries in the other PID record\n            for entry in value:  # Iterate over all values of the entry\n                if not self.entryExists(\n                    key, entry.value\n                ):  # Check if the entry does not exist in this PID record\n                    self.addPIDRecordEntry(entry)  # Add the entry to this PID record\n\n        return self  # Return the merged PID record\n\n    def __str__(self):\n        return f\"PIDRecord(pid={self._pid}, entries={self._entries})\"\n\n    def __repr__(self):\n        return str(self.toJSON())\n\n    def __dict__(self):\n        return self.toJSON()\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/domain/pid_record/#nmr_FAIR_DOs.domain.pid_record.PIDRecord.__init__","title":"__init__","text":"<pre><code>__init__(pid: str, entries: list[PIDRecordEntry] = None)\n</code></pre> <p>Creates a PID record</p> <p>Parameters:</p> Name Type Description Default <code>pid</code> <code>str</code> <p>The PID of the PID record</p> required <code>entries</code> <code>list[PIDRecordEntry]</code> <p>The entries of the PID record (optional) Entries is a dictionary with the key as the key of the entry and the value as a list of values for the entry. Each value is a dictionary with the key \"value\" and the value of the entry as the value. The value can also be accessed with the key \"@value\"</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the PID is None</p> Source code in <code>src/nmr_FAIR_DOs/domain/pid_record.py</code> <pre><code>def __init__(self, pid: str, entries: list[PIDRecordEntry] = None):\n    \"\"\"\n    Creates a PID record\n\n    Args:\n        pid (str): The PID of the PID record\n        entries (list[PIDRecordEntry]): The entries of the PID record (optional) Entries is a dictionary with the key as the key of the entry and the value as a list of values for the entry. Each value is a dictionary with the key \"value\" and the value of the entry as the value. The value can also be accessed with the key \"@value\"\n\n    Raises:\n        ValueError: If the PID is None\n    \"\"\"\n    if pid is None:\n        raise ValueError(\"PID must not be None\")\n\n    self._pid = pid\n\n    self._entries = {}\n    if entries is not None and isinstance(\n        entries, list\n    ):  # Check if entries is not None and a list\n        for entry in entries:\n            if isinstance(entry, PIDRecordEntry):\n                self.addPIDRecordEntry(entry)\n            elif isinstance(entry, dict) and \"key\" in entry and \"value\" in entry:\n                self.addEntry(\n                    entry[\"key\"],\n                    entry[\"value\"],\n                    entry[\"name\"] if \"name\" in entry else None,\n                )\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/domain/pid_record/#nmr_FAIR_DOs.domain.pid_record.PIDRecord.addPIDRecordEntry","title":"addPIDRecordEntry","text":"<pre><code>addPIDRecordEntry(entry: PIDRecordEntry)\n</code></pre> <p>Adds a PID record entry to the PID record</p> <p>Parameters:</p> Name Type Description Default <code>entry</code> <code>PIDRecordEntry</code> <p>The PID record entry to add</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the key of the entry is None or the value of the entry is None</p> Source code in <code>src/nmr_FAIR_DOs/domain/pid_record.py</code> <pre><code>def addPIDRecordEntry(self, entry: PIDRecordEntry):\n    \"\"\"\n    Adds a PID record entry to the PID record\n\n    Args:\n        entry (PIDRecordEntry): The PID record entry to add\n\n    Raises:\n        ValueError: If the key of the entry is None or the value of the entry is None\n    \"\"\"\n\n    if entry.key is None:  # Check if the key is None\n        raise ValueError(\"Key must not be None\")\n    if entry.value is None:  # Check if the value is None\n        raise ValueError(\"Value must not be None\")\n\n    if (\n        entry.key not in self._entries\n    ):  # Check if the key is not already in the PID record\n        logger.debug(f\"Adding entry {entry} to PID record\")\n        self._entries[entry.key] = [entry]  # Add the entry to the PID record\n    elif isinstance(\n        self._entries[entry.key], list\n    ):  # Check if the entry is already a list\n        if not any(\n            e.value == entry.value\n            for e in self._entries[\n                entry.key\n            ]  # Check if the entry value is already in the list\n        ):\n            logger.debug(\n                f\"Adding entry {entry} to PID record. Entry with key {entry.key} already exists. Adding to list\"\n            )\n            self._entries[entry.key].append(\n                entry\n            )  # Add the entry to the list iff the value is not already in the list\n        logger.debug(\n            f\"Entry with key {entry.key} and value {entry.value} already exists. Skipping\"\n        )\n    else:  # If the entry is not a list\n        logger.debug(\n            f\"Adding entry {entry} to PID record. Entry with key {entry.key} already exists. Converting to list\"\n        )\n        self._entries[entry.key] = [\n            self._entries[entry.key],\n            entry,\n        ]  # Convert the entry to a list\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/domain/pid_record/#nmr_FAIR_DOs.domain.pid_record.PIDRecord.addEntry","title":"addEntry","text":"<pre><code>addEntry(key: str, value: str | dict, name: str = None)\n</code></pre> <p>Adds an entry to the PID record If the entry already exists, it is not added again (no duplicates)</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key of the entry</p> required <code>value</code> <code>str | dict</code> <p>The value of the entry</p> required <code>name</code> <code>str</code> <p>The name of the entry (optional)</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the key is None or the values are None</p> Source code in <code>src/nmr_FAIR_DOs/domain/pid_record.py</code> <pre><code>def addEntry(self, key: str, value: str | dict, name: str = None):\n    \"\"\"\n    Adds an entry to the PID record\n    If the entry already exists, it is not added again (no duplicates)\n\n    Args:\n        key (str): The key of the entry\n        value (str|dict): The value of the entry\n        name (str): The name of the entry (optional)\n\n    Raises:\n        ValueError: If the key is None or the values are None\n    \"\"\"\n\n    entry = PIDRecordEntry(key, value, name)  # Create a PIDRecordEntry object\n    self.addPIDRecordEntry(entry)  # Add the PIDRecordEntry object to the PID record\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/domain/pid_record/#nmr_FAIR_DOs.domain.pid_record.PIDRecord.addListOfEntries","title":"addListOfEntries","text":"<pre><code>addListOfEntries(entries: list[PIDRecordEntry])\n</code></pre> <p>Adds multiple PID record entries to the PID record</p> <p>Parameters:</p> Name Type Description Default <code>entries</code> <code>list[PIDRecordEntry]</code> <p>The PID record entries to add</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the entries are None</p> Source code in <code>src/nmr_FAIR_DOs/domain/pid_record.py</code> <pre><code>def addListOfEntries(self, entries: list[PIDRecordEntry]):\n    \"\"\"\n    Adds multiple PID record entries to the PID record\n\n    Args:\n        entries (list[PIDRecordEntry]): The PID record entries to add\n\n    Raises:\n        ValueError: If the entries are None\n    \"\"\"\n\n    if entries is None:\n        raise ValueError(\"Entries must not be None\")\n\n    for entry in entries:  # Add each entry to the PID record\n        self.addPIDRecordEntry(entry)\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/domain/pid_record/#nmr_FAIR_DOs.domain.pid_record.PIDRecord.addEntries","title":"addEntries","text":"<pre><code>addEntries(key: str, values: list[str], name: str = None)\n</code></pre> <p>Adds multiple entries to the PID record</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key of the entries</p> required <code>values</code> <code>list[str]</code> <p>The values of the entries. All values are added to the PID record with the same key.</p> required <code>name</code> <code>str</code> <p>The name of the entries (optional)</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the key is None or the values are None</p> Source code in <code>src/nmr_FAIR_DOs/domain/pid_record.py</code> <pre><code>def addEntries(self, key: str, values: list[str], name: str = None):\n    \"\"\"\n    Adds multiple entries to the PID record\n\n    Args:\n        key (str): The key of the entries\n        values (list[str]): The values of the entries. All values are added to the PID record with the same key.\n        name (str): The name of the entries (optional)\n\n    Raises:\n        ValueError: If the key is None or the values are None\n    \"\"\"\n    if key is None:  # Check if the key is None\n        raise ValueError(\"Key must not be None\")\n\n    if values is None:  # Check if the values are None\n        raise ValueError(\"Values must not be None\")\n\n    for value in values:  # Add each value to the PID record\n        self.addEntry(key, value, name)\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/domain/pid_record/#nmr_FAIR_DOs.domain.pid_record.PIDRecord.updateEntry","title":"updateEntry","text":"<pre><code>updateEntry(key: str, value: str | dict, name: str = None)\n</code></pre> <p>Updates an entry in the PID record If the entry does not exist, it is added</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key of the entry</p> required <code>value</code> <code>str | dict</code> <p>The value of the entry. If the value is a dictionary, it is converted to a string internally.</p> required <code>name</code> <code>str</code> <p>The name of the entry (optional)</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the key is None</p> Source code in <code>src/nmr_FAIR_DOs/domain/pid_record.py</code> <pre><code>def updateEntry(self, key: str, value: str | dict, name: str = None):\n    \"\"\"\n    Updates an entry in the PID record\n    If the entry does not exist, it is added\n\n    Args:\n        key (str): The key of the entry\n        value (str|dict): The value of the entry. If the value is a dictionary, it is converted to a string internally.\n        name (str): The name of the entry (optional)\n\n    Raises:\n        ValueError: If the key is None\n    \"\"\"\n    entry = PIDRecordEntry(key, value, name)  # Create a PIDRecordEntry object\n    self.deleteEntry(key)  # Delete the entry with the given key\n    self.addPIDRecordEntry(entry)  # Add the PIDRecordEntry object to the PID record\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/domain/pid_record/#nmr_FAIR_DOs.domain.pid_record.PIDRecord.getEntries","title":"getEntries","text":"<pre><code>getEntries() -&gt; dict\n</code></pre> <p>Returns the entries of the PID record</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The entries of the PID record</p> Source code in <code>src/nmr_FAIR_DOs/domain/pid_record.py</code> <pre><code>def getEntries(self) -&gt; dict:\n    \"\"\"\n    Returns the entries of the PID record\n\n    Returns:\n        dict: The entries of the PID record\n    \"\"\"\n    return self._entries\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/domain/pid_record/#nmr_FAIR_DOs.domain.pid_record.PIDRecord.getPID","title":"getPID","text":"<pre><code>getPID() -&gt; str\n</code></pre> <p>Returns the PID of the PID record</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The PID of the PID record</p> Source code in <code>src/nmr_FAIR_DOs/domain/pid_record.py</code> <pre><code>def getPID(self) -&gt; str:\n    \"\"\"\n    Returns the PID of the PID record\n\n    Returns:\n        str: The PID of the PID record\n    \"\"\"\n    return self._pid\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/domain/pid_record/#nmr_FAIR_DOs.domain.pid_record.PIDRecord.getEntry","title":"getEntry","text":"<pre><code>getEntry(\n    key: str,\n) -&gt; list[PIDRecordEntry] | PIDRecordEntry | None\n</code></pre> <p>Returns all entries with the given key</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key of the entries</p> required <p>Returns:</p> Name Type Description <code>list[PIDRecordEntry] | PIDRecordEntry | None</code> <p>list[PIDRecordEntry]: The entries with the given key</p> <code>PIDRecordEntry</code> <code>list[PIDRecordEntry] | PIDRecordEntry | None</code> <p>The entry with the given key if only one entry is found</p> <code>None</code> <code>list[PIDRecordEntry] | PIDRecordEntry | None</code> <p>If no entry is found</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the key is None</p> Source code in <code>src/nmr_FAIR_DOs/domain/pid_record.py</code> <pre><code>def getEntry(self, key: str) -&gt; list[PIDRecordEntry] | PIDRecordEntry | None:\n    \"\"\"\n    Returns all entries with the given key\n\n    Args:\n        key (str): The key of the entries\n\n    Returns:\n        list[PIDRecordEntry]: The entries with the given key\n        PIDRecordEntry: The entry with the given key if only one entry is found\n        None: If no entry is found\n\n    Raises:\n        ValueError: If the key is None\n    \"\"\"\n    if key is None:  # Check if the key is None\n        raise ValueError(\"Key must not be None\")\n\n    if key in self._entries:  # Check if the key is in the PID record\n        return self._entries[key]\n    else:  # If the key is not in the PID record\n        return None\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/domain/pid_record/#nmr_FAIR_DOs.domain.pid_record.PIDRecord.deleteEntry","title":"deleteEntry","text":"<pre><code>deleteEntry(key: str, value: str | dict = None)\n</code></pre> <p>Deletes an entry from the PID record</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key of the entry</p> required <code>value</code> <code>str | dict</code> <p>The value of the entry (optional) If the value is None, all entries with the given key are deleted. If the value is not None, only the entry with the given key and value is deleted.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the key is None</p> Source code in <code>src/nmr_FAIR_DOs/domain/pid_record.py</code> <pre><code>def deleteEntry(self, key: str, value: str | dict = None):\n    \"\"\"\n    Deletes an entry from the PID record\n\n    Args:\n        key (str): The key of the entry\n        value (str|dict): The value of the entry (optional) If the value is None, all entries with the given key are deleted. If the value is not None, only the entry with the given key and value is deleted.\n\n    Raises:\n        ValueError: If the key is None\n    \"\"\"\n    if key is None:  # Check if the key is None\n        raise ValueError(\"Key must not be None\")\n\n    if key in self._entries:\n        if value is None:  # Delete all entries with the given key\n            del self._entries[key]\n        else:\n            self._entries[key] = [\n                entry for entry in self._entries[key] if entry[\"value\"] != value\n            ]\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/domain/pid_record/#nmr_FAIR_DOs.domain.pid_record.PIDRecord.deleteAllEntries","title":"deleteAllEntries","text":"<pre><code>deleteAllEntries()\n</code></pre> <p>Deletes all entries from the PID record</p> Source code in <code>src/nmr_FAIR_DOs/domain/pid_record.py</code> <pre><code>def deleteAllEntries(self):\n    \"\"\"\n    Deletes all entries from the PID record\n    \"\"\"\n    self._entries = {}\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/domain/pid_record/#nmr_FAIR_DOs.domain.pid_record.PIDRecord.entryExists","title":"entryExists","text":"<pre><code>entryExists(key: str, value: str | dict = None) -&gt; bool\n</code></pre> <p>Checks if an entry exists</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key of the entry</p> required <code>value</code> <code>str | dict</code> <p>The value of the entry (optional) If the value is None, the method checks if an entry with the given key exists. If the value is not None, the method checks if an entry with the given key and value exists.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the entry exists, False otherwise</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the key is None</p> Source code in <code>src/nmr_FAIR_DOs/domain/pid_record.py</code> <pre><code>def entryExists(self, key: str, value: str | dict = None) -&gt; bool:\n    \"\"\"\n    Checks if an entry exists\n\n    Args:\n        key (str): The key of the entry\n        value (str|dict): The value of the entry (optional) If the value is None, the method checks if an entry with the given key exists. If the value is not None, the method checks if an entry with the given key and value exists.\n\n    Returns:\n        bool: True if the entry exists, False otherwise\n\n    Raises:\n        ValueError: If the key is None\n    \"\"\"\n    if key is None:  # Check if the key is None\n        raise ValueError(\"Key must not be None\")\n\n    if key in self._entries:  # Check if the key is in the PID record\n        if value is None:  # Check if the value argument is not specified (None)\n            return True\n        else:  # If the value argument is specified, check if the value is in the list of entries\n            return any(entry[\"value\"] == value for entry in self._entries[key])\n    else:  # If the key is not in the PID record\n        return False\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/domain/pid_record/#nmr_FAIR_DOs.domain.pid_record.PIDRecord.toJSON","title":"toJSON","text":"<pre><code>toJSON() -&gt; dict\n</code></pre> <p>Exports the PID record as JSON object</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The PID record as JSON object</p> Source code in <code>src/nmr_FAIR_DOs/domain/pid_record.py</code> <pre><code>def toJSON(self) -&gt; dict:\n    \"\"\"\n    Exports the PID record as JSON object\n\n    Returns:\n        dict: The PID record as JSON object\n    \"\"\"\n    entries = {}\n\n    for key, value in self._entries.items():  # Iterate over all entries\n        entries[key] = [\n            entry.toJSON() for entry in value\n        ]  # Convert the entries to JSON\n\n    return {\"pid\": self._pid, \"entries\": entries}\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/domain/pid_record/#nmr_FAIR_DOs.domain.pid_record.PIDRecord.exportSimpleFormatJSON","title":"exportSimpleFormatJSON","text":"<pre><code>exportSimpleFormatJSON() -&gt; dict\n</code></pre> <p>Exports the PID record as a simple JSON object</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The PID record as a simple JSON object</p> Source code in <code>src/nmr_FAIR_DOs/domain/pid_record.py</code> <pre><code>def exportSimpleFormatJSON(self) -&gt; dict:\n    \"\"\"\n    Exports the PID record as a simple JSON object\n\n    Returns:\n        dict: The PID record as a simple JSON object\n    \"\"\"\n    kv_pairs = []\n\n    for key, value in self._entries.items():  # Iterate over all entries\n        for entry in value:  # Iterate over all values of the entry\n            kv_pairs.append(\n                {\"key\": key, \"value\": entry[\"value\"]}\n            )  # Add the key and value to the list\n\n    return {\"pid\": self._pid, \"record\": kv_pairs}\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/domain/pid_record/#nmr_FAIR_DOs.domain.pid_record.PIDRecord.fromJSON","title":"fromJSON  <code>staticmethod</code>","text":"<pre><code>fromJSON(input_json: dict) -&gt; PIDRecord\n</code></pre> <p>Creates a PID record from a JSON object</p> <p>Parameters:</p> Name Type Description Default <code>input_json</code> <code>dict</code> <p>The JSON object to create the PID record from</p> required <p>Returns:</p> Name Type Description <code>PIDRecord</code> <code>PIDRecord</code> <p>The PID record created from the JSON object</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the JSON object is None or invalid</p> Source code in <code>src/nmr_FAIR_DOs/domain/pid_record.py</code> <pre><code>@staticmethod\ndef fromJSON(input_json: dict) -&gt; \"PIDRecord\":\n    \"\"\"\n    Creates a PID record from a JSON object\n\n    Args:\n        input_json (dict): The JSON object to create the PID record from\n\n    Returns:\n        PIDRecord: The PID record created from the JSON object\n\n    Raises:\n        ValueError: If the JSON object is None or invalid\n    \"\"\"\n    logger.debug(\"Trying to extract PID record from JSON\", input_json)\n\n    if input_json is None:  # Check if the JSON object is None\n        raise ValueError(\"JSON must not be None\")\n\n    if \"pid\" not in input_json:  # Check if the JSON object contains a PID\n        raise ValueError(\"PID must be in JSON object\")\n\n    if \"entries\" not in input_json:  # Check if the JSON object contains entries\n        return PIDRecord(input_json[\"pid\"])\n    else:\n        entries = []\n\n        for key, value in input_json[\n            \"entries\"\n        ].items():  # Iterate over all entries in the JSON object\n            for entry in value:  # Iterate over all values of the entry. Each value consists of a dict with the keys \"key\", \"value\" and \"name\". Name is the only optional key.\n                if \"value\" not in entry or \"key\" not in entry:\n                    # Skip this entry if it does not contain a key or value\n                    logger.warning(\n                        f\"Skipping entry {entry} because it does not contain a key or value\"\n                    )\n                    continue\n                elif \"name\" in entry:\n                    # If the entry contains a name, add it to the PIDRecordEntry\n                    entries.append(\n                        PIDRecordEntry(key, entry[\"value\"], entry[\"name\"])\n                    )\n                else:\n                    # If the entry does not contain a name, add it without a name\n                    entries.append(PIDRecordEntry(key, entry[\"value\"]))\n\n        logger.debug(\n            f\"Extracted PID record from JSON: {PIDRecord(input_json['pid'], entries)}\"\n        )\n        return PIDRecord(input_json[\"pid\"], entries)\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/domain/pid_record/#nmr_FAIR_DOs.domain.pid_record.PIDRecord.merge","title":"merge","text":"<pre><code>merge(other: PIDRecord) -&gt; PIDRecord\n</code></pre> <p>Merges the PID record with another PID record</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>PIDRecord</code> <p>The PID record to merge with</p> required <p>Returns:</p> Name Type Description <code>PIDRecord</code> <code>PIDRecord</code> <p>The merged PID record</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the other PID record is None</p> Source code in <code>src/nmr_FAIR_DOs/domain/pid_record.py</code> <pre><code>def merge(self, other: \"PIDRecord\") -&gt; \"PIDRecord\":\n    \"\"\"\n    Merges the PID record with another PID record\n\n    Args:\n        other (PIDRecord): The PID record to merge with\n\n    Returns:\n        PIDRecord: The merged PID record\n\n    Raises:\n        ValueError: If the other PID record is None\n    \"\"\"\n    if other is None:  # Check if the other PID record is None\n        raise ValueError(\"Other PID record must not be None\")\n\n    if (\n        self._pid != other.getPID()\n    ):  # Check if the PID of both PID records is the same\n        raise ValueError(\"PID of both PID records must be the same\")\n\n    for (\n        key,\n        value,\n    ) in (\n        other.getEntries().items()\n    ):  # Iterate over all entries in the other PID record\n        for entry in value:  # Iterate over all values of the entry\n            if not self.entryExists(\n                key, entry.value\n            ):  # Check if the entry does not exist in this PID record\n                self.addPIDRecordEntry(entry)  # Add the entry to this PID record\n\n    return self  # Return the merged PID record\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/domain/pid_record_entry/","title":"pid_record_entry","text":""},{"location":"reference/nmr_FAIR_DOs/domain/pid_record_entry/#nmr_FAIR_DOs.domain.pid_record_entry.PIDRecordEntry","title":"PIDRecordEntry","text":"<p>               Bases: <code>dict</code></p> <p>Represents a PID record entry. For more information on the PID record format, see the documentation of the Typed PID Maker (https://kit-data-manager.github.io/webpage/typed-pid-maker/openapi.html). A PID record entry consists of a key, a value, and optionally a name.</p> <p>Attributes: key:str The key of the entry value:str The value of the entry name:str The name of the entry (optional)</p> Source code in <code>src/nmr_FAIR_DOs/domain/pid_record_entry.py</code> <pre><code>class PIDRecordEntry(dict):\n    \"\"\"\n    Represents a PID record entry.\n    For more information on the PID record format, see the documentation of the Typed PID Maker (https://kit-data-manager.github.io/webpage/typed-pid-maker/openapi.html).\n    A PID record entry consists of a key, a value, and optionally a name.\n\n    Attributes:\n    key:str The key of the entry\n    value:str The value of the entry\n    name:str The name of the entry (optional)\n    \"\"\"\n\n    key: str = None\n    value: str | dict = None\n    name: str = None\n\n    def __init__(self, key: str, value: str | dict, name: str = None):\n        \"\"\"\n        Creates a PID record entry\n\n        Args:\n            key:str The key of the entry\n            value:str The value of the entry\n            name:str The name of the entry (optional)\n\n        Raises:\n            ValueError: If the key is None or the value is None\n        \"\"\"\n\n        super().__init__()  # initialize the dictionary\n        if key is None:  # if key is None, raise an error\n            raise ValueError(f\"Key must not be None: {self.__repr__()}\")\n\n        if value is None:  # if value is None, raise an error\n            raise ValueError(f\"Value must not be None: {self.__repr__()}\")\n        elif not isinstance(value, str) and not isinstance(\n            value, dict\n        ):  # if value is not a string or a dictionary, log a warning\n            logger.warning(\n                f\"Value SHOULD be a string or a dictionary: {key}({name}), {value}\"\n            )\n\n        try:\n            if isinstance(value, str):  # if value is a JSON string, parse it\n                self.value = json.loads(value)\n            elif isinstance(value, dict):  # if value is a dictionary, use it as is\n                self.value = value\n            else:  # if the value is neither; parse as string\n                self.value = str(value)\n        except Exception as e:  # if parsing fails, log a warning\n            logger.debug(f\"Value is not a JSON string: {value}, {e}\")\n            self.value = value  # if value is not a JSON string, use it as is\n\n        self.key = key\n        self.name = name\n\n    def __getitem__(self, item):\n        \"\"\"\n        This method is called to get the value of the given key.\n        This enables the use of the dictionary syntax to access the key, value, and name of the PID record entry.\n        \"\"\"\n        if item == \"key\":\n            return self.key\n        elif item == \"value\":\n            return self.value\n        elif item == \"name\":\n            return self.name\n        else:\n            return None\n\n    def __str__(self):\n        return self.__repr__()\n\n    def __repr__(self):\n        val = (\n            json.dumps(self.value) if isinstance(self.value, dict) else self.value\n        )  # if the value is a dictionary, convert it to a JSON string\n        return json.dumps(\n            {\"key\": self.key, \"value\": val, \"name\": self.name}\n        )  # return the key, value, and name as a JSON string\n\n    def toJSON(self):\n        \"\"\"\n        Exports the PID record entry as JSON\n\n        Returns:\n        dict: The PID record entry as JSON\n        \"\"\"\n        val = json.dumps(self.value) if isinstance(self.value, dict) else self.value\n\n        if self.name is None:  # if the name is None, return only the key and value\n            return {\"key\": self.key, \"value\": val}\n        else:  # if the name is not None, return the key, value, and name\n            return {\"key\": self.key, \"value\": val, \"name\": self.name}\n\n    def __dict__(self):\n        val = json.dumps(self.value) if isinstance(self.value, dict) else self.value\n        return {\"key\": self.key, \"value\": val, \"name\": self.name}\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/domain/pid_record_entry/#nmr_FAIR_DOs.domain.pid_record_entry.PIDRecordEntry.__init__","title":"__init__","text":"<pre><code>__init__(key: str, value: str | dict, name: str = None)\n</code></pre> <p>Creates a PID record entry</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>str The key of the entry</p> required <code>value</code> <code>str | dict</code> <p>str The value of the entry</p> required <code>name</code> <code>str</code> <p>str The name of the entry (optional)</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the key is None or the value is None</p> Source code in <code>src/nmr_FAIR_DOs/domain/pid_record_entry.py</code> <pre><code>def __init__(self, key: str, value: str | dict, name: str = None):\n    \"\"\"\n    Creates a PID record entry\n\n    Args:\n        key:str The key of the entry\n        value:str The value of the entry\n        name:str The name of the entry (optional)\n\n    Raises:\n        ValueError: If the key is None or the value is None\n    \"\"\"\n\n    super().__init__()  # initialize the dictionary\n    if key is None:  # if key is None, raise an error\n        raise ValueError(f\"Key must not be None: {self.__repr__()}\")\n\n    if value is None:  # if value is None, raise an error\n        raise ValueError(f\"Value must not be None: {self.__repr__()}\")\n    elif not isinstance(value, str) and not isinstance(\n        value, dict\n    ):  # if value is not a string or a dictionary, log a warning\n        logger.warning(\n            f\"Value SHOULD be a string or a dictionary: {key}({name}), {value}\"\n        )\n\n    try:\n        if isinstance(value, str):  # if value is a JSON string, parse it\n            self.value = json.loads(value)\n        elif isinstance(value, dict):  # if value is a dictionary, use it as is\n            self.value = value\n        else:  # if the value is neither; parse as string\n            self.value = str(value)\n    except Exception as e:  # if parsing fails, log a warning\n        logger.debug(f\"Value is not a JSON string: {value}, {e}\")\n        self.value = value  # if value is not a JSON string, use it as is\n\n    self.key = key\n    self.name = name\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/domain/pid_record_entry/#nmr_FAIR_DOs.domain.pid_record_entry.PIDRecordEntry.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(item)\n</code></pre> <p>This method is called to get the value of the given key. This enables the use of the dictionary syntax to access the key, value, and name of the PID record entry.</p> Source code in <code>src/nmr_FAIR_DOs/domain/pid_record_entry.py</code> <pre><code>def __getitem__(self, item):\n    \"\"\"\n    This method is called to get the value of the given key.\n    This enables the use of the dictionary syntax to access the key, value, and name of the PID record entry.\n    \"\"\"\n    if item == \"key\":\n        return self.key\n    elif item == \"value\":\n        return self.value\n    elif item == \"name\":\n        return self.name\n    else:\n        return None\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/domain/pid_record_entry/#nmr_FAIR_DOs.domain.pid_record_entry.PIDRecordEntry.toJSON","title":"toJSON","text":"<pre><code>toJSON()\n</code></pre> <p>Exports the PID record entry as JSON</p> <p>Returns: dict: The PID record entry as JSON</p> Source code in <code>src/nmr_FAIR_DOs/domain/pid_record_entry.py</code> <pre><code>def toJSON(self):\n    \"\"\"\n    Exports the PID record entry as JSON\n\n    Returns:\n    dict: The PID record entry as JSON\n    \"\"\"\n    val = json.dumps(self.value) if isinstance(self.value, dict) else self.value\n\n    if self.name is None:  # if the name is None, return only the key and value\n        return {\"key\": self.key, \"value\": val}\n    else:  # if the name is not None, return the key, value, and name\n        return {\"key\": self.key, \"value\": val, \"name\": self.name}\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/repositories/","title":"repositories","text":"<p>This module contains all repositories for which FAIR DOs are created.</p> <p>The repositories are implemented as classes, which are derived from the abstract class Repository. The following repositories are implemented:</p> <ul> <li><code>ChemotionRepository</code>: A repository for the Chemotion repository. See https://chemotion-repository.net/ for more information.</li> <li><code>NMRXivRepository</code>: A repository for the NMRXiv repository. See https://nmrxiv.org/ for more information.</li> </ul>"},{"location":"reference/nmr_FAIR_DOs/repositories/AbstractRepository/","title":"AbstractRepository","text":""},{"location":"reference/nmr_FAIR_DOs/repositories/AbstractRepository/#nmr_FAIR_DOs.repositories.AbstractRepository.AbstractRepository","title":"AbstractRepository","text":"<p>               Bases: <code>ABC</code></p> <p>An abstract class representing a repository. It defines the methods that must be implemented by any repository class.</p> <p>Attributes:</p> Name Type Description <code>repositoryID</code> <code>str</code> <p>An identifier for the repository that is used to reference it internally. This is not exposed to the outside or published in an FAIR-DO. (abstract)</p> Source code in <code>src/nmr_FAIR_DOs/repositories/AbstractRepository.py</code> <pre><code>class AbstractRepository(ABC):\n    \"\"\"\n    An abstract class representing a repository.\n    It defines the methods that must be implemented by any repository class.\n\n    Attributes:\n        repositoryID (str): An identifier for the repository that is used to reference it internally. This is not exposed to the outside or published in an FAIR-DO. (abstract)\n    \"\"\"\n\n    @property\n    @abstractmethod\n    def repositoryID(self) -&gt; str:\n        \"\"\"\n        Returns an internal identifier for the repository.\n        This is not exposed to the outside or published in an FAIR-DO.\n\n        Returns:\n            str: The internal id of the repository\n        \"\"\"\n        return NotImplemented\n\n    @abstractmethod\n    async def getAllAvailableResources(self) -&gt; list[dict] | None:\n        \"\"\"\n        Returns a list of all resources available in the repository.\n\n        Returns:\n            list[dict]: A list of all resources available in the repository\n            None: If no resources are available in the repository\n        \"\"\"\n        # By default, return all resources available in the repository for the entire time frame from the beginning of time to the end of time\n        return await self.getResourcesForTimeFrame(datetime.min, datetime.max)\n\n    @abstractmethod\n    async def getResourcesForTimeFrame(\n        self, start: datetime, end: datetime\n    ) -&gt; list[dict]:\n        \"\"\"\n        Returns a list of all resources available in the repository within the specified time frame.\n\n        Args:\n            start (datetime): The start of the time frame\n            end (datetime): The end of the time frame\n\n        Returns:\n            list[dict]: A list of all resources available in the repository within the specified time frame\n        \"\"\"\n        return NotImplemented\n\n    @abstractmethod\n    async def extractPIDRecordFromResource(\n        self,\n        resource: dict,\n        add_relationship: Callable[\n            [str, list[PIDRecordEntry], Callable[[str], None] | None], str\n        ],\n    ) -&gt; PIDRecord | None:\n        \"\"\"\n        Extracts a PID record from a resource of the repository.\n        This method expects an `add_relationship` function that is used to create relationships between FAIR DOs.\n        For more information on the `add_relationship` function, see in ``lib.py``.\n        It expects the following arguments in the following order: (str, list[PIDRecordEntry], Callable[[str], None] | None) and returns the actual PID of the target FAIR-DO.\n        The first argument is the (presumed) PID of the target record.\n        The second argument is a list of entries to add to the target record.\n        Optionally, the third argument is a function that is executed on success of adding the entries to the target record.\n        It is meant to be used to create the back-reference relationship from the target record to the source record.\n\n        Args:\n            resource (dict): The resource to extract the PID record from\n            add_relationship (function): The function to add entries to a PIDRecord. This function expects the following arguments in the following order: (str, list[PIDRecordEntry], Callable[[str], None] | None) and returns a str.\n\n        Returns:\n            PIDRecord: The PID record extracted from the resource\n            None: If the PID record cannot be extracted from the resource\n        \"\"\"\n        return NotImplemented\n\n    @abstractmethod\n    def getRepositoryFDO(self) -&gt; PIDRecord:\n        \"\"\"\n        Define the PID record for the repository.\n        This record will be referenced by all extracted PID records from the repository in the \"hasPrimarySource\" relationship.\n\n        Returns:\n            PIDRecord: The PID record for the repository\n        \"\"\"\n        return NotImplemented\n\n    async def extractAll(\n        self,\n        urls: list[str],\n        addEntries: Callable[\n            [str, list[PIDRecordEntry], Callable[[str], None] | None], str\n        ],\n    ) -&gt; tuple[list[PIDRecord], list[dict]] | list[PIDRecord]:\n        \"\"\"\n        Extracts PID records from all resources available in the repository.\n\n        Args:\n            urls (list[str]): A list of URLs for all resources available in the repository. (Optional) If not provided, all available URLs will be fetched from the repository.\n            addEntries (function): The function to add entries to a PIDRecord. This function expects the following arguments in the following order: (str, list[PIDRecordEntry]) and returns a str. The first argument is the (presumed) PID of the target record, the second argument is a list of entries to add to the target record. It returns the PID of the target record.\n\n        Returns:\n            tuple[list[PIDRecord], list[dict[str, str]]]: A tuple containing a list of extracted PID records and a list of errors encountered during extraction\n            list[PIDRecord]: A list of extracted PID records\n        \"\"\"\n        resources = []\n\n        if urls is None or not isinstance(urls, list) or len(urls) == 0:\n            try:\n                resources = await self.getAllAvailableResources()\n            except Exception as e:\n                logger.error(\n                    f\"Error getting resources from repository {self.repositoryID}: {str(e)}\"\n                )\n                return []\n        else:\n            resources = await fetch_multiple(urls)\n\n        if resources is None or len(urls) == 0:\n            logger.warning(f\"No resources available for repository {self.repositoryID}\")\n            return []\n\n        pid_records: list[PIDRecord] = []\n        errors: list[dict] = []\n\n        for resource in resources:\n            try:\n                pid_record = await self.extractPIDRecordFromResource(\n                    resource,\n                    addEntries,\n                )\n                if pid_record is not None:\n                    pid_records.append(pid_record)\n            except Exception as e:\n                logger.error(f\"Error extracting PID record from {resource}: {str(e)}\")\n                errors.append(\n                    {\n                        \"url\": resource,\n                        \"error\": str(e),\n                        \"timestamp\": datetime.now().isoformat(),\n                    }\n                )\n\n        if errors:\n            return pid_records, errors\n        return pid_records\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/repositories/AbstractRepository/#nmr_FAIR_DOs.repositories.AbstractRepository.AbstractRepository.repositoryID","title":"repositoryID  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>repositoryID: str\n</code></pre> <p>Returns an internal identifier for the repository. This is not exposed to the outside or published in an FAIR-DO.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The internal id of the repository</p>"},{"location":"reference/nmr_FAIR_DOs/repositories/AbstractRepository/#nmr_FAIR_DOs.repositories.AbstractRepository.AbstractRepository.getAllAvailableResources","title":"getAllAvailableResources  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>getAllAvailableResources() -&gt; list[dict] | None\n</code></pre> <p>Returns a list of all resources available in the repository.</p> <p>Returns:</p> Name Type Description <code>list[dict] | None</code> <p>list[dict]: A list of all resources available in the repository</p> <code>None</code> <code>list[dict] | None</code> <p>If no resources are available in the repository</p> Source code in <code>src/nmr_FAIR_DOs/repositories/AbstractRepository.py</code> <pre><code>@abstractmethod\nasync def getAllAvailableResources(self) -&gt; list[dict] | None:\n    \"\"\"\n    Returns a list of all resources available in the repository.\n\n    Returns:\n        list[dict]: A list of all resources available in the repository\n        None: If no resources are available in the repository\n    \"\"\"\n    # By default, return all resources available in the repository for the entire time frame from the beginning of time to the end of time\n    return await self.getResourcesForTimeFrame(datetime.min, datetime.max)\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/repositories/AbstractRepository/#nmr_FAIR_DOs.repositories.AbstractRepository.AbstractRepository.getResourcesForTimeFrame","title":"getResourcesForTimeFrame  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>getResourcesForTimeFrame(\n    start: datetime, end: datetime\n) -&gt; list[dict]\n</code></pre> <p>Returns a list of all resources available in the repository within the specified time frame.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>datetime</code> <p>The start of the time frame</p> required <code>end</code> <code>datetime</code> <p>The end of the time frame</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of all resources available in the repository within the specified time frame</p> Source code in <code>src/nmr_FAIR_DOs/repositories/AbstractRepository.py</code> <pre><code>@abstractmethod\nasync def getResourcesForTimeFrame(\n    self, start: datetime, end: datetime\n) -&gt; list[dict]:\n    \"\"\"\n    Returns a list of all resources available in the repository within the specified time frame.\n\n    Args:\n        start (datetime): The start of the time frame\n        end (datetime): The end of the time frame\n\n    Returns:\n        list[dict]: A list of all resources available in the repository within the specified time frame\n    \"\"\"\n    return NotImplemented\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/repositories/AbstractRepository/#nmr_FAIR_DOs.repositories.AbstractRepository.AbstractRepository.extractPIDRecordFromResource","title":"extractPIDRecordFromResource  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>extractPIDRecordFromResource(\n    resource: dict,\n    add_relationship: Callable[\n        [\n            str,\n            list[PIDRecordEntry],\n            Callable[[str], None] | None,\n        ],\n        str,\n    ],\n) -&gt; PIDRecord | None\n</code></pre> <p>Extracts a PID record from a resource of the repository. This method expects an <code>add_relationship</code> function that is used to create relationships between FAIR DOs. For more information on the <code>add_relationship</code> function, see in <code>lib.py</code>. It expects the following arguments in the following order: (str, list[PIDRecordEntry], Callable[[str], None] | None) and returns the actual PID of the target FAIR-DO. The first argument is the (presumed) PID of the target record. The second argument is a list of entries to add to the target record. Optionally, the third argument is a function that is executed on success of adding the entries to the target record. It is meant to be used to create the back-reference relationship from the target record to the source record.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>dict</code> <p>The resource to extract the PID record from</p> required <code>add_relationship</code> <code>function</code> <p>The function to add entries to a PIDRecord. This function expects the following arguments in the following order: (str, list[PIDRecordEntry], Callable[[str], None] | None) and returns a str.</p> required <p>Returns:</p> Name Type Description <code>PIDRecord</code> <code>PIDRecord | None</code> <p>The PID record extracted from the resource</p> <code>None</code> <code>PIDRecord | None</code> <p>If the PID record cannot be extracted from the resource</p> Source code in <code>src/nmr_FAIR_DOs/repositories/AbstractRepository.py</code> <pre><code>@abstractmethod\nasync def extractPIDRecordFromResource(\n    self,\n    resource: dict,\n    add_relationship: Callable[\n        [str, list[PIDRecordEntry], Callable[[str], None] | None], str\n    ],\n) -&gt; PIDRecord | None:\n    \"\"\"\n    Extracts a PID record from a resource of the repository.\n    This method expects an `add_relationship` function that is used to create relationships between FAIR DOs.\n    For more information on the `add_relationship` function, see in ``lib.py``.\n    It expects the following arguments in the following order: (str, list[PIDRecordEntry], Callable[[str], None] | None) and returns the actual PID of the target FAIR-DO.\n    The first argument is the (presumed) PID of the target record.\n    The second argument is a list of entries to add to the target record.\n    Optionally, the third argument is a function that is executed on success of adding the entries to the target record.\n    It is meant to be used to create the back-reference relationship from the target record to the source record.\n\n    Args:\n        resource (dict): The resource to extract the PID record from\n        add_relationship (function): The function to add entries to a PIDRecord. This function expects the following arguments in the following order: (str, list[PIDRecordEntry], Callable[[str], None] | None) and returns a str.\n\n    Returns:\n        PIDRecord: The PID record extracted from the resource\n        None: If the PID record cannot be extracted from the resource\n    \"\"\"\n    return NotImplemented\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/repositories/AbstractRepository/#nmr_FAIR_DOs.repositories.AbstractRepository.AbstractRepository.getRepositoryFDO","title":"getRepositoryFDO  <code>abstractmethod</code>","text":"<pre><code>getRepositoryFDO() -&gt; PIDRecord\n</code></pre> <p>Define the PID record for the repository. This record will be referenced by all extracted PID records from the repository in the \"hasPrimarySource\" relationship.</p> <p>Returns:</p> Name Type Description <code>PIDRecord</code> <code>PIDRecord</code> <p>The PID record for the repository</p> Source code in <code>src/nmr_FAIR_DOs/repositories/AbstractRepository.py</code> <pre><code>@abstractmethod\ndef getRepositoryFDO(self) -&gt; PIDRecord:\n    \"\"\"\n    Define the PID record for the repository.\n    This record will be referenced by all extracted PID records from the repository in the \"hasPrimarySource\" relationship.\n\n    Returns:\n        PIDRecord: The PID record for the repository\n    \"\"\"\n    return NotImplemented\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/repositories/AbstractRepository/#nmr_FAIR_DOs.repositories.AbstractRepository.AbstractRepository.extractAll","title":"extractAll  <code>async</code>","text":"<pre><code>extractAll(\n    urls: list[str],\n    addEntries: Callable[\n        [\n            str,\n            list[PIDRecordEntry],\n            Callable[[str], None] | None,\n        ],\n        str,\n    ],\n) -&gt; tuple[list[PIDRecord], list[dict]] | list[PIDRecord]\n</code></pre> <p>Extracts PID records from all resources available in the repository.</p> <p>Parameters:</p> Name Type Description Default <code>urls</code> <code>list[str]</code> <p>A list of URLs for all resources available in the repository. (Optional) If not provided, all available URLs will be fetched from the repository.</p> required <code>addEntries</code> <code>function</code> <p>The function to add entries to a PIDRecord. This function expects the following arguments in the following order: (str, list[PIDRecordEntry]) and returns a str. The first argument is the (presumed) PID of the target record, the second argument is a list of entries to add to the target record. It returns the PID of the target record.</p> required <p>Returns:</p> Type Description <code>tuple[list[PIDRecord], list[dict]] | list[PIDRecord]</code> <p>tuple[list[PIDRecord], list[dict[str, str]]]: A tuple containing a list of extracted PID records and a list of errors encountered during extraction</p> <code>tuple[list[PIDRecord], list[dict]] | list[PIDRecord]</code> <p>list[PIDRecord]: A list of extracted PID records</p> Source code in <code>src/nmr_FAIR_DOs/repositories/AbstractRepository.py</code> <pre><code>async def extractAll(\n    self,\n    urls: list[str],\n    addEntries: Callable[\n        [str, list[PIDRecordEntry], Callable[[str], None] | None], str\n    ],\n) -&gt; tuple[list[PIDRecord], list[dict]] | list[PIDRecord]:\n    \"\"\"\n    Extracts PID records from all resources available in the repository.\n\n    Args:\n        urls (list[str]): A list of URLs for all resources available in the repository. (Optional) If not provided, all available URLs will be fetched from the repository.\n        addEntries (function): The function to add entries to a PIDRecord. This function expects the following arguments in the following order: (str, list[PIDRecordEntry]) and returns a str. The first argument is the (presumed) PID of the target record, the second argument is a list of entries to add to the target record. It returns the PID of the target record.\n\n    Returns:\n        tuple[list[PIDRecord], list[dict[str, str]]]: A tuple containing a list of extracted PID records and a list of errors encountered during extraction\n        list[PIDRecord]: A list of extracted PID records\n    \"\"\"\n    resources = []\n\n    if urls is None or not isinstance(urls, list) or len(urls) == 0:\n        try:\n            resources = await self.getAllAvailableResources()\n        except Exception as e:\n            logger.error(\n                f\"Error getting resources from repository {self.repositoryID}: {str(e)}\"\n            )\n            return []\n    else:\n        resources = await fetch_multiple(urls)\n\n    if resources is None or len(urls) == 0:\n        logger.warning(f\"No resources available for repository {self.repositoryID}\")\n        return []\n\n    pid_records: list[PIDRecord] = []\n    errors: list[dict] = []\n\n    for resource in resources:\n        try:\n            pid_record = await self.extractPIDRecordFromResource(\n                resource,\n                addEntries,\n            )\n            if pid_record is not None:\n                pid_records.append(pid_record)\n        except Exception as e:\n            logger.error(f\"Error extracting PID record from {resource}: {str(e)}\")\n            errors.append(\n                {\n                    \"url\": resource,\n                    \"error\": str(e),\n                    \"timestamp\": datetime.now().isoformat(),\n                }\n            )\n\n    if errors:\n        return pid_records, errors\n    return pid_records\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/repositories/chemotion/","title":"chemotion","text":""},{"location":"reference/nmr_FAIR_DOs/repositories/chemotion/#nmr_FAIR_DOs.repositories.chemotion.ChemotionRepository","title":"ChemotionRepository","text":"<p>               Bases: <code>AbstractRepository</code></p> <p>The ChemotionRepository class represents a repository to extract FAIR-DOs from the Chemotion repository (https://chemotion-repository.net).</p> <p>It implements the AbstractRepository class and defines the methods to extract FAIR-DOs from the Chemotion repository.</p> <p>Attributes:</p> Name Type Description <code>_baseURL</code> <code>str</code> <p>The base URL of the Chemotion repository. E.g. \"https://chemotion-repository.net\".</p> <code>_limit</code> <code>int</code> <p>The number of records to fetch in one request. Default is 1000.</p> Source code in <code>src/nmr_FAIR_DOs/repositories/chemotion.py</code> <pre><code>class ChemotionRepository(AbstractRepository):\n    \"\"\"\n    The ChemotionRepository class represents a repository to extract FAIR-DOs from the Chemotion repository (https://chemotion-repository.net).\n\n    It implements the AbstractRepository class and defines the methods to extract FAIR-DOs from the Chemotion repository.\n\n    Attributes:\n        _baseURL (str): The base URL of the Chemotion repository. E.g. \"https://chemotion-repository.net\".\n        _limit (int): The number of records to fetch in one request. Default is 1000.\n    \"\"\"\n\n    _baseURL: str\n\n    def __init__(self, baseURL: str, limit: int = 1000):\n        \"\"\"\n        Constructor for the ChemotionRepository class.\n\n        Args:\n            baseURL (str): The base URL of the Chemotion repository. E.g. \"https://chemotion-repository.net\".\n            limit (int): The number of records to fetch in one request. Default is 500.\n\n        \"\"\"\n        if not baseURL or baseURL == \"\":  # Check if the base URL is empty\n            raise ValueError(\"Base URL cannot be empty.\")\n\n        if (\n            not limit or limit is None or not isinstance(limit, int) or limit &lt;= 0\n        ):  # Check if the limit is a positive integer\n            raise ValueError(\"Limit must be a positive integer.\")\n\n        self._baseURL = baseURL\n        self._limit = limit\n        logger.debug(\n            f\"Created ChemotionRepository with baseURL: {baseURL} and limit: {limit}\"\n        )\n\n    @property\n    def repositoryID(self) -&gt; str:\n        return \"Chemotion_\" + self._baseURL\n\n    async def getResourcesForTimeFrame(\n        self, start: datetime, end: datetime\n    ) -&gt; list[dict]:\n        urls = await self._getAllURLs(\n            start, end\n        )  # Get all URLs for the specified time frame\n        return await fetch_multiple(urls)  # Fetch all resources from the URLs\n\n    async def extractPIDRecordFromResource(\n        self,\n        resource: dict,\n        add_relationship: Callable[\n            [str, list[PIDRecordEntry], Callable[[str], None] | None], str\n        ],\n    ) -&gt; PIDRecord | None:\n        if (\n            not resource\n            or resource is None\n            or resource == \"\"\n            or not isinstance(resource, dict)\n        ):  # Check if the resource is empty or not a dict\n            raise ValueError(\"Resource cannot be empty and must be a dict.\")\n\n        if (\n            not add_relationship\n            or add_relationship is None\n            or add_relationship == \"\"\n            or not callable(add_relationship)\n        ):  # Check if the add_relationship function is empty or not a function\n            raise ValueError(\"add_relationship function cannot be empty.\")\n\n        logger.debug(\n            f\"Extracted resource from Chemotion repository: {str(resource)[0:100]}\"\n        )\n\n        if resource[\"@type\"] == \"Dataset\":  # Check if the resource is a dataset\n            return await self._mapDataset2PIDRecord(\n                resource\n            )  # Map the dataset to a PID record\n        elif resource[\"@type\"] == \"Study\":  # Check if the resource is a study\n            return await self._mapStudy2PIDRecord(\n                resource, add_relationship\n            )  # Map the study to a PID record\n        else:\n            raise ValueError(\n                \"Invalid resource from Chemotion repository.\"\n            )  # Raise an error if the resource is not a dataset or study\n\n    async def _getAllURLs(self, start: datetime, end: datetime):\n        urls = []\n        urls.extend(\n            await self._getURLsForCategory(\"Container\", start, end)\n        )  # Get all URLs for the category \"Container\"\n        urls.extend(\n            await self._getURLsForCategory(\"Sample\", start, end)\n        )  # Get all URLs for the category \"Sample\"\n        return urls\n\n    async def _getURLsForCategory(\n        self, category: str, start: datetime, end: datetime\n    ) -&gt; list[str]:\n        \"\"\"\n        Get all URLs for a specific category and time frame.\n\n        Args:\n            category (str): The category to fetch the URLs for. Either \"Sample\" or \"Container\".\n            start (datetime): The start of the time frame.\n            end (datetime): The end of the time frame.\n\n        Returns:\n            list[str]: A list of URLs for the specified category and time frame.\n\n        Raises:\n            ValueError: If the category is invalid or the start and end date are invalid\n        \"\"\"\n        if (\n            not start\n            or not end\n            or start == \"\"\n            or end == \"\"\n            or start is None\n            or end is None\n            or not isinstance(start, datetime)\n            or not isinstance(end, datetime)\n        ):  # Check if the start and end date are empty or not a datetime\n            raise ValueError(\n                \"Start date and end date cannot be empty and must be a datetime.\"\n            )\n        if start &gt; end:  # Check if the start date is before the end date\n            raise ValueError(\"Start date must be before end date.\")\n        if start &gt; datetime.now():  # Check if the start date is in the future\n            raise ValueError(\"Start date must be in the past.\")\n\n        if (\n            not category or category == \"\" or category not in [\"Sample\", \"Container\"]\n        ):  # Check if the category is empty or not \"Sample\" or \"Container\"\n            raise ValueError(\n                \"Category cannot be empty and must be either 'Sample' or 'Container' .\"\n            )\n\n        # Create the URL template\n        url_template = Template(\n            \"$repositoryURL/api/v1/public/metadata/publications?type=$category&amp;offset=$offset&amp;limit=$limit&amp;date_from=$dateFrom&amp;date_to=$dateTo\"\n        )\n        offset = 0\n        complete = False\n        urls = []\n\n        while not complete:  # Loop until all entries are fetched\n            # Create the URL\n            url = url_template.safe_substitute(\n                repositoryURL=self._baseURL,\n                offset=offset,\n                limit=self._limit,\n                category=category,\n                dateFrom=f\"{start.year}-{start.month}-{start.day}\",\n                dateTo=f\"{end.year}-{end.month}-{end.day}\",\n            )\n            logger.debug(\"Getting frame \" + url)\n\n            # Fetch the data\n            response = await fetch_data(url, True)\n            if (\n                not response\n                or response is None\n                or not isinstance(response, dict)\n                or \"publications\" not in response\n            ):\n                raise ValueError(\"Invalid response from Chemotion repository.\")\n\n            # Add the URLs to the list\n            urls.extend(response[\"publications\"])\n\n            if len(response[\"publications\"]) != 0:\n                offset += (\n                    self._limit\n                )  # Increase the offset by the limit to fetch the next frame of urls\n            else:\n                complete = True  # If no more entries are found, stop the loop\n\n        # Log the number of URLs found and return them\n        logger.info(f\"found {len(urls)} urls\\n\\n\")\n        return urls\n\n    @staticmethod\n    def _extractContactField(field_name: str, json_object: dict) -&gt; list[str]:\n        \"\"\"\n        Extracts contacts from a field in a JSON object.\n\n        Args:\n            field_name (str): The name of the field to extract the contacts from.\n            json_object (dict): The JSON object to extract the contacts from.\n\n        Returns:\n            list[str]: A list of contact identifiers extracted from the field.\n        \"\"\"\n        contacts = []\n\n        def extractContact(contact_element: dict) -&gt; str | None:\n            \"\"\"\n            Extracts the identifier of a contact from a contact object.\n\n            Args:\n                contact_element (dict): The contact JSON object to extract the identifier from.\n\n            Returns:\n                str: The identifier of the contact\n            \"\"\"\n            if \"identifier\" in contact_element:\n                logger.debug(\n                    f\"Found identifier in identifier field {contact_element['identifier']}\"\n                )\n                return contact_element[\n                    \"identifier\"\n                ]  # get the identifier of the contact from the identifier field if it exists\n            elif \"@id\" in contact_element:\n                logger.debug(f\"Found identifier in @id field {contact_element['@id']}\")\n                return contact_element[\n                    \"@id\"\n                ]  # get the identifier of the contact from the @id field if it exists\n            return None\n\n        if field_name in json_object:\n            field = json_object[\n                field_name\n            ]  # get the field e.g. author, creator, contributor\n\n            if isinstance(field, list):  # if the field is a list of contacts\n                for element in field:  # iterate over the contacts\n                    logger.debug(\n                        f\"Extracting contact from {field_name} out of list\", element\n                    )\n                    identifier = extractContact(\n                        element\n                    )  # extract the identifier of the contact\n                    if identifier not in contacts and identifier is not None:\n                        logger.debug(f\"Adding contact {identifier} to contacts\")\n                        contacts.append(identifier)\n                    else:\n                        logger.debug(\n                            f\"Contact {identifier} already in contacts\", contacts\n                        )\n\n            elif isinstance(field, dict):  # if the field is a single contact\n                logger.debug(f\"Extracting contact from {field_name} out of dict\", field)\n                identifier = extractContact(\n                    field\n                )  # extract the identifier of the contact\n                if identifier not in contacts and identifier is not None:\n                    logger.debug(f\"Adding contact {identifier} to contacts\")\n                    contacts.append(identifier)\n                else:\n                    logger.debug(\n                        f\"Contact {identifier} already in contacts or is None\",\n                        contacts,\n                    )\n            else:\n                logger.debug(f\"Field {field_name} is not a list or dict\", field)\n        else:\n            logger.debug(f\"Field {field_name} not found in json\", json_object)\n\n        logger.debug(f\"Extracted contacts from {field_name}\", contacts)\n        return contacts\n\n    @staticmethod\n    def _mapGenericInfo2PIDRecord(chemotion_content) -&gt; PIDRecord:\n        \"\"\"\n        Maps generic information to a PID record.\n\n        Args:\n            chemotion_content (dict): The JSON response from the Chemotion API.\n\n        Returns:\n            PIDRecord: The PID record mapped from the generic information\n        \"\"\"\n        logger.debug(f\"Mapping generic info to PID Record: {chemotion_content['@id']}\")\n\n        fdo = PIDRecord(\n            encodeInBase64(chemotion_content[\"@id\"].replace(\"https://doi.org/\", \"\"))\n        )\n\n        fdo.addEntry(\n            \"21.T11148/076759916209e5d62bd5\",\n            \"21.T11148/b9b76f887845e32d29f7\",  # TODO: get the correct KIP PID; currently HelmholtzKIP\n            \"Kernel Information Profile\",\n        )\n\n        fdo.addEntry(\n            \"21.T11148/1c699a5d1b4ad3ba4956\",\n            \"21.T11148/ca9fd0b2414177b79ac2\",\n            \"digitalObjectType\",\n        )\n\n        fdo.addEntry(\n            \"21.T11148/b8457812905b83046284\",\n            f\"https://dx.doi.org/{chemotion_content['@id'].replace('https://doi.org/', '')}\",\n            \"digitalObjectLocation\",\n        )\n\n        # Generate a list of contacts from the author, creator, and contributor fields\n        contact = []\n        contact.extend(\n            ChemotionRepository._extractContactField(\"author\", chemotion_content)\n        )\n        contact.extend(\n            ChemotionRepository._extractContactField(\"creator\", chemotion_content)\n        )\n        contact.extend(\n            ChemotionRepository._extractContactField(\"contributor\", chemotion_content)\n        )\n        logger.debug(f\"Found {len(contact)} contacts\")\n\n        for (\n            contact_id\n        ) in contact:  # Iterate over the contacts and add them to the PID record\n            fdo.addEntry(\n                \"21.T11148/1a73af9e7ae00182733b\",\n                \"https://orcid.org/\" + contact_id,\n                \"contact\",\n            )\n\n        if (\n            \"dateModified\" in chemotion_content\n            and chemotion_content[\"dateModified\"] is not None\n        ):  # Add the dateModified to the PID record if it exists\n            fdo.addEntry(\n                \"21.T11148/397d831aa3a9d18eb52c\",\n                parseDateTime(chemotion_content[\"dateModified\"]).isoformat(),\n                \"dateModified\",\n            )\n\n        if (\n            \"dateCreated\" in chemotion_content\n            and chemotion_content[\"dateCreated\"] is not None\n        ):  # Add the dateCreated to the PID record if it exists\n            fdo.addEntry(\n                \"21.T11148/aafd5fb4c7222e2d950a\",\n                parseDateTime(chemotion_content[\"dateCreated\"]).isoformat(),\n                \"dateCreated\",\n            )\n\n        logger.debug(f\"Mapped generic info to FAIR-DO: {fdo.getPID()}\")\n        return fdo\n\n    @staticmethod\n    async def _mapDataset2PIDRecord(dataset) -&gt; PIDRecord:\n        \"\"\"\n        Maps a dataset to a PID record.\n\n        Args:\n            dataset (dict): The dataset to map to a PID record. This is the JSON response from the Chemotion API.\n\n        Returns:\n            PIDRecord: The PID record mapped from the dataset\n\n        Raises:\n            ValueError: If the provided data is not a dataset or is invalid\n        \"\"\"\n        if \"@type\" not in dataset or dataset[\"@type\"] != \"Dataset\":\n            raise ValueError(\n                \"Bad Request - The provided data is not a dataset\", dataset\n            )\n\n        logger.info(\"mapping dataset to FAIR-DO\", dataset[\"@id\"])\n        try:\n            fdo = ChemotionRepository._mapGenericInfo2PIDRecord(\n                dataset\n            )  # Start with the generic information\n\n            fdo.addEntry(\"21.T11969/b736c3898dd1f6603e2c\", \"Dataset\", \"resourceType\")\n\n            fdo.addEntry(\"21.T11148/6ae999552a0d2dca14d6\", dataset[\"name\"], \"name\")\n\n            fdo.addEntry(\n                \"21.T11969/8710d753ad10f371189b\", dataset[\"url\"], \"landingPageLocation\"\n            )\n\n            fdo.addEntry(\n                \"21.T11148/f3f0cbaa39fa9966b279\", dataset[\"identifier\"], \"identifier\"\n            )\n\n            if (\n                \"measurementTechnique\" in dataset\n            ):  # Add the measurement technique to the PID record if it exists\n                fdo.addEntry(\n                    \"21.T11969/7a19f6d5c8e63dd6bfcb\",\n                    dataset[\"measurementTechnique\"][\"@id\"],\n                    \"NMR method\",\n                )\n\n            fdo.addEntry(  # Add the license to the PID record\n                \"21.T11148/2f314c8fe5fb6a0063a8\",\n                await parseSPDXLicenseURL(dataset[\"license\"]),\n                \"license\",\n            )\n\n            if \"isPartOf\" in dataset and not fdo.entryExists(\n                \"21.T11148/aafd5fb4c7222e2d950a\"\n            ):\n                if (\n                    \"dateCreated\" in dataset[\"isPartOf\"]\n                ):  # Add the dateCreated of the parent dataset to the PID record if fdo does not already contain a dateCreated\n                    fdo.addEntry(\n                        \"21.T11148/aafd5fb4c7222e2d950a\",\n                        parseDateTime(dataset[\"isPartOf\"][\"dateCreated\"]).isoformat(),\n                        \"dateCreated\",\n                    )\n                elif (\n                    \"datePublished\" in dataset[\"isPartOf\"]\n                ):  # Add the datePublished of the parent dataset to the PID record if fdo does not already contain a dateCreated\n                    fdo.addEntry(\n                        \"21.T11148/aafd5fb4c7222e2d950a\",\n                        parseDateTime(dataset[\"isPartOf\"][\"datePublished\"]).isoformat(),\n                        \"dateCreated\",\n                    )\n\n            return fdo\n        except Exception as e:\n            logger.error(\"Error mapping dataset to FAIR-DO\", dataset, e)\n            raise e\n\n    @staticmethod\n    async def _mapStudy2PIDRecord(\n        study,\n        addRelationship: Callable[\n            [str, list[PIDRecordEntry], Callable[[str], None] | None], str\n        ],\n    ) -&gt; PIDRecord:\n        \"\"\"\n        Maps a study to a PID record.\n\n        Args:\n            study (dict): The study to map to a PID record. This is the JSON response from the Chemotion API.\n            addRelationship (function): The function to add entries to a PIDRecord. This function expects the following arguments in the following order: (str, list[PIDRecordEntry]) and returns a str. The first argument is the (presumed) PID of the target record, the second argument is a list of entries to add to the target record. It returns the PID of the target record.\n\n        Returns:\n            PIDRecord: The PID record mapped from the study\n\n        Raises:\n            ValueError: If the provided data is not a dataset or is invalid\n        \"\"\"\n\n        if \"@id\" not in study or study[\"@type\"] != \"Study\":\n            raise ValueError(\"Bad Request - The provided data is not a study\", study)\n\n        logger.info(\"mapping study to FAIR-DO\", study[\"@id\"])\n\n        try:\n            fdo = ChemotionRepository._mapGenericInfo2PIDRecord(study)\n\n            fdo.addEntry(\"21.T11969/b736c3898dd1f6603e2c\", \"Study\", \"resourceType\")\n\n            fdo.addEntry(\n                \"21.T11148/2f314c8fe5fb6a0063a8\",\n                await parseSPDXLicenseURL(study[\"includedInDataCatalog\"][\"license\"]),\n                \"license\",\n            )\n\n            if (\n                \"about\" not in study\n                or not isinstance(study[\"about\"], list)\n                or len(study[\"about\"]) == 0\n            ):  # Check if the study contains any datasets\n                raise ValueError(\"Study does not contain any datasets\", study)\n\n            for entry in study[\"about\"]:  # Iterate over the datasets in the study\n                if \"image\" in entry:  # Add the image to the PID record if it exists\n                    fdo.addEntry(\n                        \"21.T11148/7fdada5846281ef5d461\",\n                        entry[\"image\"],\n                        \"locationPreview\",\n                    )\n\n                if \"hasBioChemEntityPart\" in entry:\n                    parts = entry[\"hasBioChemEntityPart\"]\n                    if not isinstance(parts, list) or isinstance(parts, dict):\n                        parts = [parts]\n\n                    for (\n                        part\n                    ) in parts:  # Iterate over the parts of the dataset if they exist\n                        value = {}\n                        if (\n                            \"molecularWeight\" in part\n                            and \"value\" in part[\"molecularWeight\"]\n                            and part[\"molecularWeight\"][\"value\"] is not None\n                        ):  # add the molecular weight to the characterized compound if it exists\n                            value[\"21.T11969/6c4d3deac9a49b65886a\"] = float(\n                                part[\"molecularWeight\"][\"value\"]\n                            )\n                        if (\n                            \"url\" in part and part[\"url\"] is not None\n                        ):  # add the PubChem URL to the characterized compound if it exists\n                            value[\"21.T11969/f9cb9b53273ce0da7739\"] = part[\"url\"]\n\n                        if (\n                            len(value) &gt; 0\n                        ):  # Add the characterized compound to the PID record if any values were found\n                            fdo.addEntry(\n                                \"21.T11969/d15381199a44a16dc88d\",\n                                value,  # This is a dictionary of the values found\n                                \"characterizedCompound\",\n                            )\n                        else:\n                            logger.warning(\n                                f\"The provided part does not contain a molecularWeight or url: {part}\"\n                            )\n                if \"name\" in entry:  # Add the name to the PID record if it exists\n                    fdo.addEntry(\n                        \"21.T11148/6ae999552a0d2dca14d6\", entry[\"name\"], \"name\"\n                    )\n                if \"url\" in entry:  # Add the URL to the PID record if it exists\n                    fdo.addEntry(\n                        \"21.T11969/8710d753ad10f371189b\",\n                        entry[\"url\"],\n                        \"landingPageLocation\",\n                    )\n                if (\n                    \"identifier\" in entry\n                ):  # Add the identifier to the PID record if it exists\n                    fdo.addEntry(\n                        \"21.T11148/f3f0cbaa39fa9966b279\",\n                        entry[\"identifier\"],\n                        \"identifier\",\n                    )\n\n                if \"subjectOf\" in entry:\n                    for dataset in entry[\"subjectOf\"]:  # Iterate over the datasets\n                        presumedDatasetID = encodeInBase64(\n                            dataset[\"@id\"].replace(\"https://doi.org/\", \"\")\n                        )\n\n                        datasetEntries = [  # Prepare the dataset entries\n                            PIDRecordEntry(\n                                \"21.T11148/d0773859091aeb451528\",\n                                fdo.getPID(),\n                                \"hasMetadata\",\n                            )\n                        ]\n\n                        if (\n                            not fdo.entryExists(\"21.T11148/aafd5fb4c7222e2d950a\")\n                            and \"dateCreated\" in dataset\n                        ):  # Add the dateCreated to the PID record if it does not already exist but is found in the dataset\n                            fdo.addEntry(\n                                \"21.T11148/aafd5fb4c7222e2d950a\",\n                                parseDateTime(dataset[\"dateCreated\"]).isoformat(),\n                                \"dateCreated\",\n                            )\n\n                        if fdo.entryExists(\n                            \"21.T11148/7fdada5846281ef5d461\"\n                        ):  # Add the images to the dataset entries if they exist\n                            images = fdo.getEntry(\"21.T11148/7fdada5846281ef5d461\")\n                            logger.debug(f\"Found images in study {images}\")\n                            if images is not None and isinstance(images, list):\n                                datasetEntries.extend(images)\n                            elif images is not None and isinstance(\n                                images, PIDRecordEntry\n                            ):\n                                datasetEntries.append(images)\n\n                        if fdo.entryExists(\n                            \"21.T11969/d15381199a44a16dc88d\"\n                        ):  # Add the compounds to the dataset entries if they exist\n                            compounds = fdo.getEntry(\"21.T11969/d15381199a44a16dc88d\")\n                            logger.debug(f\"Found compounds in study {compounds}\")\n                            if compounds is not None and isinstance(compounds, list):\n                                datasetEntries.extend(compounds)\n                            elif compounds is not None and isinstance(\n                                compounds, PIDRecordEntry\n                            ):\n                                datasetEntries.append(compounds)\n\n                        try:  # Add the dataset reference to the study\n\n                            def add_metadata_entry(fdo_pid: str, pid: str) -&gt; None:\n                                \"\"\"\n                                Adds a metadata entry to the study.\n\n                                Args:\n                                    fdo_pid (str): The PID of the study.\n                                    pid (str): The PID of the dataset.\n\n                                Returns:\n                                    None\n                                \"\"\"\n                                if pid is not None:  # Ensure the PID is not None\n                                    addRelationship(\n                                        fdo_pid,  # Add the relationship between the study and the dataset\n                                        [\n                                            PIDRecordEntry(  # Add the relationship entry\n                                                \"21.T11148/4fe7cde52629b61e3b82\",\n                                                pid,\n                                                \"isMetadataFor\",\n                                            )\n                                        ],\n                                        None,  # No callback function\n                                    )\n\n                            addRelationship(  # Add the dataset entries to the dataset\n                                presumedDatasetID,  # presumed PID of the dataset\n                                datasetEntries,  # dataset entries as defined above\n                                lambda pid: add_metadata_entry(\n                                    fdo.getPID(), pid\n                                ),  # callback function to add the dataset reference to the study after the relationship has been added\n                            )\n                        except Exception as e:  # Log an error if the dataset reference could not be added to the study\n                            logger.error(\n                                \"Error adding dataset reference to study\",\n                                presumedDatasetID,\n                                datasetEntries,\n                                e,\n                            )\n\n            return fdo\n        except Exception as e:\n            print(\"Error mapping study to FAIR-DO\", study, e)\n            raise e\n\n    def getRepositoryFDO(self) -&gt; PIDRecord:\n        fdo = PIDRecord(encodeInBase64(self._baseURL))\n        fdo.addEntry(\n            \"21.T11148/076759916209e5d62bd5\",\n            \"21.T11148/b9b76f887845e32d29f7\",  # TODO: get the correct KIP PID; currently HelmholtzKIP\n            \"Kernel Information Profile\",\n        )\n        fdo.addEntry(\n            \"21.T11148/1c699a5d1b4ad3ba4956\",\n            \"21.T11148/010acb220a9c2c8c0ee6\",  # TODO: text/html for now\n            \"digitalObjectType\",\n        )\n\n        fdo.addEntry(\n            \"21.T11148/b8457812905b83046284\",\n            self._baseURL,\n            \"digitalObjectLocation\",\n        )\n\n        fdo.addEntry(\n            \"21.T11969/8710d753ad10f371189b\",\n            self._baseURL,\n            \"landingPageLocation\",\n        )\n\n        fdo.addEntry(\n            \"21.T11148/aafd5fb4c7222e2d950a\",\n            datetime.now().isoformat(),\n            \"dateCreated\",\n        )\n\n        fdo.addEntry(\n            \"21.T11148/6ae999552a0d2dca14d6\",\n            \"Chemotion Repository\",\n            \"name\",\n        )\n\n        fdo.addEntry(\n            \"21.T11148/7fdada5846281ef5d461\",\n            \"https://www.chemotion-repository.net/images/repo/Chemotion-V1.png\",\n            \"locationPreview\",\n        )\n\n        fdo.addEntry(\"21.T11969/b736c3898dd1f6603e2c\", \"Repository\", \"resourceType\")\n\n        return fdo\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/repositories/chemotion/#nmr_FAIR_DOs.repositories.chemotion.ChemotionRepository.__init__","title":"__init__","text":"<pre><code>__init__(baseURL: str, limit: int = 1000)\n</code></pre> <p>Constructor for the ChemotionRepository class.</p> <p>Parameters:</p> Name Type Description Default <code>baseURL</code> <code>str</code> <p>The base URL of the Chemotion repository. E.g. \"https://chemotion-repository.net\".</p> required <code>limit</code> <code>int</code> <p>The number of records to fetch in one request. Default is 500.</p> <code>1000</code> Source code in <code>src/nmr_FAIR_DOs/repositories/chemotion.py</code> <pre><code>def __init__(self, baseURL: str, limit: int = 1000):\n    \"\"\"\n    Constructor for the ChemotionRepository class.\n\n    Args:\n        baseURL (str): The base URL of the Chemotion repository. E.g. \"https://chemotion-repository.net\".\n        limit (int): The number of records to fetch in one request. Default is 500.\n\n    \"\"\"\n    if not baseURL or baseURL == \"\":  # Check if the base URL is empty\n        raise ValueError(\"Base URL cannot be empty.\")\n\n    if (\n        not limit or limit is None or not isinstance(limit, int) or limit &lt;= 0\n    ):  # Check if the limit is a positive integer\n        raise ValueError(\"Limit must be a positive integer.\")\n\n    self._baseURL = baseURL\n    self._limit = limit\n    logger.debug(\n        f\"Created ChemotionRepository with baseURL: {baseURL} and limit: {limit}\"\n    )\n</code></pre>"},{"location":"reference/nmr_FAIR_DOs/repositories/nmrxiv/","title":"nmrxiv","text":""},{"location":"reference/nmr_FAIR_DOs/repositories/nmrxiv/#nmr_FAIR_DOs.repositories.nmrxiv.NMRXivRepository","title":"NMRXivRepository","text":"<p>               Bases: <code>AbstractRepository</code></p> <p>This class creates FAIR-DOs for the contents of the NMRXiv repository. See https://nmrxiv.org/ for more information. The class is derived from the abstract class AbstractRepository.</p> <p>Attributes:</p> Name Type Description <code>_baseURL</code> <code>str</code> <p>The base URL of the NMRXiv repository.</p> <code>_terminology</code> <code>Terminology</code> <p>The terminology service used to map terms to ontology items.</p> <code>_fetch_fresh</code> <code>bool</code> <p>A flag indicating whether to fetch fresh data from the repository or use a cached version.</p> Source code in <code>src/nmr_FAIR_DOs/repositories/nmrxiv.py</code> <pre><code>class NMRXivRepository(AbstractRepository):\n    \"\"\"\n    This class creates FAIR-DOs for the contents of the NMRXiv repository. See https://nmrxiv.org/ for more information.\n    The class is derived from the abstract class AbstractRepository.\n\n    Attributes:\n        _baseURL (str): The base URL of the NMRXiv repository.\n        _terminology (Terminology): The terminology service used to map terms to ontology items.\n        _fetch_fresh (bool): A flag indicating whether to fetch fresh data from the repository or use a cached version.\n    \"\"\"\n\n    _baseURL: str\n\n    def __init__(\n        self, baseURL: str, terminology: Terminology, fetch_fresh: bool = True\n    ) -&gt; None:\n        if baseURL is not None and isinstance(\n            baseURL, str\n        ):  # Check if the baseURL is valid\n            self._baseURL = baseURL\n        else:  # use the default baseURL\n            self._baseURL = \"https://nmrxiv.org\"\n\n        if terminology is not None and isinstance(\n            terminology, Terminology\n        ):  # Check if the terminology is valid\n            self._terminology = terminology\n        else:\n            raise ValueError(\"Terminology must be an instance of Terminology\")\n\n        self._fetch_fresh = (\n            fetch_fresh if fetch_fresh is not None else True\n        )  # Set the fetch_fresh flag to the provided value or True if no value was provided\n\n    @property\n    def repositoryID(self) -&gt; str:\n        return \"NMRXiv_\" + self._baseURL\n\n    async def getResourcesForTimeFrame(\n        self, start: datetime, end: datetime\n    ) -&gt; list[dict]:\n        result: list[dict] = []\n\n        if not self._fetch_fresh:\n            with open(\"nmrxiv_resources.json\", \"r\") as r:\n                result = json.load(r)  # Load the cached data\n                if result is None or not isinstance(result, list):\n                    logger.error(\"Invalid resources file. Fetching from scratch...\")\n                    self._fetch_fresh = (\n                        True  # If the cached data is invalid, fetch fresh data\n                    )\n                else:\n                    return result\n\n        if (\n            self._fetch_fresh or not os.path.isfile(\"nmrxiv_resources.json\")\n        ):  # Check if the data should be fetched fresh or if a cached version is not available\n            result.extend(\n                await self._getResourcesForCategory(\"datasets\", start, end)\n            )  # Fetch the datasets\n            result.extend(\n                await self._getResourcesForCategory(\"samples\", start, end)\n            )  # Fetch the samples\n            result.extend(\n                await self._getResourcesForCategory(\"projects\", start, end)\n            )  # Fetch the projects\n\n            with open(\n                \"nmrxiv_resources.json\", \"w\"\n            ) as r:  # Write the fetched data to a file for caching. This is recommended since NMRXiv doesn't provide an API for getting just the URLs with a timestamp...\n                json.dump(result, r)\n        return result\n\n    async def extractPIDRecordFromResource(\n        self,\n        resource: dict,\n        add_relationship: Callable[\n            [str, list[PIDRecordEntry], Callable[[str], None] | None], str\n        ],\n    ) -&gt; PIDRecord | None:\n        if (\n            not resource or resource is None or not isinstance(resource, dict)\n        ):  # Check if the resource is valid\n            raise ValueError(\"Invalid resource.\")\n        elif (\n            \"original\" not in resource or \"bioschema\" not in resource\n        ):  # Check if the resource contains the original and bioschema data\n            raise ValueError(\"Resource is missing original or bioschema data.\")\n\n        if \"doi\" not in resource[\"original\"]:  # Check if the resource has a DOI\n            raise ValueError(\"Resource has no DOI.\")\n\n        first_letter_type_indicator = resource[\n            \"original\"\n        ][\n            \"identifier\"\n        ].replace(\n            \"NMRXIV:\", \"\"\n        )[\n            0\n        ]  # Get the first letter of the identifier to determine the type of the resource\n\n        if first_letter_type_indicator == \"D\":  # Check if the resource is a dataset\n            return await self._mapDatasetToPIDRecord(resource)\n        elif first_letter_type_indicator == \"S\":  # Check if the resource is a sample\n            return await self._mapSampleToPIDRecord(resource, add_relationship)\n        elif first_letter_type_indicator == \"P\":  # Check if the resource is a project\n            return await self._mapProjectToPIDRecord(resource, add_relationship)\n        else:  # If the resource is neither a dataset nor a sample nor a project, raise an error\n            raise ValueError(\n                \"Resource is neither a dataset nor a sample nor a project.\", resource\n            )\n\n    async def _getResourcesForCategory(\n        self, category: str, start: datetime, end: datetime\n    ) -&gt; list[dict]:\n        \"\"\"\n        Get all resources of the specified category that were created or updated in the specified time frame.\n\n        Args:\n            category (str): The category of the resources. Must be either \"datasets\" or \"samples\".\n            start (datetime): The start date of the time frame.\n            end (datetime): The end date of the time frame.\n\n        Returns:\n            list[dict]: A list of resources that were created or updated in the specified time frame.\n\n        Raises:\n            ValueError: If the category is invalid or the start or end date is invalid.\n        \"\"\"\n        if (\n            not start\n            or not end\n            or start == \"\"\n            or end == \"\"\n            or start is None\n            or end is None\n            or not isinstance(start, datetime)\n            or not isinstance(end, datetime)\n        ):  # Check if the start and end date are valid\n            raise ValueError(\n                \"Start date and end date cannot be empty and must be a datetime.\"\n            )\n        if start &gt; end:  # Check if the start date is before the end date\n            raise ValueError(\"Start date must be before end date.\")\n        if start &gt; datetime.now():  # Check if the start date is in the past\n            raise ValueError(\"Start date must be in the past.\")\n\n        if (\n            not category\n            or category == \"\"\n            or category not in [\"datasets\", \"samples\", \"projects\"]\n        ):  # Check if the category is valid\n            raise ValueError(\n                \"Category cannot be empty and must be either 'datasets' or 'samples' .\"\n            )\n\n        # Remove the timezone information from the datetime objects\n        start = start.replace(tzinfo=None)\n        end = end.replace(tzinfo=None)\n\n        # Create the URL\n        url = f\"{self._baseURL}/api/v1/list/{category}\"\n        complete = False\n        objects: list[dict] = []\n\n        while not complete:  # Loop until all entries are fetched\n            # Create the URL\n            logger.debug(\"Getting frame \" + url)\n\n            # Fetch the data\n            response = await fetch_data(url, True)\n            if (\n                not response\n                or response is None\n                or not isinstance(response, dict)\n                or \"data\" not in response\n            ):  # Check if the response is valid\n                raise ValueError(\"Invalid response from NMRXiv repository.\")\n\n            for elem in response[\"data\"]:\n                created = (\n                    parseDateTime(elem[\"created_at\"]).replace(tzinfo=None)\n                    if \"created_at\" in elem\n                    else None\n                )  # Extract the creation date\n                updated = (\n                    parseDateTime(elem[\"updated_at\"]).replace(tzinfo=None)\n                    if \"updated_at\" in elem\n                    else None\n                )  # Extract the update date, if available\n\n                try:\n                    if created is None:  # This should never happen\n                        logger.debug(f\"Resource {elem['doi']} has no creation date.\")\n                        raise ValueError(\n                            f\"Resource {elem['doi']} has no creation date.\", elem\n                        )\n                    elif (\n                        start &lt;= created &lt;= end\n                    ):  # Check if the creation date is in the timerange\n                        logger.debug(\n                            f\"Creation date of the resource {elem['doi']} is in the timerange.\"\n                        )\n                        objects.append(\n                            await self._getBioChemIntegratedDict(elem)\n                        )  # add the resource to the list of objects to return\n                    elif (\n                        updated is not None and start &lt;= updated &lt;= end\n                    ):  # Check if the update date is in the timerange (if available)\n                        logger.debug(\n                            f\"Update date of the resource {elem['doi']} is in the timerange.\"\n                        )\n                        objects.append(\n                            await self._getBioChemIntegratedDict(elem)\n                        )  # add the resource to the list of objects to return\n                    else:\n                        logger.debug(f\"Resource {elem['doi']} is not in the timerange.\")\n                        continue\n                except (\n                    Exception\n                ) as e:  # Log the error and continue with the next resource\n                    logger.error(\n                        f\"Error fetching BioSchema for resource {elem['doi']}: {str(e)}\",\n                        elem,\n                        e,\n                    )\n\n            next_url = response[\"links\"][\"next\"]  # Get the URL of the next page\n\n            if (\n                not next_url or next_url == \"\" or next_url == \"null\"\n            ):  # Check if there are more pages by looking at the \"next\" link\n                complete = True  # If there are no more pages, stop the loop\n                logger.debug(\"Finished fetching all resources for \" + category)\n            else:\n                url = next_url  # If there are more pages, get the next page\n\n        # Log the number of URLs found and return them\n        logger.info(f\"found {len(objects)} urls\\n\")\n        return objects\n\n    async def _getBioChemIntegratedDict(self, elem: dict) -&gt; dict:\n        \"\"\"\n        Fetches the JSON-LD representation of the BioSchema for the specified ID.\n\n        Args:\n            elem (dict): The element to fetch the BioSchema for.\n\n        Returns:\n            dict: The JSON-LD representation of the BioSchema.\n\n        Raises:\n            ValueError: If the ID is invalid or the BioSchema cannot be fetched.\n        \"\"\"\n        identifier = elem[\"identifier\"].replace(\n            \"NMRXIV:\", \"\"\n        )  # Remove the NMRXIV: prefix from the identifier\n        if not identifier or identifier == \"\" or not isinstance(identifier, str):\n            raise ValueError(\"Invalid ID. Please provide a valid ID.\", identifier, elem)\n\n        template = Template(\"$repositoryURL/api/v1/schemas/bioschemas/$id\")\n        url = template.safe_substitute(repositoryURL=self._baseURL, id=identifier)\n        logger.debug(\"Getting BioSchema JSON for \" + url)\n\n        bioschema = await fetch_data(url)  # Fetch the BioSchema JSON\n\n        if not bioschema or bioschema is None or not isinstance(bioschema, dict):\n            raise ValueError(\"Invalid BioSchema JSON.\", bioschema, url)\n\n        return {\n            \"original\": self._removeDescription(\n                elem\n            ),  # Remove the description from the original data to save memory and have a cleaner output\n            \"bioschema\": self._removeDescription(\n                bioschema\n            ),  # Remove the description from the BioSchema to save memory and have a cleaner output\n        }\n\n    @staticmethod\n    async def _mapGenericInfo2PIDRecord(resource) -&gt; PIDRecord:\n        \"\"\"\n        Maps generic information to a PID record.\n\n        Args:\n            resource (dict): The JSON response from the NMRXiv API.\n\n        Returns:\n            PIDRecord: The PID record mapped from the generic information\n        \"\"\"\n        try:\n            original_resource = resource[\"original\"]\n            bioschema_resource = resource[\"bioschema\"]\n\n            logger.debug(\n                f\"Mapping generic info to PID Record: {original_resource['doi']}\"\n            )\n            fdo = PIDRecord(encodeInBase64(original_resource[\"doi\"]))\n\n            fdo.addEntry(\n                \"21.T11148/076759916209e5d62bd5\",\n                \"21.T11148/b9b76f887845e32d29f7\",  # TODO: get the correct KIP PID; currently HelmholtzKIP\n                \"Kernel Information Profile\",\n            )\n\n            fdo.addEntry(\n                \"21.T11148/1c699a5d1b4ad3ba4956\",\n                \"21.T11148/ca9fd0b2414177b79ac2\",  # TODO: get the correct digitalObjectType; currently application/json\n                \"digitalObjectType\",\n            )\n\n            if (\n                \"created_at\" in original_resource\n                and original_resource[\"created_at\"] is not None\n            ):  # Add the creation date to the PID record if available\n                fdo.addEntry(\n                    \"21.T11148/aafd5fb4c7222e2d950a\",\n                    parseDateTime(original_resource[\"created_at\"]).isoformat(),\n                    \"dateCreated\",\n                )\n\n            if (\n                \"updated_at\" in original_resource\n                and original_resource[\"updated_at\"] is not None\n            ):  # Add the update date to the PID record if available\n                fdo.addEntry(\n                    \"21.T11148/397d831aa3a9d18eb52c\",\n                    parseDateTime(original_resource[\"updated_at\"]).isoformat(),\n                    \"dateModified\",\n                )\n\n            if (\n                \"name\" in original_resource\n            ):  # Add the name of the resource to the PID record\n                fdo.addEntry(\n                    \"21.T11148/6ae999552a0d2dca14d6\", original_resource[\"name\"], \"name\"\n                )\n\n            fdo.addEntry(\n                \"21.T11148/f3f0cbaa39fa9966b279\",\n                original_resource[\"doi\"].replace(\"https://doi.org/\", \"\"),\n                \"identifier\",\n            )\n\n            if (\n                \"license\" in original_resource\n                and \"spdx_id\" in original_resource[\"license\"]\n                and original_resource[\"license\"][\"spdx_id\"] is not None\n            ):  # Add the license to the PID record if available\n                fdo.addEntry(\n                    \"21.T11148/2f314c8fe5fb6a0063a8\",\n                    await parseSPDXLicenseURL(\n                        original_resource[\"license\"][\"spdx_id\"]\n                    ),  # Get the SPDX URL for the license\n                    \"license\",\n                )\n            elif (\n                \"license\" in bioschema_resource\n                and bioschema_resource[\"license\"] is not None\n            ):  # Add the license to the PID record if available\n                fdo.addEntry(\n                    \"21.T11148/2f314c8fe5fb6a0063a8\",\n                    await parseSPDXLicenseURL(\n                        bioschema_resource[\"license\"]\n                    ),  # Get the SPDX URL for the license\n                    \"license\",\n                )\n\n            if \"authors\" in original_resource and isinstance(\n                original_resource[\"authors\"], list\n            ):  # Add the authors to the PID record if available\n                for author in original_resource[\"authors\"]:\n                    if \"orcid_id\" in author:\n                        fdo.addEntry(\n                            \"21.T11148/1a73af9e7ae00182733b\",\n                            \"https://orcid.org/\"\n                            + author[\"orcid_id\"],  # Get the ORCiD URL\n                            \"contact\",\n                        )\n                    elif \"email\" in author:\n                        fdo.addEntry(\n                            \"21.T11148/e117a4a29bfd07438c1e\",\n                            author[\n                                \"email\"\n                            ],  # Add the email to the PID record if no ORCiD is available\n                            \"emailContact\",\n                        )\n            elif (\n                \"owner\" in original_resource and \"email\" in original_resource[\"owner\"]\n            ):  # Add the owner to the PID record if available and no authors are available\n                fdo.addEntry(\n                    \"21.T11148/e117a4a29bfd07438c1e\",\n                    original_resource[\"owner\"][\"email\"],\n                    \"emailContact\",\n                )\n            elif (\n                \"users\" in original_resource\n            ):  # Add the users to the PID record if available and no authors or owners are available\n                for user in original_resource[\"users\"]:\n                    if \"email\" in user:\n                        fdo.addEntry(\n                            \"21.T11148/e117a4a29bfd07438c1e\",\n                            user[\"email\"],\n                            \"emailContact\",\n                        )\n\n            if (\n                \"download_url\" in original_resource\n                and original_resource[\"download_url\"] is not None\n            ):  # Add the download URL to the PID record if available (for samples and projects)\n                fdo.addEntry(\n                    \"21.T11148/b8457812905b83046284\",\n                    original_resource[\"download_url\"],\n                    \"digitalObjectLocation\",\n                )\n            else:  # Add the DOI to the PID record if no download URL is available\n                fdo.addEntry(\n                    \"21.T11148/b8457812905b83046284\",\n                    f\"https://dx.doi.org/{original_resource['doi'].replace('https://doi.org/', '')}\",\n                    \"digitalObjectLocation\",\n                )\n\n            logger.debug(f\"Mapped generic info to FAIR-DO: {fdo.getPID()}\")\n            return fdo\n        except Exception as e:  # Log the error and raise it\n            logger.error(f\"Error mapping generic info to FAIR-DO: {str(e)}\", resource)\n            raise ValueError(\n                f\"Error mapping generic info to FAIR-DO: {str(e)}\", resource\n            )\n\n    async def _mapDatasetToPIDRecord(self, dataset: dict) -&gt; PIDRecord:\n        \"\"\"\n        Maps a dataset to a PID record.\n\n        Args:\n            dataset (dict): The dataset to map to a PID record. Contains the original and BioSchema data.\n\n        Returns:\n            PIDRecord: The PID record mapped from the dataset.\n        \"\"\"\n        # Extract the original and BioSchema data from the dataset\n        original_dataset = dataset[\"original\"]\n        bioschema_dataset = dataset[\"bioschema\"]\n\n        if (\n            not original_dataset\n            or original_dataset is None\n            or not isinstance(original_dataset, dict)\n            or not original_dataset[\"identifier\"].startswith(\"NMRXIV:D\")\n            or \"@type\" not in bioschema_dataset\n            or bioschema_dataset[\"@type\"] != \"Dataset\"\n        ):  # Check if the dataset is valid\n            raise ValueError(\n                \"Bad Request - The provided data is not a dataset\", dataset\n            )\n\n        try:\n            logger.info(f\"mapping dataset to FAIR-DO: {bioschema_dataset['@id']}\")\n            fdo = await self._mapGenericInfo2PIDRecord(\n                dataset\n            )  # Get the generic information for the dataset\n\n            fdo.addEntry(\n                \"21.T11969/b736c3898dd1f6603e2c\",\n                \"Dataset\",\n                \"resourceType\",\n            )\n\n            if \"measurementTechnique\" in bioschema_dataset and isinstance(\n                bioschema_dataset[\"measurementTechnique\"], dict\n            ):  # Add the measurement technique to the PID record if available\n                if \"url\" in bioschema_dataset[\"measurementTechnique\"]:\n                    fdo.addEntry(\n                        \"21.T11969/7a19f6d5c8e63dd6bfcb\",\n                        bioschema_dataset[\"measurementTechnique\"][\"url\"],\n                        \"NMR method\",\n                    )\n                else:\n                    logger.info(\n                        f\"Measurement technique in entry {bioschema_dataset['@id']} has no URL: {bioschema_dataset['measurementTechnique']}\"\n                    )\n\n            if (\n                \"public_url\" in original_dataset\n                and original_dataset[\"public_url\"] is not None\n            ):  # Add the public URL to the PID record as a landing page if available\n                fdo.addEntry(\n                    \"21.T11969/8710d753ad10f371189b\",\n                    original_dataset[\"public_url\"],\n                    \"landingPageLocation\",\n                )\n            elif (\n                \"url\" in bioschema_dataset and bioschema_dataset[\"url\"] is not None\n            ):  # Add the URL to the PID record as a landing page if available\n                fdo.addEntry(\n                    \"21.T11969/8710d753ad10f371189b\",\n                    bioschema_dataset[\"url\"],\n                    \"landingPageLocation\",\n                )\n\n            if (\n                \"dataset_photo_url\" in original_dataset\n                and original_dataset[\"dataset_photo_url\"] is not None\n            ):  # Add the dataset photo URL to the PID record as a preview if available\n                fdo.addEntry(\n                    \"21.T11148/7fdada5846281ef5d461\",\n                    original_dataset[\"dataset_photo_url\"],\n                    \"locationPreview\",\n                )\n\n            if \"variableMeasured\" in bioschema_dataset and isinstance(\n                bioschema_dataset[\"variableMeasured\"], list\n            ):\n                for variable in bioschema_dataset[\n                    \"variableMeasured\"\n                ]:  # Iterate over the measured variables\n                    try:\n                        if (\n                            \"name\" not in variable or \"value\" not in variable\n                        ):  # Check if the variable has a name and a value\n                            logger.warning(\n                                f\"Skipping variable {variable} because it has no name or value\"\n                            )\n                            continue\n\n                        name = variable[\"name\"]\n                        values = variable[\"value\"]\n\n                        if values is None:  # Check if the value is valid\n                            logger.warning(\n                                f\"Skipping variable {name} because it has no value\"\n                            )\n                            continue\n                        elif not isinstance(values, list):\n                            values = [values]\n\n                        for value in values:  # Iterate over the values of the variable\n                            if not isinstance(value, str):\n                                logger.warning(\n                                    f\"Skipping variable {name} because value {value} is not a string\"\n                                )\n                                continue\n                            logger.debug(\n                                f\"Evaluating variable {name} with value {value}\"\n                            )\n\n                            if (\n                                name == \"NMR solvent\"\n                            ):  # Check if the variable is the NMR solvent\n                                ontology_item = await self._terminology.searchForTerm(\n                                    value,\n                                    \"chebi\",\n                                    \"http://purl.obolibrary.org/obo/CHEBI_197449\",  # Has to be a child of \"nmrSolvent\"\n                                )  # Search for the term in the ChEBI ontology with the terminology service\n                                if (\n                                    ontology_item is not None\n                                ):  # Add the ontology item to the PID record if available\n                                    fdo.addEntry(\n                                        \"21.T11969/92b4c6b461709b5b36f5\",\n                                        ontology_item,\n                                        \"NMR solvent\",\n                                    )\n                            elif (\n                                name == \"acquisition nucleus\"\n                            ):  # Check if the variable is the acquisition nucleus\n                                ontology_item = await self._terminology.searchForTerm(\n                                    value,\n                                    \"chebi\",\n                                    \"http://purl.obolibrary.org/obo/CHEBI_33250\",  # has to be an atom\n                                )  # Search for the term in the ChEBI ontology with the terminology service\n                                if ontology_item is not None:\n                                    fdo.addEntry(\n                                        \"21.T11969/1058eae15dac10260bb6\",\n                                        ontology_item,\n                                        \"Aquisition Nucleus\",\n                                    )\n                            elif (\n                                name == \"irridation frequency\"\n                            ):  # Check if the variable is the irradiation frequency\n                                fdo.addEntry(\n                                    \"21.T11969/1e6e84562ace3b58558d\",\n                                    value,\n                                    \"Nominal Proton Frequency\",\n                                )\n                            elif name == \"nuclear magnetic resonance pulse sequence\":\n                                fdo.addEntry(\n                                    \"21.T11969/3303cd9e3dda7afd6000\",\n                                    value,\n                                    \"Pulse Sequence Name\",\n                                )\n                    except Exception as e:  # Log the error and raise it\n                        logger.error(f\"Error mapping variable {variable}: {str(e)}\")\n                        raise ValueError(f\"Error mapping variable {variable}: {str(e)}\")\n\n            if (\n                \"isPartOf\" in bioschema_dataset\n                and bioschema_dataset[\"isPartOf\"] is not None\n            ):\n                if isinstance(bioschema_dataset[\"isPartOf\"], list):\n                    for part in bioschema_dataset[\n                        \"isPartOf\"\n                    ]:  # Iterate over the parts of the dataset\n                        if (\n                            \"name\" in part\n                        ):  # Add the name of the part to the PID record if available\n                            new_name = f\"{original_dataset['name']}-{part['name']}\"\n                            fdo.updateEntry(\"21.T11148/6ae999552a0d2dca14d6\", new_name)\n                        if \"hasBioChemEntityPart\" in part:\n                            biochem_part = part[\"hasBioChemEntityPart\"]\n                            value = {}\n                            if (\n                                \"molecularWeight\" in biochem_part\n                                and biochem_part[\"molecularWeight\"] is not None\n                            ):\n                                value[\"21.T11969/6c4d3deac9a49b65886a\"] = float(\n                                    biochem_part[\"molecularWeight\"]\n                                )  # Add the molecular weight to the value of characterizedCompound if available\n                            if (\n                                \"url\" in biochem_part\n                                and biochem_part[\"url\"] is not None\n                            ):\n                                value[\"21.T11969/f9cb9b53273ce0da7739\"] = biochem_part[\n                                    \"url\"\n                                ]  # Add the PubChem-URL to the value of characterizedCompound if available\n\n                            if (\n                                len(value) &gt; 0\n                            ):  # Add the value to the PID record if available\n                                fdo.addEntry(\n                                    \"21.T11969/d15381199a44a16dc88d\",\n                                    value,\n                                    \"characterizedCompound\",\n                                )\n\n                            if (\n                                \"chemicalFormula\" in biochem_part\n                            ):  # Check if the part has a chemical formula\n                                formula = biochem_part[\"chemicalFormula\"]\n                                if (\n                                    formula is not None\n                                    and formula != \"\"\n                                    and len(formula) &gt; 1\n                                ):  # Check for meaningful formula\n                                    new_name = f\"{original_dataset['name']}-{formula}\"  # Add the formula to the name of the part\n                                    fdo.deleteEntry(\"21.T11969/6ae999552a0d2dca14d6\")\n                                    fdo.addEntry(\n                                        \"21.T11148/6ae999552a0d2dca14d6\",\n                                        new_name,\n                                        \"name\",\n                                    )\n\n            return fdo\n        except Exception as e:  # Log the error and raise it\n            logger.error(f\"Error mapping dataset to FAIR-DO: {str(e)}\", dataset)\n            raise ValueError(f\"Error mapping dataset to FAIR-DO: {str(e)}\", dataset)\n\n    async def _mapSampleToPIDRecord(\n        self,\n        sample: dict,\n        addRelationship: Callable[\n            [str, list[PIDRecordEntry], Callable[[str], None] | None], str\n        ],\n    ) -&gt; PIDRecord:\n        \"\"\"\n        Maps a sample to a PID record.\n\n        Args:\n            sample (dict): The sample to map to a PID record. Contains the original and BioSchema data.\n            addRelationship (function): The function to add relationships to a PIDRecord. For more information see AbstractRepository.\n\n        Returns:\n            PIDRecord: The PID record mapped from the sample.\n        \"\"\"\n        # Extract the original and BioSchema data from the sample\n        original_study = sample[\"original\"]\n        bioschema_study = sample[\"bioschema\"]\n\n        if (\n            not original_study\n            or original_study is None\n            or not isinstance(original_study, dict)\n            or not original_study[\"identifier\"].startswith(\"NMRXIV:S\")\n        ):  # Check if the sample is valid\n            raise ValueError(\n                \"The provided data doesnt contain an original study\",\n                sample,\n                original_study,\n            )\n        elif (\n            not bioschema_study\n            or bioschema_study is None\n            or not isinstance(bioschema_study, dict)\n        ):  # Check if the BioSchema data is valid\n            raise ValueError(\n                \"The provided data doesnt contain a bioschema study\",\n                sample,\n                bioschema_study,\n            )\n        elif (\n            \"study_preview_urls\" not in original_study\n        ):  # Check if the sample has a study preview URL\n            raise ValueError(\n                \"The provided original_study doesnt contain a study preview url and can therefore not be a study\",\n                sample,\n                original_study,\n            )\n        elif (\n            \"@type\" not in bioschema_study or not bioschema_study[\"@type\"] == \"Study\"\n        ):  # Check if the BioSchema data is a study\n            raise ValueError(\n                \"The provided bioschema_study doesnt contain the correct @type value\",\n                sample,\n                bioschema_study,\n            )\n\n        logger.info(\"mapping sample to FAIR-DO\", sample)\n        try:\n            fdo = await self._mapGenericInfo2PIDRecord(\n                sample\n            )  # Get the generic information for the sample\n\n            fdo.addEntry(\n                \"21.T11969/b736c3898dd1f6603e2c\",\n                \"Study\",\n                \"resourceType\",\n            )\n\n            if (\n                \"public_url\" in original_study\n                and original_study[\"public_url\"] is not None\n            ):  # Add the public URL to the PID record as a landing page if available\n                fdo.addEntry(\n                    \"21.T11969/8710d753ad10f371189b\",\n                    original_study[\"public_url\"],\n                    \"landingPageLocation\",\n                )\n            elif (\n                \"url\" in bioschema_study and bioschema_study[\"url\"] is not None\n            ):  # Add the URL to the PID record as a landing page if available\n                fdo.addEntry(\n                    \"21.T11969/8710d753ad10f371189b\",\n                    bioschema_study[\"url\"],\n                    \"landingPageLocation\",\n                )\n\n            if (\n                \"study_photo_urls\" in original_study\n                and original_study[\"study_photo_urls\"] is not None\n            ):  # Add the study photo URLs to the PID record as a preview if available\n                for url in original_study[\"study_photo_urls\"]:\n                    fdo.addEntry(\n                        \"21.T11148/7fdada5846281ef5d461\", url, \"locationPreview\"\n                    )\n\n            compoundEntries = []  # Initialize the list of compound entries\n            if (\n                \"about\" in bioschema_study\n                and \"hasBioChemEntityPart\" in bioschema_study[\"about\"]\n                and bioschema_study[\"about\"][\"hasBioChemEntityPart\"] is not None\n            ):\n                for part in bioschema_study[\"about\"][\n                    \"hasBioChemEntityPart\"\n                ]:  # Iterate over the parts of the study\n                    if not part or part is None:  # Check if the part is valid\n                        logger.debug(\n                            f\"The provided part is empty. See {bioschema_study['@id']}\"\n                        )\n                        continue\n\n                    value: dict = {}\n\n                    if (\n                        \"molecularWeight\" in part\n                        and part[\"molecularWeight\"] is not None\n                    ):  # Add the molecular weight to the value of characterizedCompound if available\n                        value[\"21.T11969/6c4d3deac9a49b65886a\"] = float(\n                            part[\"molecularWeight\"]\n                        )\n                    if (\n                        \"url\" in part and part[\"url\"] is not None\n                    ):  # Add the PubChem-URL to the value of characterizedCompound if available\n                        value[\"21.T11969/f9cb9b53273ce0da7739\"] = part[\"url\"]\n\n                    if len(value) &gt; 0:  # Add the value to the PID record if available\n                        compoundEntries.append(\n                            PIDRecordEntry(\n                                \"21.T11969/d15381199a44a16dc88d\",\n                                value,\n                                \"characterizedCompound\",\n                            )\n                        )\n                    else:\n                        logger.warning(\n                            f\"The provided part does not contain a molecularWeight or url: {part}\"\n                        )\n\n                    # mol = part[\"molecularWeight\"]\n                    # # formula = part[\n                    # #     \"molecularFormula\"\n                    # # ]  # TODO: use this in the name or topic\n                    # # inchi = part[\"inChI\"]\n                    # pubchem = part[\"url\"]\n\n            elif (\n                \"molecules\" in original_study\n                and original_study[\"molecules\"] is not None\n            ):  # Add the molecules to the PID record if available and no BioChemEntityParts are available\n                for molecule in original_study[\n                    \"molecules\"\n                ]:  # Iterate over the molecules\n                    mol = molecule[\"molecular_weight\"]\n                    # formula = molecule[\n                    #     \"molecular_formula\"\n                    # ]  # TODO: use this in the name or topic\n                    # inchi = molecule[\"standard_inchi\"]\n                    compoundEntries.append(\n                        PIDRecordEntry(\n                            \"21.T11969/d15381199a44a16dc88d\",\n                            {  # characterisedCompound\n                                \"21.T11969/6c4d3deac9a49b65886a\": mol,  # molecularWeight\n                            },\n                            \"characterizedCompound\",\n                        )\n                    )\n\n            if (\n                len(compoundEntries) &gt; 0\n            ):  # Add the compound entries to the PID record if available\n                fdo.addListOfEntries(compoundEntries)\n\n            if \"hasPart\" in bioschema_study and bioschema_study[\"hasPart\"] is not None:\n                for part in bioschema_study[\n                    \"hasPart\"\n                ]:  # Iterate over the parts of the study\n                    if (\n                        not part or part is None or \"@id\" not in part\n                    ):  # Check if the part is valid\n                        logger.error(\n                            f\"The provided part {part} in this study does not contain an @id\"\n                        )\n                        continue\n\n                    presumedDatasetID = encodeInBase64(\n                        part[\"@id\"].replace(\"https://doi.org/\", \"\")\n                    )  # Encode the dataset ID\n\n                    datasetEntries = [\n                        PIDRecordEntry(\n                            \"21.T11148/d0773859091aeb451528\",\n                            fdo.getPID(),\n                            \"hasMetadata\",\n                        ),\n                    ]  # Initialize the list of dataset entries\n\n                    # Add the preview image(s) to the dataset, if available\n                    images = fdo.getEntry(\"21.T11148/7fdada5846281ef5d461\")\n                    if images is not None and isinstance(\n                        images, list\n                    ):  # Add the images to the dataset if available\n                        for image in images:  # Iterate over the images\n                            datasetEntries.append(\n                                PIDRecordEntry(\n                                    \"21.T11148/7fdada5846281ef5d461\",\n                                    image,\n                                    \"locationPreview\",\n                                )\n                            )\n                    elif images is not None and isinstance(\n                        images, str\n                    ):  # Add the image to the dataset if available\n                        datasetEntries.append(\n                            PIDRecordEntry(\n                                \"21.T11148/7fdada5846281ef5d461\",\n                                images,\n                                \"locationPreview\",\n                            )\n                        )\n\n                    # TODO: Add formula to name or topic\n\n                    if (\n                        len(compoundEntries) &gt; 0\n                    ):  # Add the compound entries to the dataset if available\n                        datasetEntries.extend(compoundEntries)\n\n                    try:  # TODO: Abstract this\n\n                        def add_metadata_entry(fdo_pid: str, pid: str) -&gt; None:\n                            \"\"\"\n                            Adds a metadata entry to the dataset.\n\n                            Args:\n                                fdo_pid (str): The PID of the FAIR-DO.\n                                pid (str): The PID of the dataset.\n\n                            Returns:\n                                None\n                            \"\"\"\n                            if pid is not None:\n                                addRelationship(\n                                    fdo_pid,\n                                    [\n                                        PIDRecordEntry(\n                                            \"21.T11148/4fe7cde52629b61e3b82\",\n                                            pid,\n                                            \"isMetadataFor\",\n                                        )\n                                    ],\n                                    None,\n                                )\n\n                        addRelationship(  # Add the dataset to the PID record\n                            presumedDatasetID,  # The presumed PID of the dataset\n                            datasetEntries,  # The predefined dataset entries from above\n                            lambda pid: add_metadata_entry(\n                                fdo.getPID(), pid\n                            ),  # Callback function to add the metadata entry to the study\n                        )\n                    except Exception as e:  # Log the error and raise it\n                        logger.error(\n                            \"Error adding dataset reference to study\",\n                            presumedDatasetID,\n                            datasetEntries,\n                            e,\n                        )\n\n            return fdo\n        except Exception as e:  # Log the error and raise it\n            logger.error(f\"Error mapping sample to FAIR-DO: {str(e)}\", sample)\n            raise ValueError(f\"Error mapping sample to FAIR-DO: {str(e)}\", sample)\n\n    async def _mapProjectToPIDRecord(\n        self,\n        project: dict,\n        addEntries: Callable[\n            [str, list[PIDRecordEntry], Callable[[str], None] | None], str\n        ],\n    ) -&gt; PIDRecord:\n        \"\"\"\n        Maps a project to a PID record.\n\n        Args:\n            project (dict): The project to map to a PID record. Contains the original and BioSchema data.\n            addEntries (function): The function to add entries to a PIDRecord. For more information see AbstractRepository.\n\n        Returns:\n            PIDRecord: The PID record mapped from the project\n        \"\"\"\n        # Extract the original and BioSchema data from the project\n        original_project = project[\"original\"]\n        bioschema_project = project[\"bioschema\"]\n\n        if (\n            not original_project\n            or original_project is None\n            or not isinstance(original_project, dict)\n            or not original_project[\"identifier\"].startswith(\"NMRXIV:P\")\n        ):  # Check if the project is valid\n            raise ValueError(\n                \"Bad Request - The provided data is not a project\", project\n            )\n\n        logger.info(\"mapping project to FAIR-DO\", project)\n        try:\n            fdo = await self._mapGenericInfo2PIDRecord(\n                project\n            )  # Get the generic information for the project\n\n            fdo.addEntry(\n                \"21.T11969/b736c3898dd1f6603e2c\",\n                \"Project\",\n                \"resourceType\",\n            )\n\n            if (\n                \"public_url\" in original_project\n                and original_project[\"public_url\"] is not None\n            ):  # Add the public URL to the PID record as a landing page if available\n                fdo.addEntry(\n                    \"21.T11969/8710d753ad10f371189b\",\n                    original_project[\"public_url\"],\n                    \"landingPageLocation\",\n                )\n            elif (\n                \"url\" in bioschema_project and bioschema_project[\"url\"] is not None\n            ):  # Add the URL to the PID record as a landing page if available\n                fdo.addEntry(\n                    \"21.T11969/8710d753ad10f371189b\",\n                    bioschema_project[\"url\"],\n                    \"landingPageLocation\",\n                )\n\n            if (\n                \"photo_url\" in original_project\n                and original_project[\"photo_url\"] is not None\n            ):  # Add the photo URL to the PID record as a preview if available\n                fdo.addEntry(\n                    \"21.T11148/7fdada5846281ef5d461\",\n                    original_project[\"photo_url\"],\n                    \"locationPreview\",\n                )\n\n            if (\n                \"hasPart\" in bioschema_project\n                and bioschema_project[\"hasPart\"] is not None\n            ):\n                for study in bioschema_project[\n                    \"hasPart\"\n                ]:  # Iterate over the studies of the project (if available)\n                    if \"@id\" not in study:  # Check if the study has an ID\n                        raise ValueError(\n                            \"The provided study in this project does not contain an @id\",\n                            project,\n                        )\n\n                    presumedStudyID = encodeInBase64(\n                        study[\"@id\"].replace(\"https://doi.org/\", \"\")\n                    )  # Encode the study ID\n\n                    studyEntries = [\n                        PIDRecordEntry(\n                            \"21.T11148/d0773859091aeb451528\",\n                            fdo.getPID(),\n                            \"hasMetadata\",\n                        ),\n                    ]\n\n                    try:\n\n                        def add_metadata_entry(fdo_pid: str, pid: str):\n                            \"\"\"\n                            Adds a metadata entry to the project.\n\n                            Args:\n                                fdo_pid (str): The PID of the FAIR-DO.\n                                pid (str): The PID of the study.\n\n                            Returns:\n                                None\n                            \"\"\"\n                            if pid is not None:\n                                addEntries(\n                                    fdo_pid,\n                                    [\n                                        PIDRecordEntry(\n                                            \"21.T11148/4fe7cde52629b61e3b82\",\n                                            pid,\n                                            \"isMetadataFor\",\n                                        )\n                                    ],\n                                    None,\n                                )\n\n                        addEntries(  # Add the study to the PID record\n                            presumedStudyID,  # The presumed PID of the study\n                            studyEntries,  # The predefined study entries from above\n                            lambda pid: add_metadata_entry(\n                                fdo.getPID(), pid\n                            ),  # Callback function to add the metadata entry to the project\n                        )\n                    except Exception as e:  # Log the error and raise it\n                        logger.error(\n                            \"Error adding study reference to project\",\n                            presumedStudyID,\n                            studyEntries,\n                            e,\n                        )\n            return fdo\n        except Exception as e:  # Log the error and raise it\n            logger.error(f\"Error mapping project to FAIR-DO: {str(e)}\", project)\n            raise ValueError(f\"Error mapping project to FAIR-DO: {str(e)}\", project)\n\n    def _removeDescription(self, resource: Any):\n        \"\"\"\n        Removes the description from the specified resource. This is done for better readability and to reduce the size of the JSON-LD. The description field is not machine-readable and is therefore not needed.\n\n        Args:\n            resource (Any): The resource to remove the description from. If it is not a dictionary, the resource is returned as is.\n\n        Returns:\n            dict: The resource without the description.\n            Any: The resource as is if it is not a dictionary.\n        \"\"\"\n\n        if (\n            not resource or resource is None or not isinstance(resource, dict)\n        ):  # If the resource is not a dictionary, return it as is\n            return resource\n\n        if \"description\" in resource:  # If the resource has a description, remove it\n            resource[\"description\"] = None\n        if \"sdf\" in resource:  # If the resource has an sdf, remove it\n            resource[\"sdf\"] = None\n\n        def removeRecursively(key: str):\n            \"\"\"\n            Removes the description from the specified key in the resource. This is done recursively for all parts of the resource.\n            \"\"\"\n            if (\n                key not in resource\n            ):  # if the key is not in the resource, stop the function\n                return\n            parts = []\n            if isinstance(resource[key], list):\n                for part in resource[\n                    key\n                ]:  # if the key is a list, iterate over the list\n                    parts.append(\n                        self._removeDescription(part)\n                    )  # remove the description from each part\n            else:\n                parts.append(\n                    self._removeDescription(resource[key])\n                )  # if the key is not a list, remove the description from the key\n            resource[key] = parts  # set the key to the list of parts\n\n        removeRecursively(\"hasPart\")\n        removeRecursively(\"isPartOf\")\n        removeRecursively(\"samples\")\n        removeRecursively(\"studies\")\n\n        return resource\n\n    def getRepositoryFDO(self) -&gt; PIDRecord:\n        fdo = PIDRecord(encodeInBase64(self._baseURL))\n        fdo.addEntry(\n            \"21.T11148/076759916209e5d62bd5\",\n            \"21.T11148/b9b76f887845e32d29f7\",  # TODO: get the correct KIP PID; currently HelmholtzKIP\n            \"Kernel Information Profile\",\n        )\n        fdo.addEntry(\n            \"21.T11148/1c699a5d1b4ad3ba4956\",\n            \"21.T11148/010acb220a9c2c8c0ee6\",  # TODO: text/html for now\n            \"digitalObjectType\",\n        )\n\n        fdo.addEntry(\n            \"21.T11148/b8457812905b83046284\",\n            self._baseURL,\n            \"digitalObjectLocation\",\n        )\n\n        fdo.addEntry(\n            \"21.T11969/8710d753ad10f371189b\",\n            self._baseURL,\n            \"landingPageLocation\",\n        )\n\n        fdo.addEntry(\n            \"21.T11148/7fdada5846281ef5d461\",\n            \"https://avatars.githubusercontent.com/u/65726315\",  # TODO: get the correct location preview\n            \"locationPreview\",\n        )\n\n        fdo.addEntry(\n            \"21.T11148/aafd5fb4c7222e2d950a\",\n            datetime.now().isoformat(),\n            \"dateCreated\",\n        )\n\n        fdo.addEntry(\n            \"21.T11148/6ae999552a0d2dca14d6\",\n            \"NMRXiv\",\n            \"name\",\n        )\n\n        fdo.addEntry(\"21.T11969/b736c3898dd1f6603e2c\", \"Repository\", \"resourceType\")\n\n        return fdo\n</code></pre>"}]}